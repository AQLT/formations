[
  {
    "objectID": "2021/index.html",
    "href": "2021/index.html",
    "title": "Formations",
    "section": "",
    "text": "2021\n\nJuin 2021 : Désaisonnalisation avec JDemetra+ et RJDemetra (RTE)"
  },
  {
    "objectID": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html",
    "href": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html",
    "title": "1 - Première manipulation de JDemetra+",
    "section": "",
    "text": "L’objectif de ce TP est de faire une première manipulation de JDemetra+ : créer un workspace, importer des données, lancer une première désaisonnalisation."
  },
  {
    "objectID": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html#importation-dun-fichier-excel-sous-jdemetra",
    "href": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html#importation-dun-fichier-excel-sous-jdemetra",
    "title": "1 - Première manipulation de JDemetra+",
    "section": "Importation d’un fichier Excel sous JDemetra+",
    "text": "Importation d’un fichier Excel sous JDemetra+\nOn se place ici dans le cas où les données brutes figurent dans un fichier Excel qui respecte les règles suivantes :\n\nla première colonne correspond à la date au format JJ/MM/AAAA\nla première ligne contient le nom des séries\n\n\n\n\n\n\n\nPour information\n\n\n\nPour créer un tel fichier Excel depuis R, voir le TP 0 - Traitement des séries temporelles sous R.\n\n\n\nRetourner sous JDemetra+\nCliquer sur l’onglet Providers\nClic-droit sur Spreadsheets\nCliquer sur Open\nCliquer sur le bouton …\nSélectionner un fichier Excel contenant les séries à désaisonnaliser\nCliquer sur OK\n\nQue voit-on sous Spreadsheets ?"
  },
  {
    "objectID": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html#mettre-un-fichier-en-favori",
    "href": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html#mettre-un-fichier-en-favori",
    "title": "1 - Première manipulation de JDemetra+",
    "section": "Mettre un fichier en « favori »",
    "text": "Mettre un fichier en « favori »\n\nSauvegarder le workspace puis l’ouvrir de nouveau\nCliquer sur l’onglet Providers\nQue voit-on ?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLes données ont disparues !\n\n\n\n\nImporter de nouveau votre fichier Excel\nClic-droit sur le nom du fichier Excel qui est apparu sous Spreadsheets\nCliquer sur Add star\nQue se passe-t-il ?\nSauvegarder le workspace, fermer le logiciel puis l’ouvrir de nouveau\nCliquer sur l’onglet Providers\n\nQue voit-on ?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLes données restent ! Si on utilise souvent ce fichier Excel c’est un moyen de le garder en mémoire.\n\n\n\n\n\n\n\n\n\nPour information\n\n\n\nJDemetra+ stocke l’emplacement du fichier Excel, si vous le changez de répertoire, les données ne seront plus reconnues ! Peu pratique me direz-vous mais c’est en fait indispensable si l’on souhaite mettre à jour. Évitez donc de laisser votre fichier dans le dossier “Téléchargements” !"
  },
  {
    "objectID": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html#création-dun-nouveau-multi-document",
    "href": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html#création-dun-nouveau-multi-document",
    "title": "1 - Première manipulation de JDemetra+",
    "section": "Création d’un nouveau « multi-document »",
    "text": "Création d’un nouveau « multi-document »\n\nCliquer sur l’onglet Workspace\nDouble-clic sur Seasonal adjustment\nClic-droit sur multi-documents\nCliquer sur New\nDouble-clic sur multi-documents\n\nQue voit-on ?\n\nDouble-clic sur le « multi-document » créé, nommé SAProcessing-1 par défaut\n\nQue se passe-t-il ?"
  },
  {
    "objectID": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html#choisir-une-spécfication-pré-définie",
    "href": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html#choisir-une-spécfication-pré-définie",
    "title": "1 - Première manipulation de JDemetra+",
    "section": "Choisir une spécfication pré-définie",
    "text": "Choisir une spécfication pré-définie\n\nAller dans l’onglet SAProcessing-1\nCliquer sur la flèche située à côté de la petite « calculatrice »\nCliquer sur le + à côté de « x13 » puis cliquer sur RSA5c\nCliquer quelque part dans SAProcessing-1"
  },
  {
    "objectID": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html#lancer-une-désaisonnalisation",
    "href": "2021/rte/TP/JD-1-Premiere_manipulation_JD.html#lancer-une-désaisonnalisation",
    "title": "1 - Première manipulation de JDemetra+",
    "section": "Lancer une désaisonnalisation",
    "text": "Lancer une désaisonnalisation\n\nCliquer sur Providers\nFaire glisser l’ensemble des séries de votre fichier dans l’onglet SAProcessing-1\n\nQue voit-on ?\n\nCliquer sur la flèche verte figurant dans l’onglet SAProcessing-1\n\n\n\nQue se passe-t-il ?\nCliquer sur une série\n\nQue voit-on ?\n\nSauvegarder le workspace\n\n\n\n\n\n\n\nPour information\n\n\n\nIl y a de grandes chances pour qu’un jour vous oubliiez l’étape 3.2 avant de “faire glisser” vos séries. Dans ce cas, vous aurez beau changer la spécification, cela n’affectera vos séries déjà importées. Deux solutions s’offrent à vous :\n\nSolution brutale : fermer le workspace, supprimer toutes les séries, bref, tout recommencer.\nSolution maligne : sélectionner toutes les séries (ctrl + clic gauche ou ctrl + a, ou ctrl + maj…), clic droit, Spécification > Select > choisir la spécification voulue."
  },
  {
    "objectID": "2021/rte/TP/JD-2-Analyse_exploratoire.html",
    "href": "2021/rte/TP/JD-2-Analyse_exploratoire.html",
    "title": "2 - Analyse exploratoire",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à faire une analyse exploratoire sous JDemetra+.\n\n\nTracer un graphique dans JDemetra+\n\nCliquer sur la commande Tools>Container>Chart de la barre de menus en haut de l’écran\n\nQue se passe-t-il ?\n\nFaire glisser une série de l’onglet Providers vers l’onglet Chart.\n\nQue peut-on dire ?\n\nEst-ce que la série présente une tendance ?\nEst-ce que la série semble saisonnière?\n\n\nEst-ce que la série présente des pics ?\n\nSi oui, ces pics ont-ils ont toujours la même amplitude ?\n\nCliquer sur la courbe\nClic-droit sur la courbe\nCliquer sur Split into yearly components\n\nQue se passe-t-il ?\nQue peut-on dire en analysant ce graphique ?\n\n\n\n\nTracer les taux de croissance d’une série dans JDemetra+\n\nCliquer sur la commande Tools>Container>GrowthChart de la barre de menus en haut de l’écran\n\nQue se passe-t-il ?\n\nFaire glisser une série de l’onglet Providers vers l’onglet GrowthChart.\n\nQuel est le taux de croissance représenté par défaut sur ce graphique ?\nReprésenter le taux de croissance en glissement annuel par un clic droit sur le graphique et en sélectionnant ensuite dans le menu qui s’affiche l’item Kind puis Previous Year.\nPlacer le curseur de la souris sur une des « barres » du graphique : que se passe-t-il?\n\nQuelles informations peut-on tirer de ces graphiques ?\n\n\n\nTracer le spectre d’une série sous JDemetra+\n\nCliquer sur la commande Tools>Spectral analysis>Periodogram de la barre de menus en haut de l’écran\n\nQue se passe-t-il ?\n\nFaire glisser une série de l’onglet Providers vers l’onglet Periodogram Window.\n\nLe spectre présente-il des pics ?\n\nSi oui, à quelles fréquences ?\n\n\nFaire la même chose en prenant un autre outil que le Periodogram."
  },
  {
    "objectID": "2021/rte/TP/JD-3-CVS_sans_CJO.html",
    "href": "2021/rte/TP/JD-3-CVS_sans_CJO.html",
    "title": "3 - Désaisonnalisation sans correction des jours ouvrables",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à faire une désaisonnalisation sans correction des jours ouvrables (CJO)."
  },
  {
    "objectID": "2021/rte/TP/JD-3-CVS_sans_CJO.html#schéma-de-décomposition",
    "href": "2021/rte/TP/JD-3-CVS_sans_CJO.html#schéma-de-décomposition",
    "title": "3 - Désaisonnalisation sans correction des jours ouvrables",
    "section": "9.1. Schéma de décomposition",
    "text": "9.1. Schéma de décomposition\n\nDans la fenêtre Main results\n\nQuel est le schéma de décomposition choisi par JDemetra+ ? Est-ce que vous êtes d’accord ?"
  },
  {
    "objectID": "2021/rte/TP/JD-3-CVS_sans_CJO.html#outliers",
    "href": "2021/rte/TP/JD-3-CVS_sans_CJO.html#outliers",
    "title": "3 - Désaisonnalisation sans correction des jours ouvrables",
    "section": "Outliers",
    "text": "Outliers\n\nDans la fenêtre Main results\n\nCombien d’outliers ont été détectés par JDemetra+ ?\n\nY en a-t-il trop ?\n\n\nDans la fenêtre Pre-processing\n\nQuels sont les différents types d’outliers détéctés par JDemetra+ ?\n\nRetourner dans la fenêtre Main results\n\nAller dans Main results > Charts\n\nRegarder les différents graphiques : pouvez-vous repérer, sur la série brute, les points atypiques détéctés dans le modèle ?"
  },
  {
    "objectID": "2021/rte/TP/JD-3-CVS_sans_CJO.html#s-i-ratio",
    "href": "2021/rte/TP/JD-3-CVS_sans_CJO.html#s-i-ratio",
    "title": "3 - Désaisonnalisation sans correction des jours ouvrables",
    "section": "S-I Ratio",
    "text": "S-I Ratio\n\nAller dans la fenêtre Main results > S-I ratio\nPouvez-vous repérer le schéma de décomposition ?\nQuel est l’objectif de ce graphique ?\nLes coefficients saisonniers sont-ils stables ?"
  },
  {
    "objectID": "2021/rte/TP/JD-4-CVS_CJO.html",
    "href": "2021/rte/TP/JD-4-CVS_CJO.html",
    "title": "4 - Désaisonnalisation avec correction des jours ouvrables",
    "section": "",
    "text": "Importer les jeux de régresseurs « Jours Ouvrables » sous JDemetra+\n\nCliquer sur l’onglet Providers\nClic-droit sur Spreadsheets\n\nCliquer sur Open\nCliquer sur le bouton …\nSélectionner le fichier Excel « regcjo.xls » contenant les régresseurs « Jours Ouvrables » créés depuis R à partir de l’objet regresseurs_JO.\nCliquer sur OK\n\nCliquer sur l’onglet Workspace\nCliquer sur le + à côté d’Utilities\nClic-droit sur Variables\nCliquer sur New\nCliquer sur le + à côté de Variables\nDouble cliquer sur l’icône Vars-1\n\nQue se passe-t-il ?\n\nRetourner dans l’onglet Providers\nFaire glisser l’ensemble des séries du fichier « regcjo.xls » dans l’onglet Vars-1\nRenommer les séries en reprenant leur nom d’origine dans le fichier excel « regcjo.xls ».\n\nCe travail peut être très fastidieux… Heureusement depuis R il existe une solution plus automatique ! Ci-dessous un code pour vous éviter de faire ce travail (un peu compliqué mais une fois le code écrit, vous pouvez l’utiliser tel quel !).\n\n# On va créer un nouveau workspace où l'on va ajouter les nouvelles variables\nlibrary(RJDemetra)\nlibrary(rJava)\ncomplete_variables <- function(liste_var, workspace){\n  if(!is.mts(liste_var))\n    stop(\"liste_var doit être de type mts\")\n  context_dictionary <- .jcall(workspace,\"Lec/tstoolkit/algorithm/ProcessingContext;\", \"getContext\")\n  ts_variable_managers <- context_dictionary$getTsVariableManagers()\n  ts_variables <- .jnew(\"ec/tstoolkit/timeseries/regression/TsVariables\")\n  jd_r_variables <- ts_variable_managers$get(\"r\")\n  if (is.null(jd_r_variables)) {\n    ts_variable_managers$set(\"r\",\n                             .jnew(\"ec/tstoolkit/timeseries/regression/TsVariables\"))\n    jd_r_variables <- ts_variable_managers$get(\"r\")\n  }\n  jd_var_names <- jd_r_variables$getNames()\n\n  model_var_names <- colnames(liste_var)\n\n  for (i in seq_along(model_var_names)) {\n    name <- model_var_names[i]\n    dictionary_var <- jd_r_variables$get(name)\n    tsvar <- .jnew(\"ec/tstoolkit/timeseries/regression/TsVariable\",\n                   name, RJDemetra:::ts_r2jd(liste_var[, i]))\n    if (is.null(dictionary_var)) {\n      jd_r_variables$set(name, tsvar)\n    } else {\n      warning(sprintf(\"La variable %s existe déjà\", name))\n    }\n  }\n}\n\n# Pour la création des regresseurs, voir le TP R associé.\n# Par exemple :\nlibrary(rjd3modelling)\nfrenchCalendar <- calendar.new()\ncalendar.holiday(frenchCalendar, \"NEWYEAR\")\ncalendar.holiday(frenchCalendar, \"EASTERMONDAY\") # Lundi de Pâques\ncalendar.holiday(frenchCalendar, \"MAYDAY\") # 1er mai\ncalendar.fixedday(frenchCalendar, 5, 8)\ncalendar.holiday(frenchCalendar, \"WHITMONDAY\") # Lundi de Pentecôte\ncalendar.fixedday(frenchCalendar, 7, 14)\ncalendar.holiday(frenchCalendar, \"ASSUMPTION\") # Assomption\ncalendar.holiday(frenchCalendar, \"ALLSAINTDAY\") # Toussaint\ncalendar.holiday(frenchCalendar, \"ARMISTICE\")\n\nleap_year <- function(start = 1990, end = 2030, frequency = 12){\n  ly <- ts(0, start = start, end = end, frequency = 12)\n  mois_feb <- cycle(ly) == 2\n  annees <- trunc(round(time(ly), 3)) # arrondi car parfois des pbs avec fonction time\n  # On utilise la définition exacte\n  is_ly <- (annees %% 400 == 0) |\n    ((annees %% 4 == 0) & (annees %% 100 != 0))\n  ly[mois_feb] <- 28 - 28.2425\n  ly[mois_feb & is_ly] <- 29 - 28.2425\n  # on change si besoin la fréquence\n  stats::aggregate(ly, nfrequency = frequency)\n}\nfrequency <- 12\nstart <- c(1990,1)\nend = c(2030, 1)\nlength = (end[1] - start[1]) * 12 + end[2] - start[2]\n\nly <- leap_year(frequency = frequency, start = start,\n                end = end)\nreg6 <- htd(frenchCalendar, frequency = frequency, start = start, length = length,\n            groups = c(1, 2, 3, 4, 5, 6, 0))\nreg5 <- htd(frenchCalendar, frequency = frequency, start = start, length = length,\n            groups = c(1, 2, 3, 4, 5, 0, 0))\nreg4 <- htd(frenchCalendar, frequency = frequency, start = start, length = length,\n            groups = c(1, 2, 2, 2, 3, 4, 0))\nreg3 <- htd(frenchCalendar, frequency = frequency, start = start, length = length,\n            groups = c(1, 2, 2, 2, 2, 0, 0))\nreg2 <- htd(frenchCalendar, frequency = frequency, start = start, length = length,\n            groups = c(1, 1, 1, 1, 1, 2, 0))\nreg1 <- htd(frenchCalendar, frequency = frequency, start = start, length = length,\n            groups = c(1, 1, 1, 1, 1, 0, 0))\n\n\nregresseurs_JO <- ts(cbind(reg1, reg2, reg3, reg4, reg5, reg6),\n                     start = start, frequency = frequency)\nregresseurs_JO <- ts.union(regresseurs_JO,\n                           ly)\ncolnames(regresseurs_JO) <- c(\"REG1_semaine\",\n                              sprintf(\"REG2_%s\", c(\"lundi_a_vendredi\", \"samedi\")),\n                              sprintf(\"REG3_%s\", c(\"lundi\", \"mardi_a_vendredi\")),\n                              sprintf(\"REG4_%s\", c(\"lundi\", \"mardi_a_jeudi\", \"vendredi\", \"samedi\")),\n                              sprintf(\"REG5_%s\", c(\"lundi\", \"mardi\", \"mercredi\", \"jeudi\", \"vendredi\")),\n                              sprintf(\"REG6_%s\", c(\"lundi\", \"mardi\", \"mercredi\", \"jeudi\", \"vendredi\", \"samedi\")),\n                              \"leap_year\")\n\n# Création d'un nouveaux\nwk <- new_workspace()\n# regresseurs_JO est l'objet mts qui contient tous vos régresseurs\n# Il doit donc déjà être créé (voir code ci-dessus) !\ncomplete_variables(regresseurs_JO, wk)\nsave_workspace(wk,\"my workspace.xml\")\n\n\n\nCréer une spécification incluant les jeux de régresseurs « jours ouvrables » Insee\n\nCliquer sur l’onglet Workspace\nDouble cliquer sur Seasonal adjustment\nDouble cliquer sur specifications\nDouble cliquer sur x13\nClic-droit sur RSA5c\nCliquer sur Clone\n\nQue se passe-t-il ?\n\nDouble-cliquer sur X13Spec-1\nCliquer sur le + à côté de Calendar\nCliquer sur le + à côté de tradingDays\nCliquer sur Default à côté de option\n\nQue se passe-t-il ?.\n\nCliquer sur UserDefined\nCliquer sur Unused à côté de userVariables\n\nQue se passe-t-il ?\n\nFaire passer les 6 régresseurs du jeu de régresseurs REG6 + leap_year de la gauche vers la droite\nCliquer sur le bouton Done\nCliquer sur OK\n\n\n\nRéaliser une désaisonnalisation automatique de vos séries en utilisant la spécification X13Spec-1\nVoir exercice 1.\n\n\nAnalyser les diagnostics relatifs à la correction des effets de calendrier\nPour chaque série, répondez aux questions suivantes :\n\nY a-t-il eu une correction des effets de calendrier ?\n\nSi oui, est-ce que tous les coefficients associés aux régresseurs « JO » sont significativement différents de 0 ?\n\nSi non, essayer d’autres jeux de régresseurs « JO »\n\nY a-t-il eu une correction de l’effet Pâques ?\n\nLa série CVS-CJO présente-t-elle des effets « Jours Ouvrables » résiduels ?"
  },
  {
    "objectID": "2021/rte/TP/JD-5-Preajustment.html",
    "href": "2021/rte/TP/JD-5-Preajustment.html",
    "title": "5 - Pré-ajustement",
    "section": "",
    "text": "L’objectif de ce TP est d’analyser la qualité du pre-ajustement et de modifier, si nécessaire, la spécification"
  },
  {
    "objectID": "2021/rte/TP/JD-5-Preajustment.html#transformation",
    "href": "2021/rte/TP/JD-5-Preajustment.html#transformation",
    "title": "5 - Pré-ajustement",
    "section": "Transformation",
    "text": "Transformation\n\nEssayez de changer le schéma de décomposition (onglet TRANSFORMATION > function)\n\nQu’est-ce que vous remarquez ? Est-ce qu’il y a eu des changements dans la partie le pré-ajustement ?\nEst-ce que les critères AICc et BIC ont été modifiés ?"
  },
  {
    "objectID": "2021/rte/TP/JD-5-Preajustment.html#régresseurs-calendaires",
    "href": "2021/rte/TP/JD-5-Preajustment.html#régresseurs-calendaires",
    "title": "5 - Pré-ajustement",
    "section": "Régresseurs calendaires",
    "text": "Régresseurs calendaires\n\nEssayez de changer le jeu de régresseurs jours ouvrables :\nQue pouvez-vous noter sur les tests de Student, Fischer, coefficients, AICc et BIC ?\nEst-ce qu’il y a des effets calendaires résiduels ?\nQuelle est la qualité du modèle Reg-ARIMA ?"
  },
  {
    "objectID": "2021/rte/TP/JD-5-Preajustment.html#outliers",
    "href": "2021/rte/TP/JD-5-Preajustment.html#outliers",
    "title": "5 - Pré-ajustement",
    "section": "Outliers",
    "text": "Outliers\n\nDans la partie REGRESSION > Pre-specified outliers\n\nAjouter des outliers qui vous semblent pertinents et qui ne sont pas détectés par JDemetra+ (si vous avez connaissance d’un évènement particulier)\n\nEssayer de changer le seuil critique de détection des outliers (Critical value)\nQue remarquez vous sur le nombre d’outliers, l’AICc et le BIC ?\nEn quoi cela affecte la qualité de l’ajustement et des résidus du modèle ?\nEssayer de changer le type d’outliers détectés."
  },
  {
    "objectID": "2021/rte/TP/JD-5-Preajustment.html#forecasts-results",
    "href": "2021/rte/TP/JD-5-Preajustment.html#forecasts-results",
    "title": "5 - Pré-ajustement",
    "section": "Forecasts results",
    "text": "Forecasts results\n\nAller dans la partie Pre-processing > Forecasts > Out-of-sample test\nQue comprenez-vous ?\nEn quoi c’est utile ?"
  },
  {
    "objectID": "2021/rte/TP/JD-6-X11.html",
    "href": "2021/rte/TP/JD-6-X11.html",
    "title": "6 - X11",
    "section": "",
    "text": "L’objectif de ce TP est d’analyser la décomposition et de changer la spécification si nécessaire"
  },
  {
    "objectID": "2021/rte/TP/JD-6-X11.html#filtre-saisonnier",
    "href": "2021/rte/TP/JD-6-X11.html#filtre-saisonnier",
    "title": "6 - X11",
    "section": "Filtre saisonnier",
    "text": "Filtre saisonnier\n\nEssayer de changer le filtre saisonnier dans X11 > Seasonal filter\n\nLorsque vous prenez un filtre plus long ou plus court, qu’observez vous sur les M statistics, S-I ratios, la saisonnalité et la série désaisonnalisée ?\nEn quoi cela affecte les autres diagnostics (en particulier la saisonnalité résiduelle) ?"
  },
  {
    "objectID": "2021/rte/TP/JD-6-X11.html#filtre-de-henderson",
    "href": "2021/rte/TP/JD-6-X11.html#filtre-de-henderson",
    "title": "6 - X11",
    "section": "Filtre de Henderson",
    "text": "Filtre de Henderson\n\nEssayer de changer le filtre de Henderson dans X11 > Henderson filter\n\nLorsque vous prenez un filtre plus long ou plus court, qu’observez vous sur les M statistics, S-I ratios, la saisonnalité et la série désaisonnalisée ?\nEn quoi cela affecte les autres diagnostics ?"
  },
  {
    "objectID": "2021/rte/TP/JD-6-X11.html#lsigma-and-usigma",
    "href": "2021/rte/TP/JD-6-X11.html#lsigma-and-usigma",
    "title": "6 - X11",
    "section": "Lsigma and Usigma",
    "text": "Lsigma and Usigma\n\nEssayer de changer les paramètres Lsigma et Usigma\n\nQu’observez-vous sur les statistiques M ?\nEn quoi cela affecte les autres diagnostics ?"
  },
  {
    "objectID": "2021/rte/TP/JD-6-X11.html#calendar-sigma",
    "href": "2021/rte/TP/JD-6-X11.html#calendar-sigma",
    "title": "6 - X11",
    "section": "Calendar sigma",
    "text": "Calendar sigma\n\nAller dans la fenêtre Decomposition (X11) > Quality measures > Details et descendre jusqu’au test de Cochran\n\nEst-ce que le test est rejeté ? Si oui qu’est-ce que cela implique ? Regarder les S-I ratios : est-ce que vous êtes d’accord avec ce test ?\nChanger le paramètre calendarsigma à “Signif” : en quoi les différents diagnostics sont impactés ?"
  },
  {
    "objectID": "2021/rte/TP/JD-7-Etude_de_cas.html",
    "href": "2021/rte/TP/JD-7-Etude_de_cas.html",
    "title": "7 - Étude de cas",
    "section": "",
    "text": "L’objectif de ce TP est de faire une étude de cas spécifique pour voir des problèmes possibles et une proposition de solution\nDisclaimer : il peut exister plusieurs solutions, celles données dans ce TP ne sont que des propositions qui peuvent être discuté.\nPour télécharger le workspace, cliquer ici et dézipper le fichier. Pour importer les séries depuis R, vous pouvez par exemple utiliser le code suivant :"
  },
  {
    "objectID": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2932",
    "href": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2932",
    "title": "7 - Étude de cas",
    "section": "Série RF2932",
    "text": "Série RF2932\n\nIl y a un problème d’hétéroscédasticité (au seuil de 1 %) et un léger problème de non-normalité (au seuil de 1 %).\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nQue pensez-vous du schéma de décomposition ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nDécision : forcer le schéma en multiplicatif.\n\n\n\nSolution sous R :\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nRF2932_init <- x13(get_ts(all_models$RF2932),\n                   x13_spec(all_models$RF2932),\n                   userdefined = c(\"diagnostics.levelstat\",\n                                   \"diagnostics.logstat\"))\n# avec modèle airline, le modèle additif est meilleur en terme d'aicc\nc(RF2932_init$user_defined) \n\n$diagnostics.levelstat\n[1] 1107.123\n\n$diagnostics.logstat\n[1] 1118.317\n\nRF2932_init$regarima$residuals.stat\n\n$st.error\n[1] 6.357559\n\n$tests\n\n\u001b[1mNormality\u001b[22m\n          Statistic P.value    \nmean     -0.3191819  0.7500 ***\nskewness  0.0654232  0.7315 ***\nkurtosis  3.8008702  0.0357    \n\nSignif. codes:  H0 (normality of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mIndependence\u001b[22m\n                                        Statistic P.value    \nljung box                              27.5414156  0.1914 ***\nljung box (residuals at seasonal lags)  0.0000204  1.0000 ***\n\nSignif. codes: H0 (independence of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mLinearity\u001b[22m\n                               Statistic P.value  \nljung box (squared residuals) 42.8148107  0.0050  \n\nSignif. codes:  H0 (no conditional heteroscedasticity of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\nsummary(RF2932_init$regarima)\n\ny = regression model + arima (1, 1, 0, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-2004 to 10-2018\nLog-transformation: no\nRegression model: no mean, trading days effect(1), no leap year effect, no Easter effect, outliers(1)\n\nCoefficients:\nARIMA: \n          Estimate Std. Error T-stat Pr(>|t|)    \nPhi(1)     0.32715    0.07446  4.394 1.99e-05 ***\nBTheta(1) -0.42117    0.06825 -6.171 5.07e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n             Estimate Std. Error T-stat Pr(>|t|)    \nSemaine        2.5398     0.2233 11.374  < 2e-16 ***\nLS (11-2008) -23.0820     5.1897 -4.448 1.59e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 6.358 on 160 degrees of freedom\nLog likelihood = -540.5, aic =  1091, aicc =  1091, bic(corrected for length) = 3.823\n\nplot(get_ts(RF2932_init)) # schéma parait plutôt multiplicatif\n\n\n\nRF2932 <- x13(get_ts(RF2932_init),\n              x13_spec(RF2932_init,\n                       transform.function = \"Log\"))\n# critères d'information plus petits avec le modèle ARIMA final\nsummary(RF2932$regarima) \n\ny = regression model + arima (1, 1, 0, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-2004 to 10-2018\nLog-transformation: yes\nRegression model: no mean, trading days effect(1), no leap year effect, no Easter effect, outliers(2)\n\nCoefficients:\nARIMA: \n          Estimate Std. Error T-stat Pr(>|t|)    \nPhi(1)     0.28605    0.07630  3.749 0.000245 ***\nBTheta(1) -0.50935    0.06852 -7.434 5.44e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n              Estimate Std. Error T-stat Pr(>|t|)    \nSemaine       0.024030   0.001803 13.328  < 2e-16 ***\nAO (12-2008) -0.281493   0.036673 -7.676 1.37e-12 ***\nLS (11-2008) -0.236169   0.044617 -5.293 3.78e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.05084 on 159 degrees of freedom\nLog likelihood = 255.6, aic =  1037, aicc =  1038, bic(corrected for length) = -5.804\n\nRF2932$regarima$residuals.stat\n\n$st.error\n[1] 0.05083682\n\n$tests\n\n\u001b[1mNormality\u001b[22m\n         Statistic P.value    \nmean     -0.261613  0.7939 ***\nskewness  0.255684  0.1800 ***\nkurtosis  2.963556  0.9239 ***\n\nSignif. codes:  H0 (normality of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mIndependence\u001b[22m\n                                       Statistic P.value    \nljung box                              27.498876  0.1929 ***\nljung box (residuals at seasonal lags)  0.001761  0.9991 ***\n\nSignif. codes: H0 (independence of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mLinearity\u001b[22m\n                              Statistic P.value    \nljung box (squared residuals) 25.323509  0.2819 ***\n\nSignif. codes:  H0 (no conditional heteroscedasticity of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **"
  },
  {
    "objectID": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2813",
    "href": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2813",
    "title": "7 - Étude de cas",
    "section": "Série RF2813",
    "text": "Série RF2813\nL’analyse de cette série nécessite d’avoir vu les statistiques M qui jugent la qualité de la décomposition.\n\nIl y a un problème d’autocorrélation des résidus (au seuil de 1 %) et une mauvaise décomposition (Q-M2).\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nQue pensez-vous des outliers détectés ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLe problème d’autocorrélation peut être atténué en forçant le schéma additif (p-valeur du test est alors égale à 0,04).\nLa mauvaise décomposition vient du fait que la tendance est plate et donc que la composante irrégulière est plus variable que la composante tendance-cycle.\nDécision : forcer le schéma en additif."
  },
  {
    "objectID": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2223",
    "href": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2223",
    "title": "7 - Étude de cas",
    "section": "Série RF2223",
    "text": "Série RF2223\n\nIl y a un effet JO résiduel (au seuil de 5 % mais pas 1 %) et un problème d’hétéroscédasticité (au seuil de 5 % mais pas 1 %).\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nRéduire le seuil de détection des outliers pour voir ce qu’il se passe.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nDécision : Ajouter deux AO en 8-2007 et 7-2009.\nIl est préférable de rajouter les outliers à la main plutôt que de modifier de manière permanente le seuil de détection des outliers : cela évitera, pour les futures révisions du modèle,de détecter trop d’outliers.\n\n\n\nSolution sous R :\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nRF2223_init <- all_models$RF2223\nRF2223_init$regarima$residuals.stat\n\n$st.error\n[1] 4.832668\n\n$tests\n\n\u001b[1mNormality\u001b[22m\n         Statistic P.value    \nmean       0.05142  0.9591 ***\nskewness   0.12583  0.5093 ***\nkurtosis   3.32112  0.3998 ***\n\nSignif. codes:  H0 (normality of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mIndependence\u001b[22m\n                                       Statistic P.value    \nljung box                               21.21835  0.5073 ***\nljung box (residuals at seasonal lags)   2.79637  0.2470 ***\n\nSignif. codes: H0 (independence of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mLinearity\u001b[22m\n                              Statistic P.value  \nljung box (squared residuals)  34.60244  0.0426  \n\nSignif. codes:  H0 (no conditional heteroscedasticity of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\nsummary(RF2223_init$regarima)\n\ny = regression model + arima (0, 1, 1, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-2004 to 10-2018\nLog-transformation: no\nRegression model: no mean, trading days effect(1), no leap year effect, no Easter effect, no outliers\n\nCoefficients:\nARIMA: \n          Estimate Std. Error T-stat Pr(>|t|)    \nTheta(1)  -0.55547    0.06552 -8.478 1.24e-14 ***\nBTheta(1) -0.60519    0.06176 -9.799  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n        Estimate Std. Error T-stat Pr(>|t|)    \nSemaine   2.9836     0.2012  14.83   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 4.833 on 161 degrees of freedom\nLog likelihood =  -497, aic =  1002, aicc =  1002, bic(corrected for length) = 3.244\n\n# Pas d'effet JO résiduel sur l'ensemble de la série\nRF2223_init$diagnostics\n\n\u001b[1m Relative contribution of the components to the stationary\n portion of the variance in the original series,\n after the removal of the long term trend \u001b[22m\n Trend computed by Hodrick-Prescott filter (cycle length = 8.0 years)\n           Component\n Cycle         4.360\n Seasonal     93.060\n Irregular     1.509\n TD & Hol.     3.167\n Others        0.000\n Total       102.096\n\n\u001b[1m Combined test in the entire series \u001b[22m\n Non parametric tests for stable seasonality\n                                                          P.value\n   Kruskall-Wallis test                                      0.000\n   Test for the presence of seasonality assuming stability   0.000\n   Evolutive seasonality test                                0.863\n \n Identifiable seasonality present\n\n\u001b[1m Residual seasonality tests \u001b[22m\n                                      P.value\n qs test on sa                          1.000\n qs test on i                           1.000\n f-test on sa (seasonal dummies)        0.998\n f-test on i (seasonal dummies)         0.974\n Residual seasonality (entire series)   0.997\n Residual seasonality (last 3 years)    0.951\n f-test on sa (td)                      0.393\n f-test on i (td)                       0.228\n\n# Mais effet JO résiduel si test sur 8 dernières années\nc(RF2223_init$user_defined)\n\n$`diagnostics.td-sa-last`\n[1] 2.27703311 0.04330548\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.td-i-last`\n[1] 1.7146908 0.1268881\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.fcast-insample-mean`\n[1] 0.07557263 0.93986257\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-mean`\n[1] -0.05393521  0.95706052\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-variance`\n[1] 0.3837777 0.9891418\nattr(,\"description\")\n[1] \"F with 18 degrees of freedom in the nominator and 147 degrees of freedom in the denominator\"\n\nRF2223 <- x13(get_ts(RF2223_init),\n              x13_spec(RF2223_init,\n                       outlier.usedefcv = FALSE,\n                       outlier.cv = 2.8),\n              userdefined = u_def_var)\nsummary(RF2223$regarima)\n\ny = regression model + arima (0, 1, 1, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-2004 to 10-2018\nLog-transformation: no\nRegression model: no mean, trading days effect(1), no leap year effect, no Easter effect, outliers(2)\n\nCoefficients:\nARIMA: \n          Estimate Std. Error T-stat Pr(>|t|)    \nTheta(1)  -0.53904    0.06677 -8.074 1.35e-13 ***\nBTheta(1) -0.58038    0.06321 -9.181 2.22e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n            Estimate Std. Error T-stat Pr(>|t|)    \nSemaine       2.9411     0.1915 15.354  < 2e-16 ***\nAO (7-2009) -12.8787     3.6192 -3.558 0.000487 ***\nAO (4-2008)  10.6107     3.6656  2.895 0.004309 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 4.554 on 159 degrees of freedom\nLog likelihood = -486.9, aic = 985.8, aicc = 986.3, bic(corrected for length) = 3.187\n\n# Plus d'effet résiduel\nc(RF2223$user_defined)\n\n$`diagnostics.td-sa-last`\n[1] 2.10576592 0.06043949\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.td-i-last`\n[1] 1.6042176 0.1554087\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.fcast-insample-mean`\n[1] 0.1021795 0.9187544\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-mean`\n[1] -0.1043920  0.9170015\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-variance`\n[1] 0.4375446 0.9773708\nattr(,\"description\")\n[1] \"F with 18 degrees of freedom in the nominator and 147 degrees of freedom in the denominator\"\n\n# Pour rajouter les outliers à la main\nRF2223 <- x13(get_ts(RF2223_init),\n              x13_spec(RF2223_init,\n                       usrdef.outliersEnabled = TRUE,\n                       usrdef.outliersType = c(\"AO\", \"AO\"),\n                       usrdef.outliersDate = c(\"2008-04-01\", \"2009-07-01\")),\n              userdefined = u_def_var)\nsummary(RF2223$regarima)\n\ny = regression model + arima (0, 1, 1, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-2004 to 10-2018\nLog-transformation: no\nRegression model: no mean, trading days effect(1), no leap year effect, no Easter effect, outliers(2)\n\nCoefficients:\nARIMA: \n          Estimate Std. Error T-stat Pr(>|t|)    \nTheta(1)  -0.53904    0.06677 -8.074 1.35e-13 ***\nBTheta(1) -0.58038    0.06321 -9.181 2.22e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n            Estimate Std. Error T-stat Pr(>|t|)    \nSemaine       2.9411     0.1915 15.354  < 2e-16 ***\nAO (4-2008)  10.6107     3.6656  2.895 0.004309 ** \nAO (7-2009) -12.8787     3.6192 -3.558 0.000487 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 4.554 on 159 degrees of freedom\nLog likelihood = -486.9, aic = 985.8, aicc = 986.3, bic(corrected for length) = 3.187"
  },
  {
    "objectID": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2453-tc-or-not-tc",
    "href": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2453-tc-or-not-tc",
    "title": "7 - Étude de cas",
    "section": "Série RF2453 : TC or not TC",
    "text": "Série RF2453 : TC or not TC\n\nIl y a un effet JO résiduel (au seuil de 1 %).\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nQue pensez-vous des outliers détectés ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSupprimer la détection des TC permet de corriger le problème sur l’irrégulier mais pas sur la série désaisonnalisée.\nDécision : désactiver la détection automatique de TC.\n\n\n\nSolution sous R :\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nRF2453_init <- all_models$RF2453\nRF2453_init$regarima$residuals.stat\n\n$st.error\n[1] 6.241587\n\n$tests\n\n\u001b[1mNormality\u001b[22m\n         Statistic P.value    \nmean       -0.1815  0.8562 ***\nskewness    0.1955  0.3054 ***\nkurtosis    3.4186  0.2724 ***\n\nSignif. codes:  H0 (normality of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mIndependence\u001b[22m\n                                       Statistic P.value    \nljung box                                21.7413  0.4754 ***\nljung box (residuals at seasonal lags)    0.2928  0.8638 ***\n\nSignif. codes: H0 (independence of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mLinearity\u001b[22m\n                              Statistic P.value    \nljung box (squared residuals)   27.3760  0.1973 ***\n\nSignif. codes:  H0 (no conditional heteroscedasticity of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n# Pas d'effet JO résiduel sur l'ensemble de la série\nRF2453_init$diagnostics\n\n\u001b[1m Relative contribution of the components to the stationary\n portion of the variance in the original series,\n after the removal of the long term trend \u001b[22m\n Trend computed by Hodrick-Prescott filter (cycle length = 8.0 years)\n           Component\n Cycle         4.723\n Seasonal     67.834\n Irregular     1.409\n TD & Hol.     2.177\n Others       26.445\n Total       102.587\n\n\u001b[1m Combined test in the entire series \u001b[22m\n Non parametric tests for stable seasonality\n                                                          P.value\n   Kruskall-Wallis test                                      0.000\n   Test for the presence of seasonality assuming stability   0.000\n   Evolutive seasonality test                                0.023\n \n Identifiable seasonality present\n\n\u001b[1m Residual seasonality tests \u001b[22m\n                                      P.value\n qs test on sa                          1.000\n qs test on i                           1.000\n f-test on sa (seasonal dummies)        0.950\n f-test on i (seasonal dummies)         0.766\n Residual seasonality (entire series)   0.873\n Residual seasonality (last 3 years)    0.865\n f-test on sa (td)                      0.111\n f-test on i (td)                       0.126\n\n# Mais effet JO résiduel si test sur 8 dernières années\nc(RF2453_init$user_defined)\n\n$`diagnostics.td-sa-last`\n[1] 4.08882336 0.00115262\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.td-i-last`\n[1] 2.30323517 0.04113822\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.fcast-insample-mean`\n[1] -0.1593649  0.8736017\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-mean`\n[1] -0.06024667  0.95204157\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-variance`\n[1] 0.8067789 0.6900112\nattr(,\"description\")\n[1] \"F with 18 degrees of freedom in the nominator and 147 degrees of freedom in the denominator\"\n\n# Beaucoup de TC qui se suivent\nsummary(RF2453_init$regarima)\n\ny = regression model + arima (0, 1, 1, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-2004 to 10-2018\nLog-transformation: no\nRegression model: no mean, trading days effect(5), no leap year effect, no Easter effect, outliers(4)\n\nCoefficients:\nARIMA: \n          Estimate Std. Error T-stat Pr(>|t|)    \nTheta(1)  -0.47971    0.07151 -6.708 3.00e-10 ***\nBTheta(1) -0.47189    0.07333 -6.435 1.29e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n             Estimate Std. Error T-stat Pr(>|t|)    \nLundi          1.3390     0.6446  2.077   0.0393 *  \nMardi          3.8152     0.6722  5.676 6.08e-08 ***\nMercredi       2.8567     0.7156  3.992 9.85e-05 ***\nJeudi          3.5577     0.6930  5.134 7.91e-07 ***\nVendredi       1.4752     0.6674  2.210   0.0285 *  \nLS (10-2008) -26.6687     5.0893 -5.240 4.85e-07 ***\nTC (12-2008) -25.6542     5.3565 -4.789 3.70e-06 ***\nTC (2-2009)  -23.6203     5.1172 -4.616 7.83e-06 ***\nTC (8-2009)   20.5306     5.0996  4.026 8.63e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 6.242 on 153 degrees of freedom\nLog likelihood = -537.9, aic =  1100, aicc =  1102, bic(corrected for length) = 4.003\n\n# Pour rajouter les outliers à la main\nRF2453 <- x13(get_ts(RF2453_init),\n              x13_spec(RF2453_init,\n                       outlier.tc = FALSE),\n              userdefined = u_def_var)\nsummary(RF2453$regarima)\n\ny = regression model + arima (0, 1, 1, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-2004 to 10-2018\nLog-transformation: no\nRegression model: no mean, trading days effect(5), no leap year effect, no Easter effect, outliers(3)\n\nCoefficients:\nARIMA: \n          Estimate Std. Error T-stat Pr(>|t|)    \nTheta(1)  -0.46988    0.07192 -6.534 7.63e-10 ***\nBTheta(1) -0.52141    0.07201 -7.241 1.61e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n             Estimate Std. Error T-stat Pr(>|t|)    \nLundi          1.3860     0.6935  1.999 0.047291 *  \nMardi          3.4958     0.7243  4.826 3.15e-06 ***\nMercredi       3.0510     0.7672  3.977 0.000104 ***\nJeudi          3.4873     0.7332  4.756 4.28e-06 ***\nVendredi       1.6673     0.7111  2.345 0.020230 *  \nLS (10-2008) -25.4297     5.5004 -4.623 7.59e-06 ***\nLS (8-2009)   23.8545     5.2981  4.502 1.26e-05 ***\nLS (12-2008) -22.0810     5.5245 -3.997 9.66e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 6.623 on 154 degrees of freedom\nLog likelihood = -548.1, aic =  1118, aicc =  1120, bic(corrected for length) = 4.091\n\nc(RF2453$user_defined)\n\n$`diagnostics.td-sa-last`\n[1] 3.617642975 0.002968356\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.td-i-last`\n[1] 2.13370757 0.05725657\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.fcast-insample-mean`\n[1] -0.1399766  0.8888714\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-mean`\n[1] -0.07115003  0.94337572\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-variance`\n[1] 0.7524495 0.7517122\nattr(,\"description\")\n[1] \"F with 18 degrees of freedom in the nominator and 147 degrees of freedom in the denominator\""
  },
  {
    "objectID": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf1101",
    "href": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf1101",
    "title": "7 - Étude de cas",
    "section": "Série RF1101",
    "text": "Série RF1101\n\n\n\n\n\n\nExercice\n\n\n\nAnalyser les S-I ratios et le graphique yearly components de la série brute : que remarquez vous ?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nPour cette série, le modèle est estimé depuis 2004 mais les CVS-CJO ne sont mises à jour qu’à partir de 2012.\nIl y a une nette rupture de saisonnalité en 2008 qui n’affecte pas la période après 2012 (filtre M3X5 utilisé, soit pour l’estimation des coefficients saisonniers de l’année A utilise les moyennes de l’année A-3 à A+3). Ainsi, commencer l’estimation du modèle à partir de 2008 permet d’avoir un modèle de pré-ajustement mieux estimé sur le présent et la rupture de saisonnalité n’affectera pas les coefficients publiés.\nUne autre solution est de rajouter un seasonal outlier en août 2008"
  },
  {
    "objectID": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2561",
    "href": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2561",
    "title": "7 - Étude de cas",
    "section": "Série RF2561",
    "text": "Série RF2561\n\nIl y a de la saisonnalité résiduelle et une mauvaise qualité des résidus du modèle RegARIMA.\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nAnalyser la série sur la fin de la période pour voir d’où vient la saisonnalité résiduelle. Comment pourrait-on la corriger ? Est-ce qu’il s’agit d’une rupture brute ou progressive ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUne rupture de saisonnalité s’observe en juin 2011 : avant cette date juin était un point haut alors qu’à partir de 2011 il est au même niveau que les mois de mai et juillet. Ajout un SO à cette date corrige la rupture mais laisse une saisonnalité résiduelle qui vient du mois de décembre : on observe sur la série désaisonnalisée des pics systématiques en décembre sur les dernières années. Cette fois-ci ce n’est pas une rupture brute de la saisonnalité : le point de décembre qui était également un point haut avant 2011 devient progressivement de plus en plus bas. Le MSR de décembre (à 0,77) est d’ailleurs bien plus bas que celui des autres mois (qui sont autour de 2) ce qui suggère de prendre un filtre saisonnier plus court en décembre (le filtre actuellement choisi est M3X3). La mauvaise qualité des résidus est difficilement corrigeable, il faudrait prendre une période d’estimation beaucoup plus courtes qui ajouterait donc une instabilité des estimations. Décision : rajouter un SO en juin 2011 et utiliser le filtre M3X1 pour le mois de décembre. Pas d’intervention pour corriger la qualité des résidus."
  },
  {
    "objectID": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2530",
    "href": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf2530",
    "title": "7 - Étude de cas",
    "section": "Série RF2530 :",
    "text": "Série RF2530 :\n\nIl y a de la saisonnalité résiduelle (au seuil de 1 %), de l’hétéroscédasticité des résidus (au seuil de 5 %), une mauvaise décomposition (q-m2) et un problème sur la moyenne des erreurs de prévision (au seuil de 5 %).\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nAnalyser correctement le problème de saisonnalité résiduelle.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOn remarque entre juillet et août 2009 un changement de saisonnalité : ajouter un pure seasonal outlier (PSO) entre juillet et août 2009 permet de corriger la saisonnalité résiduelle, l’hétéroscédasticité mais pas la mauvaise décomposition et le problème sur la moyenne des erreurs de prévision.\n\n\n\nSolution sous R :\n\n# Il faut créer le PSO :\npso <- function(date_rupture1,\n                date_rupture2,\n                date_deb = 1990, date_fin = 2030, frequence = 12){\n    x <- ts(0,start=date_deb,end=date_fin,\n            frequency = frequence)\n    per_rupture1 <- as.numeric(cycle(window(x,start=date_rupture1,end=date_rupture1)))\n    per_rupture2 <- as.numeric(cycle(window(x,start=date_rupture2,end=date_rupture2)))\n    x[(cycle(x) == per_rupture1) & (time(x) < date_rupture1)] <- 1\n    x[(cycle(x) == per_rupture2) & (time(x) < date_rupture2)] <- -1\n    x\n}\npso_juil_aout2009 <- pso(2009+(7-1)/12,\n                         2009+(8-1)/12)\nplot(pso_juil_aout2009)\n\n\n\nRF2530 <- all_models$RF2530\nc(RF2530$user_defined)\n\n$`diagnostics.td-sa-last`\n[1] 1.3937951 0.2260685\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.td-i-last`\n[1] 0.9615718 0.4560279\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.fcast-insample-mean`\n[1] -0.001473487  0.998826339\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-mean`\n[1] -2.39348894  0.01795943\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-variance`\n[1] 1.4525592 0.1157818\nattr(,\"description\")\n[1] \"F with 18 degrees of freedom in the nominator and 147 degrees of freedom in the denominator\"\n\nRF2530 <- x13(get_ts(RF2530),\n              x13_spec(RF2530,\n                       usrdef.varEnabled = TRUE,\n                       usrdef.var = pso_juil_aout2009,\n                       usrdef.varType = \"Seasonal\"\n                       ),\n              userdefined = u_def_var)\nc(RF2530$user_defined)\n\n$`diagnostics.td-sa-last`\n[1] 2.77575446 0.01612013\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.td-i-last`\n[1] 1.8370673 0.1009677\nattr(,\"description\")\n[1] \"F with 6 degrees of freedom in the nominator and 88 degrees of freedom in the denominator\"\n\n$`diagnostics.fcast-insample-mean`\n[1] 1.0196171 0.3095967\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-mean`\n[1] -1.86986419  0.06350511\nattr(,\"description\")\n[1] \"T with 146 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-variance`\n[1] 1.2460664 0.2326639\nattr(,\"description\")\n[1] \"F with 18 degrees of freedom in the nominator and 147 degrees of freedom in the denominator\""
  },
  {
    "objectID": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf3299",
    "href": "2021/rte/TP/JD-7-Etude_de_cas.html#série-rf3299",
    "title": "7 - Étude de cas",
    "section": "Série RF3299",
    "text": "Série RF3299\n\nIl y a de la saisonnalité résiduelle.\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nAnalyser correctement le problème de saisonnalité résiduelle.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAjouter des SO en 10-2012 et 12-2015."
  },
  {
    "objectID": "2021/rte/TP/JD-7-Etude_de_cas.html#séries-c4672",
    "href": "2021/rte/TP/JD-7-Etude_de_cas.html#séries-c4672",
    "title": "7 - Étude de cas",
    "section": "Séries C4672",
    "text": "Séries C4672\n\n\n\n\n\n\nExercice\n\n\n\nDans cet exercice il y a deux séries à étudier : la série C4672 depuis 1999 et la même série mais estimée à partir de 2005.\n\nCommencez par la série qui commence en 1999. Comment vous parait le modèle ?\nAnalyser le modèle de la série qui commence en 2005 et comparer les résultats.\n\n\n\n\nSaisonnalité résiduelle non détectée pour modèle ensemble mais détectée si modèle coupé à partir de 2005.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAjouter un SO 11-2008."
  },
  {
    "objectID": "2021/rte/TP/JD-7-Etude_de_cas.html#série-c4773",
    "href": "2021/rte/TP/JD-7-Etude_de_cas.html#série-c4773",
    "title": "7 - Étude de cas",
    "section": "Série C4773",
    "text": "Série C4773\n\nSaisonnalité résiduelle détectée.\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nÉtudier les S-I ratio : la saisonnalité est-elle stable ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOn observe une saisonnalité plutôt stable sauf en juillet et août (étude des S-I ratio). Les S-I ratio montrent aussi en juillet et août un comportement « atypique » de l’irrégulier en début de période. On n’observe pas de changement brusque de saisonnalité. L’étude des MSR par mois suggère de prendre un filtre plus court en juillet et en août : cela permet de corriger la saisonnalité résiduelle."
  },
  {
    "objectID": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html",
    "href": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html",
    "title": "0 - Traitement des séries temporelles sous R",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à manipuler les séries temporelles sous R en utilisant les packages de bases.\nDans R il existe de nombreux packages qui permettent de manipuler les séries temporelles. Pour n’en citer que quelques-uns :\n- Les objets ts peuvent être créés à partir du package stats ;\n- Les objets zoo peuvent être créés à partir du package zoo ;\n- Les objets xts peuvent être créés à partir du package xts ;\n- Les objets tis peuvent être créés à partir du package tseries ;\n- Les objets tsibble peuvent être créés à partir du package tsibble.\ntsbox permet quand à lui de facilement passer d’une classe à l’autre.\nIci nous nous concentrerons essentiellement sur les trois premiers : ts stocker les séries temporelles, zoo et xts pour effectuer certaines manipulations supplémentaires."
  },
  {
    "objectID": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html#création-dune-série-temporelle",
    "href": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html#création-dune-série-temporelle",
    "title": "0 - Traitement des séries temporelles sous R",
    "section": "Création d’une série temporelle",
    "text": "Création d’une série temporelle\nLa fonction ts() permet de créer des objets séries-temporelles à partir un vecteur (ou une matrice). La syntaxe de base est ts(vector, start=, end=, frequency=) où start et end sont la première et la dernière observation, frequency est le nombre d’observations par unité de temps (1=annuelle, 2=semestrielle, 4=trimestrielle, 6=bi-mestrielle, 12=mensuelle, etc.).\nPar exemple pour créer une série trimestrielle ayant les valeurs de 1 à 10 et commençant en 1959Q2 :\n\nts(1:10, frequency = 4, start = c(1959, 2)) # 2ème trimestre de 1959\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1959         1    2    3\n1960    4    5    6    7\n1961    8    9   10     \n\n# Équivalent à \nts(1:10, frequency = 4, start = 1959 + 1/4)\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1959         1    2    3\n1960    4    5    6    7\n1961    8    9   10     \n\n\nOn peut aussi définir l’objet à partir de sa date de fin :\n\nts(1:10, frequency = 4, end = c(1959, 2))\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1957    1    2    3    4\n1958    5    6    7    8\n1959    9   10          \n\n\nSi l’on directement extraire un sous-ensemble de la série on peut spécifier les paramètres end et start. Par exemple pour ne garder que les valeurs jusqu’en 1960 inclus :\n\nts(1:10, frequency = 4, start = c(1959, 2), end = c(1960, 4))\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1959         1    2    3\n1960    4    5    6    7\n\n\nOu alors utiliser la fonction window une fois l’objet créé :\n\nts_object <- ts(1:10, frequency = 4, start = c(1959, 2))\nwindow(ts_object, end = c(1960, 4))\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1959         1    2    3\n1960    4    5    6    7\n\n\nOn peut récupérer les différents attributs avec les fonctions start(), end() et frequency() :\n\nstart(ts_object)\n\n[1] 1959    2\n\nend(ts_object)\n\n[1] 1961    3\n\nfrequency(ts_object)\n\n[1] 4\n\n\nDeux autres fonctions peuvent aussi être utiles : time() crée un série-temporelle à partir des dates de notre série-temporelle et cycle() donne la position dans le cycle de chaque observation.\n\ntime(ts_object)\n\n        Qtr1    Qtr2    Qtr3    Qtr4\n1959         1959.25 1959.50 1959.75\n1960 1960.00 1960.25 1960.50 1960.75\n1961 1961.00 1961.25 1961.50        \n\ncycle(ts_object)\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1959         2    3    4\n1960    1    2    3    4\n1961    1    2    3     \n\n\n\n\n\n\n\n\nExercice\n\n\n\nExtraire toutes les données du 2ème trimestre de l’objet ts_object\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nts_object[cycle(ts_object) == 2]\n\n[1] 1 5 9\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nCréer une série temporelle mensuelle qui commence en 2000, qui se termine en janvier 2020, qui vaut 1 en avril 2009 et 0 à toutes les autres dates\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nindicatrice <- ts(0, start = 2000, end = 2020, frequency = 12)\nwindow(indicatrice, start = c(2005, 4), end = c(2005, 4)) <- 1\nindicatrice\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2000   0   0   0   0   0   0   0   0   0   0   0   0\n2001   0   0   0   0   0   0   0   0   0   0   0   0\n2002   0   0   0   0   0   0   0   0   0   0   0   0\n2003   0   0   0   0   0   0   0   0   0   0   0   0\n2004   0   0   0   0   0   0   0   0   0   0   0   0\n2005   0   0   0   1   0   0   0   0   0   0   0   0\n2006   0   0   0   0   0   0   0   0   0   0   0   0\n2007   0   0   0   0   0   0   0   0   0   0   0   0\n2008   0   0   0   0   0   0   0   0   0   0   0   0\n2009   0   0   0   0   0   0   0   0   0   0   0   0\n2010   0   0   0   0   0   0   0   0   0   0   0   0\n2011   0   0   0   0   0   0   0   0   0   0   0   0\n2012   0   0   0   0   0   0   0   0   0   0   0   0\n2013   0   0   0   0   0   0   0   0   0   0   0   0\n2014   0   0   0   0   0   0   0   0   0   0   0   0\n2015   0   0   0   0   0   0   0   0   0   0   0   0\n2016   0   0   0   0   0   0   0   0   0   0   0   0\n2017   0   0   0   0   0   0   0   0   0   0   0   0\n2018   0   0   0   0   0   0   0   0   0   0   0   0\n2019   0   0   0   0   0   0   0   0   0   0   0   0\n2020   0                                            \n\n\n\n\n\nPour tracer un graphique il suffit maintenant d’utiliser les fonctions plot() et lines()\n\nplot(ts_object * 2)\nlines(ts_object, col = \"red\")"
  },
  {
    "objectID": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html#séries-multivariées",
    "href": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html#séries-multivariées",
    "title": "0 - Traitement des séries temporelles sous R",
    "section": "Séries multivariées",
    "text": "Séries multivariées\nDe la même façon que précédemment on peut créer une série temporelle multivariée. Cette fois-ci l’objet créé est à la fois mts, ts et matrix\n\nmts <- ts(matrix(rnorm(300), 100, 3), start = c(1961, 1), frequency = 12)\n\nOn peut accéder à la première variable de la même façon que dans une matrice : par son nom ou son numéro de colonne :\n\ncolnames(mts)\n\n[1] \"Series 1\" \"Series 2\" \"Series 3\"\n\n# mts[,1] # ou de façon équivalente :\nmts[, \"Series 1\"]\n\n             Jan         Feb         Mar         Apr         May         Jun\n1961  0.48457656 -0.35498297 -4.07604013 -0.94818736  0.49777745  0.83790218\n1962 -0.59378326 -0.12329912  0.14425366 -1.87033256  2.07358714 -0.79759979\n1963 -1.32728072  0.43801327  0.27269378  0.50397756 -0.71284225 -0.28389309\n1964 -0.65843830 -1.23378701 -0.10760678  0.23627752  0.27659537  0.87856469\n1965 -0.16224075 -1.38098691 -0.84078131 -0.57084346  0.24409719  1.32974484\n1966 -0.12101717 -0.71629919  0.70740582  0.27336550  0.47031910 -2.14256903\n1967  0.49154784 -0.46248882  1.53373504  1.69799441 -1.35614340  0.81509954\n1968  1.46840899 -0.28817877 -0.05167282 -0.05508327 -0.75298834 -0.35390815\n1969 -0.98758474  1.23111712 -1.06354431 -1.68894505                        \n             Jul         Aug         Sep         Oct         Nov         Dec\n1961  1.00576280 -0.08247037 -0.70366556 -0.26087010  1.04846904 -1.71825380\n1962  0.22070799  1.01982402  0.53763430 -1.02860299 -0.61588759  1.56678439\n1963 -0.84023146  1.39245730 -0.11318523 -1.47566125 -0.48108957 -1.29835261\n1964  0.07445877 -0.56883127  0.60440919 -0.65243419  0.98461073 -2.47754589\n1965  0.88815020  1.72164040 -1.30703847  0.28122870 -0.49543356  1.08880197\n1966  3.24831138  1.01697072  1.42221349 -1.13667101 -1.23098253  0.48852850\n1967 -1.54316150  0.57076612  0.40654318  0.10156154  0.12003689  0.55890502\n1968  0.97194091  0.05395929 -1.45792337 -0.16589613 -1.35823982 -0.26852694\n1969                                                                        \n\n\nEt avec les même fonctions que pour les matrices on peut récupérer les noms des colonnes (colnames), le nombre de variables (ncol), etc.\n\n\n\n\n\n\nAttention\n\n\n\nUne source classique d’erreur est de manipuler des séries-temporelles uni et multivariées et de vouloir utiliser les fonctions liées aux matrices sur les séries univariées. Par exemple, colnames(ts_object) renverra toujours l’objet NULL. Une solution est de tester si l’objet est multivarié avec la fonction is.mts()."
  },
  {
    "objectID": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html#manipulation-basiques",
    "href": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html#manipulation-basiques",
    "title": "0 - Traitement des séries temporelles sous R",
    "section": "Manipulation basiques",
    "text": "Manipulation basiques\nPour concaténer plusieurs séries temporelles, les fonctions deux fonctions suivantes peuvent ts.union() et ts.intersect().\n\nts_object2 <- ts(1:10, frequency = 4, start = c(1960, 1))\nts.union(ts_object, ts_object2) # on garde toute la couverture temporelle en rajoutant des NA\n\n        ts_object ts_object2\n1959 Q2         1         NA\n1959 Q3         2         NA\n1959 Q4         3         NA\n1960 Q1         4          1\n1960 Q2         5          2\n1960 Q3         6          3\n1960 Q4         7          4\n1961 Q1         8          5\n1961 Q2         9          6\n1961 Q3        10          7\n1961 Q4        NA          8\n1962 Q1        NA          9\n1962 Q2        NA         10\n\nts.intersect(ts_object, ts_object2) # on ne garde que les périodes communes\n\n        ts_object ts_object2\n1960 Q1         4          1\n1960 Q2         5          2\n1960 Q3         6          3\n1960 Q4         7          4\n1961 Q1         8          5\n1961 Q2         9          6\n1961 Q3        10          7\n\n\nOn va maintenant utiliser la série d’indice de production industrielle de la France (CVS-CJO) :\n\nipi_fr_manuf <- ts(c(94.2, 96.69, 95.66, 95.06, 95.96, 93.97, 94.16, 93.4, \n94.12, 94.29, 92.42, 93.01, 94.98, 93.31, 93.76, 93.06, 91.93, \n93.41, 91.68, 92.98, 93.42, 92.39, 93.74, 92.69, 93.12, 92.57, \n93.49, 92.59, 92.85, 91.74, 91.23, 91.53, 90.08, 90.47, 89.97, \n88.44, 88.66, 87.86, 87.38, 87.42, 87.14, 86.24, 87.67, 86.86, \n87.2, 87.68, 85.93, 86.25, 88.14, 87.71, 88.21, 89.59, 90.38, \n90.76, 91.67, 92.18, 91.79, 93.02, 94.54, 94.04, 94.17, 94.56, \n93.94, 94.29, 93.59, 94.34, 94.79, 94.04, 94.62, 93.51, 92.59, \n94.9, 93.89, 93.19, 94.19, 93.67, 95.19, 94.72, 92.82, 95.49, \n95.13, 94.21, 95.42, 95.34, 94.39, 96.09, 97.14, 100.02, 97.84, \n98.59, 98.72, 102.9, 100.51, 103.23, 100.91, 103.1, 103.21, 103.76, \n102.15, 103.37, 104.98, 104.21, 105.32, 102.65, 104.34, 104.07, \n104.39, 103.62, 104.75, 103.36, 103.8, 104.89, 105.49, 106.69, \n106.91, 104.6, 107.76, 109.36, 109.26, 108.33, 109.12, 109.6, \n110.2, 110.81, 112.57, 110.92, 112.15, 110.86, 111.53, 112.75, \n112.67, 114.3, 113.32, 114.09, 114.65, 112.12, 113.06, 113.27, \n111.34, 114.36, 111.94, 112.04, 109.81, 110.12, 110.98, 111.91, \n112.23, 112.86, 111.23, 111.13, 109.96, 112.59, 110.62, 109.69, \n111.26, 108.05, 110.05, 110.39, 110.92, 110.7, 107.72, 107.26, \n109.22, 108.78, 108.66, 110.62, 108.8, 109.42, 110.12, 111.6, \n110.61, 111, 110.22, 111.69, 112.3, 107.68, 111.92, 112.66, 110.38, \n110.74, 113.16, 111.04, 108.72, 112, 110.35, 110.3, 110.21, 109.04, \n112.63, 109.26, 113.55, 112.07, 111.16, 110.64, 112.98, 111.54, \n114.46, 114.28, 112.29, 111.52, 113.52, 112.84, 112.1, 114.24, \n113.24, 114.18, 114.73, 113.28, 115.9, 114.88, 115.04, 115.72, \n112.57, 115.17, 113.71, 113.82, 115.29, 116.48, 114.36, 116.12, \n111.24, 110.64, 111.49, 109.8, 109.25, 107.21, 100.8, 99.34, \n94.87, 93.66, 92.19, 92.2, 93.49, 95.23, 94.71, 96.27, 97.09, \n96.3, 97.66, 96.56, 97.12, 96.6, 98.78, 98.7, 99.27, 99.03, 99.69, \n98.63, 99.98, 99.7, 100.82, 101.79, 104.09, 105.03, 103.59, 102.21, \n105.56, 101.55, 103.08, 101.93, 101.22, 101.5, 104.35, 102.1, \n101.05, 100.14, 101.87, 100.16, 99.79, 99.16, 100.01, 101.92, \n100.11, 97.66, 97.59, 99.12, 98.02, 98.55, 98.78, 100.31, 100.31, \n99.64, 98.56, 98.37, 98.54, 99.16, 100.35, 99.27, 98.24, 99.95, \n99.43, 99.53, 96.53, 99.06, 100.11, 98.2, 99.17, 97.91, 96.93, \n99.45, 99.02, 99.38, 99.74, 99.38, 100.85, 100.02, 98.66, 100.22, \n101.23, 100.64, 99.94, 100.92, 102.39, 100.8, 99.54, 100.73, \n99.76, 99.07, 99.77, 101.63, 100.4, 99.4, 102.76, 100.97, 100.16, \n101.11, 102.62, 101.82, 103.7, 103.02, 103.59, 103.54, 104.38, \n105.57, 105.52, 105.93, 103.59, 102.87, 103.82, 103.83, 102.5, \n104.23, 104.04, 104.61, 103.38, 104.22, 103.42, 103.7, 104.93, \n105.75, 104.38, 104.29, 105.98, 103.72, 104.07, 103.1, 103.88, \n104.37), start = 1990, frequency = 12)\n\nPour calculer la série retardée/avancée, il suffit d’utiliser la fonction lag() :\n\n# série retardée d'un mois : en février 2010 on a la valeur de janvier 2010\nlag(ipi_fr_manuf, k = -1) \n\nLa fonction diff permet de calculer la différence entre deux périodes\n\ndiff(ipi_fr_manuf, k = 1)\n\n\n\n\n\n\n\nExercice\n\n\n\nÉcrire une fonction ev() qui calcule l’évolution mensuelle si la série en entrée est mensuelle, l’évolution trimestrielle si la série en entrée est trimestrielle, etc.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nev <- function(x){\n  result <- (x/lag(x, k = -1) - 1) * 100\n  return(result)\n}\n# Ou de manière équivalente :\nev2 <- function(x){\n  # Attention ici c'est bien k = 1 dans la fonction diff\n  # et k = -1 dans la fonction lag\n  result <- (diff(x, k = 1) /lag(x, k = -1)) * 100\n  return(result)\n}\n\n#################################################\n# Remarque : pour des raisons informatiques ces deux fonctions ne donnent pas exactement\n# le même résultat. C'est un problème récurrent lorsque l'on\n# souhaite tester l'égalité entre deux séries temporelles :\nall (ev(ipi_fr_manuf) == ev2(ipi_fr_manuf))\n\n[1] FALSE\n\n# Une solution est plutôt d'utiliser la fonction all.equal():\nisTRUE(all.equal(ev(ipi_fr_manuf), ev2(ipi_fr_manuf)))\n\n[1] TRUE"
  },
  {
    "objectID": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html#utilisation-de-xts",
    "href": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html#utilisation-de-xts",
    "title": "0 - Traitement des séries temporelles sous R",
    "section": "Utilisation de xts",
    "text": "Utilisation de xts\nUn des avantages du package xts est qu’il permet d’appliquer une fonction à chaque période d’une série temporelle (par exemple à toutes les données trimestrielles, annuelles, etc.). Il s’agit des fonctions apply.monthly(), apply.quarterly(), apply.yearly(), etc. Pour cela il faut auparavant convertir les données au format xts.\n\nPar exemple pour calculer la moyenne annuelle :\n\nlibrary(xts)\nmoy_an <- apply.yearly(as.xts(ipi_fr_manuf), mean)\nmoy_an\n\n              [,1]\ndéc 1990  94.41167\ndéc 1991  93.11250\ndéc 1992  91.50667\ndéc 1993  87.19083\ndéc 1994  91.00250\ndéc 1995  94.11167\ndéc 1996  94.43833\ndéc 1997  99.45333\ndéc 1998 103.83917\ndéc 1999 106.26667\ndéc 2000 111.45667\ndéc 2001 112.51000\ndéc 2002 111.04250\ndéc 2003 109.37833\ndéc 2004 110.91000\ndéc 2005 111.02750\ndéc 2006 112.63083\ndéc 2007 114.35333\ndéc 2008 110.16833\ndéc 2009  95.01917\ndéc 2010  99.17583\ndéc 2011 103.01750\ndéc 2012  99.88167\ndéc 2013  99.15500\ndéc 2014  98.70917\ndéc 2015 100.00000\ndéc 2016 100.60167\ndéc 2017 103.41333\ndéc 2018 103.68417\noct 2019 104.44700\n\n\n\n\n\n\n\n\nExercice\n\n\n\nCalculer l’évolution trimestrielle de ipi_fr_manuf.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Tout d'abord on prolonge l'IPI par des valeurs manquantes jusqu'à la fin \n# de l'année, sinon la dernière somme sur le trimestre est fausse.\nipi_fr_manuf_prolonge <- window(ipi_fr_manuf, end = c(2019, 12), extend = TRUE)\n\nsomme_trim <- apply.quarterly(as.xts(ipi_fr_manuf_prolonge), sum)\n# Attention la fonction lag n'agit pas pareil pour les objets xts et ts :\n# il faut ici utiliser l'option k = 1\nevol_trim <- (somme_trim/lag(somme_trim, k = 1) - 1) * 100\n\n# On peut utiliser la fonction format() \n# si l'on veut convertir automatiquement en un objet ts\nstart_year <- as.numeric(format(start(evol_trim), \"%Y\"))\nstart_quarter <- as.numeric(substr(quarters(start(evol_trim)), 2, 2))\nts(evol_trim, start = c(start_year, start_quarter), frequency = 4)\n\n            Qtr1        Qtr2        Qtr3        Qtr4\n1990          NA -0.54440761 -1.16144426 -0.69582505\n1991  0.83297583 -1.29409679 -0.11494253  0.26611047\n1992  0.12911556 -0.71638370 -1.56576954 -1.45140009\n1993 -1.85212734 -1.17468738  0.35659509 -0.71447675\n1994  1.61625491  2.52594107  1.81361504  2.16224060\n1995  0.37997159 -0.15919624  0.43583020 -0.86434997\n1996  0.09608541  0.82127493 -0.04936878  0.53979678\n1997  0.92992245  3.07002295  1.91600607  1.69132493\n1998  0.61189949  1.11283644 -0.07998464 -0.07364478\n1999 -0.05447321  1.65432336  0.69385309  2.40548752\n2000  0.60253861  1.63565609  0.07179180  1.54839481\n2001  0.68880254 -1.05537040 -0.23932634 -1.67930340\n2002  0.94888092  0.02984006 -0.61153869 -1.25161329\n2003  0.71732523 -1.71414775  0.30090887  0.66736056\n2004  1.06130641  0.17452532 -0.30338530  0.56643567\n2005 -0.25765474 -0.08110056 -0.23147452  0.90394118\n2006 -0.02986144  1.64286994 -0.86693311  0.54842439\n2007  0.87564125  0.55823469 -0.21217230 -0.18349693\n2008  1.00087540 -2.34882847 -2.20710059 -7.01579234\n2009 -8.66438913  0.07124537  2.54520860  0.85048773\n2010  0.68153656  1.53846154  0.43771044  1.34428428\n2011  3.44017730 -1.08407150 -0.99896547  0.56166933\n2012 -1.58792012 -1.30337227  0.97957273 -2.53939876\n2013  0.33291436  1.66243440 -1.59528409  1.12024909\n2014 -0.38824553 -0.83999731  0.79967471 -1.07234100\n2015  1.30823338  0.70772120 -0.04662781  0.46316351\n2016  0.40796020 -1.04713771  0.74776339  0.44068920\n2017  0.25071751  1.53015894  0.96259804  1.76880357\n2018 -2.12604883  0.09024107  0.47333849 -0.22113258\n2019  1.19483523 -0.33961785 -0.93633555          NA"
  },
  {
    "objectID": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html#utilisation-de-zoo",
    "href": "2021/rte/TP/R-0-Traitement_des_series_temporelles.html#utilisation-de-zoo",
    "title": "0 - Traitement des séries temporelles sous R",
    "section": "Utilisation de zoo",
    "text": "Utilisation de zoo\nLe package zoo donne un ensemble d’outils qui permettent de manipuler les séries-temporelles. De nombreux packages (dont xts) sont d’ailleurs basés sur ce format. Il permet notamment de faire des imputations de données manquantes selon différentes fonctions (toutes les fonctions commençant par na.) et de mieux gérer le format des dates associées aux séries temporelles (ce qui permet de faire des manipulations avec la fonction format, ce qui permet par exemple plus facilement exporter des séries temporelles sous Excel). Le calcul de l’évolution trimestrielle aurait par exemple pu être faite avec ce package :\n\nsomme_trim <- aggregate(as.zoo(ipi_fr_manuf_prolonge), yearqtr, sum)\nsomme_trim <- as.ts(somme_trim) #La conversion en ts est plus simple depuis un objet zoo\nevol_trim <- ev(somme_trim)\nevol_trim\n\n            Qtr1        Qtr2        Qtr3        Qtr4\n1990             -0.54440761 -1.16144426 -0.69582505\n1991  0.83297583 -1.29409679 -0.11494253  0.26611047\n1992  0.12911556 -0.71638370 -1.56576954 -1.45140009\n1993 -1.85212734 -1.17468738  0.35659509 -0.71447675\n1994  1.61625491  2.52594107  1.81361504  2.16224060\n1995  0.37997159 -0.15919624  0.43583020 -0.86434997\n1996  0.09608541  0.82127493 -0.04936878  0.53979678\n1997  0.92992245  3.07002295  1.91600607  1.69132493\n1998  0.61189949  1.11283644 -0.07998464 -0.07364478\n1999 -0.05447321  1.65432336  0.69385309  2.40548752\n2000  0.60253861  1.63565609  0.07179180  1.54839481\n2001  0.68880254 -1.05537040 -0.23932634 -1.67930340\n2002  0.94888092  0.02984006 -0.61153869 -1.25161329\n2003  0.71732523 -1.71414775  0.30090887  0.66736056\n2004  1.06130641  0.17452532 -0.30338530  0.56643567\n2005 -0.25765474 -0.08110056 -0.23147452  0.90394118\n2006 -0.02986144  1.64286994 -0.86693311  0.54842439\n2007  0.87564125  0.55823469 -0.21217230 -0.18349693\n2008  1.00087540 -2.34882847 -2.20710059 -7.01579234\n2009 -8.66438913  0.07124537  2.54520860  0.85048773\n2010  0.68153656  1.53846154  0.43771044  1.34428428\n2011  3.44017730 -1.08407150 -0.99896547  0.56166933\n2012 -1.58792012 -1.30337227  0.97957273 -2.53939876\n2013  0.33291436  1.66243440 -1.59528409  1.12024909\n2014 -0.38824553 -0.83999731  0.79967471 -1.07234100\n2015  1.30823338  0.70772120 -0.04662781  0.46316351\n2016  0.40796020 -1.04713771  0.74776339  0.44068920\n2017  0.25071751  1.53015894  0.96259804  1.76880357\n2018 -2.12604883  0.09024107  0.47333849 -0.22113258\n2019  1.19483523 -0.33961785 -0.93633555          NA\n\n\nPour le prochain exercice, utiliser la série suivante :\n\nserie_avec_NA <- ts(c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, 0, 0, 0, \n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, \n  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \n  NA, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, NA, NA, NA, NA, NA, \n  NA, NA, NA, NA, NA, NA), start= 2000, frequency = 12)\n\n\n\n\n\n\n\nExercice\n\n\n\nSur la série serie_avec_NA, utiliser les différentes fonctions du package zoo pour : 1. Enlever les valeurs manquantes au début de la série ; 2. Remplacer les valeurs manquantes à la fin de la série par la dernière valeur observée. 3. Interpoler de manière linéaire les valeurs manquantes entre les 0 et les 1.\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nLes trois fonctions à utiliser sont : na.trim(), na.locf et na.approx()\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# D'abord on enlève les valeurs manquantes au début de la série\netape_1 <- na.trim(serie_avec_NA, sides = \"left\")\netape_1\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2001   0   0   0   0   0   0   0   0   0   0   0   0\n2002   0   0   0   0   0   0   0   0   0   0   0   0\n2003  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n2004  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n2005   1   1   1   1   1   1   1   1   1   1   1   1\n2006   1   1   1   1   1   1   1   1   1   1   1   1\n2007  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n\n# Ensuite on interpole\netape_2 <- na.approx(etape_1, na.rm = FALSE)\netape_2\n\n      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n2001 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2002 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2003 0.04 0.08 0.12 0.16 0.20 0.24 0.28 0.32 0.36 0.40 0.44 0.48\n2004 0.52 0.56 0.60 0.64 0.68 0.72 0.76 0.80 0.84 0.88 0.92 0.96\n2005 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n2006 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n2007   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n\n# Enfin on remplace les valeurs à la fin de la série\netape_3 <- na.locf(etape_2)\netape_3\n\n      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n2001 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2002 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2003 0.04 0.08 0.12 0.16 0.20 0.24 0.28 0.32 0.36 0.40 0.44 0.48\n2004 0.52 0.56 0.60 0.64 0.68 0.72 0.76 0.80 0.84 0.88 0.92 0.96\n2005 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n2006 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n2007 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nÀ l’aide des fonctions as.yearmon() et format(), créer un data.frame contenant une colonne “date” qui contient les dates au format JJ/MM/YYYY et une deuxième colonnes avec les valeurs de ipi_fr_manuf.\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nLa fonction as.yearmon() doit être appliquée sur time(ipi_fr_manuf). Pour la fonction format regarder l’aide ?format.Date.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndates <- as.yearmon(time(ipi_fr_manuf))\ndates <- format(dates, \"%d/%m/%Y\")\ndonnees_formatees <- data.frame(date = dates, ipi = ipi_fr_manuf)\nhead(donnees_formatees)\n\n        date   ipi\n1 01/01/1990 94.20\n2 01/02/1990 96.69\n3 01/03/1990 95.66\n4 01/04/1990 95.06\n5 01/05/1990 95.96\n6 01/06/1990 93.97\n\n\n\n\n\nIl peut également être utile d’exporter un objet R ts ou mts vers un fichier Excel, tout en rajoutant une colonne “date” qui sera au format date. Ci-dessous un exemple en utilisant le package XLConnect :\n\nlibrary(XLConnect)\nts2xls <- function(x, file, sheet=\"Feuille 1\", format = \"dd/mm/yyyy\"){\n  wb <- loadWorkbook(file, create = TRUE)\n  createSheet(wb, sheet)\n  if(is.mts(x)){\n    col <- c(\"date\", colnames(x))\n  }else{\n    col <- c(\"date\", \"x\")\n  }\n  # Le titre\n  writeWorksheet(wb,matrix(col,nrow = 1),\n                 sheet = sheet,startCol = 1,startRow =1,\n                 header = FALSE)\n\n  # Petit trick pour que la colonne date soit au format date d'Excel\n  csDate <- getOrCreateCellStyle(wb, name = \"date\")\n  setDataFormat(csDate, format = format)\n  date <- as.Date(format(zoo::as.Date((time(x))), \"%d/%m/%Y\"),\n                  \"%d/%m/%Y\")\n  writeWorksheet(wb,date,sheet = sheet,\n                 startCol = 1,startRow = 2,\n                 header = FALSE)\n  setCellStyle(wb, sheet = sheet, row = seq_along(date)+1,\n               col = 1,\n               cellstyle = csDate)\n  # Fin colonne date\n\n  # Autres colonnes\n  writeWorksheet(wb,x,sheet = sheet,startCol = 2,startRow = 2,\n                 header = FALSE)\n  setColumnWidth(wb, sheet, column = seq_along(col), width = -1)\n  saveWorkbook(wb, file)\n}"
  },
  {
    "objectID": "2021/rte/TP/R-1-R_et_JD.html",
    "href": "2021/rte/TP/R-1-R_et_JD.html",
    "title": "1 - R et JDemetra+",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à manipuler JDemetra+ sous R à travers le package RJDemetra.\nPour manipuler JDemetra+ sous R il y a actuellement deux façons :\nDans ce TP on utilisera les données du package RJDemetra mais n’hésitez pas à utiliser vos propres séries, en utilisant par exemple le code ci-dessous :\nSi besoin, ci-dessous un exemple de code pour récupérer vos données :"
  },
  {
    "objectID": "2021/rte/TP/R-1-R_et_JD.html#créer-une-specification",
    "href": "2021/rte/TP/R-1-R_et_JD.html#créer-une-specification",
    "title": "1 - R et JDemetra+",
    "section": "Créer une specification",
    "text": "Créer une specification\nDans les prochains exercices, la série utilisée sera ipi_c_eu[, \"FR\"] qui est l’IPI français. Vous pouvez bien sûr adapter le code pour utiliser vos propres séries. Les fonctions utilisées seront x13(), x13_spec(), regarima_x13, regarima_x13_spec ou regarima. Le détail des spécifications pré-définies par JDemetra+ sont disponibles ici.\n\n\n\n\n\n\nExercice\n\n\n\nFaire la désaisonnalisation d’une série avec X-13 avec la spécification suivante :\n\ndétection automatique du schéma de décomposition, des outliers et du modèle ARIMA\nune correction des jours ouvrables “working days” et un effet graduel de Pâques\n\nFaire ensuite un graphique avec la série brute et la série désaisonnalisée.\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nUtiliser la spécification RSA4c pour la désaisonnalisation.\nSi le modèle créé s’appelle mysa, regarder les valeurs de mysa$final, mysa$final$series et mysa$final$forecasts.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmysa <- x13(ipi_c_eu[, \"FR\"], spec = \"RSA4c\")\nmysa\n\n\u001b[4m\u001b[1mRegARIMA\u001b[22m\u001b[24m\ny = regression model + arima (2, 1, 1, 0, 1, 1)\nLog-transformation: no\nCoefficients:\n          Estimate Std. Error\nPhi(1)     0.05291      0.108\nPhi(2)     0.18672      0.074\nTheta(1)  -0.52137      0.103\nBTheta(1) -0.66132      0.042\n\n             Estimate Std. Error\nWeek days      0.6927      0.031\nLeap year      2.0903      0.694\nEaster [1]    -2.5476      0.442\nTC (4-2020)  -35.6481      2.092\nAO (3-2020)  -21.1492      2.122\nAO (5-2011)   13.1869      1.810\nLS (11-2008)  -9.2744      1.758\nLS (1-2009)   -7.2838      1.756\n\n\nResidual standard error: 2.193 on 346 degrees of freedom\nLog likelihood = -795.1, aic =  1616 aicc =  1617, bic(corrected for length) = 1.767\n\n\n\n\u001b[4m\u001b[1mDecomposition\u001b[22m\u001b[24m\n\u001b[1m Monitoring and Quality Assessment Statistics: \u001b[22m \n      M stats\nM(1)    0.127\nM(2)    0.079\nM(3)    1.094\nM(4)    0.558\nM(5)    1.093\nM(6)    0.022\nM(7)    0.085\nM(8)    0.242\nM(9)    0.064\nM(10)   0.261\nM(11)   0.247\nQ       0.355\nQ-M2    0.389\n\nFinal filters: \nSeasonal filter:  3x5\nTrend filter:  13 terms Henderson moving average\n\n\n\u001b[4m\u001b[1mFinal\u001b[22m\u001b[24m\nLast observed values\n             y        sa        t           s           i\nJan 2020 101.0 102.87273 103.0457  -1.8727280  -0.1730003\nFeb 2020 100.1 103.69025 103.0626  -3.5902540   0.6276448\nMar 2020  91.8  82.69170 103.2654   9.1083000 -20.5736602\nApr 2020  66.7  66.55184 103.6945   0.1481625 -37.1426277\nMay 2020  73.7  79.28883 104.1379  -5.5888279 -24.8490764\nJun 2020  98.2  87.35362 104.4539  10.8463757 -17.1002284\nJul 2020  97.4  92.26057 104.5518   5.1394323 -12.2912806\nAug 2020  71.7  97.54392 104.3369 -25.8439193  -6.7929846\nSep 2020 104.7  97.75728 103.8361   6.9427184  -6.0788659\nOct 2020 106.7  97.87016 103.1969   8.8298396  -5.3267823\nNov 2020 101.6 100.01475 102.6601   1.5852540  -2.6453446\nDec 2020  96.6  99.61740 102.4081  -3.0173983  -2.7907314\n\nForecasts:\n               y_f     sa_f      t_f         s_f        i_f\nJan 2021  94.29728 101.0937 102.3876  -6.7963909 -1.2939310\nFeb 2021  97.89298 101.6869 102.4525  -3.7939488 -0.7655396\nMar 2021 113.65190 102.1478 102.4593  11.5041248 -0.3115701\nApr 2021 102.34532 102.1806 102.3419   0.1647274 -0.1612727\nMay 2021  96.14552 101.6436 102.1712  -5.4980759 -0.5276194\nJun 2021 112.15785 101.2156 102.0241  10.9422549 -0.8085520\nJul 2021 104.38495 101.5439 101.9635   2.8410057 -0.4195241\nAug 2021  79.02901 102.3820 102.0412 -23.3530134  0.3408366\nSep 2021 109.40288 102.3705 102.1977   7.0323700  0.1728109\nOct 2021 108.22472 101.8558 102.3655   6.3689511 -0.5096780\nNov 2021 106.22014 102.4265 102.5266   3.7936049 -0.1000754\nDec 2021  99.67523 102.9462 102.6812  -3.2709156  0.2649189\n\n\n\u001b[4m\u001b[1mDiagnostics\u001b[22m\u001b[24m\n\u001b[1m Relative contribution of the components to the stationary\n portion of the variance in the original series,\n after the removal of the long term trend \u001b[22m\n Trend computed by Hodrick-Prescott filter (cycle length = 8.0 years)\n           Component\n Cycle         1.830\n Seasonal     51.089\n Irregular     0.927\n TD & Hol.     2.179\n Others       44.916\n Total       100.941\n\n\u001b[1m Combined test in the entire series \u001b[22m\n Non parametric tests for stable seasonality\n                                                          P.value\n   Kruskall-Wallis test                                      0.000\n   Test for the presence of seasonality assuming stability   0.000\n   Evolutive seasonality test                                0.014\n \n Identifiable seasonality present\n\n\u001b[1m Residual seasonality tests \u001b[22m\n                                      P.value\n qs test on sa                          0.924\n qs test on i                           0.643\n f-test on sa (seasonal dummies)        0.671\n f-test on i (seasonal dummies)         0.453\n Residual seasonality (entire series)   0.415\n Residual seasonality (last 3 years)    0.954\n f-test on sa (td)                      0.091\n f-test on i (td)                       0.333\n\n\n\u001b[4m\u001b[1mAdditional output variables\u001b[22m\u001b[24m\n\ny <- mysa$final$series[,\"y\"]\n# De façon équivalente :\ny <- get_ts(mysa)\nsa <- mysa$final$series[,\"sa\"]\nplot(y)\nlines(sa, col = \"red\")\n\n\n\n# ou on peut directement utiliser les fonctions de RJDemetra :\nplot(mysa, first_date = 2000, #Pour n'afficher le graphique qu'à partir de 200\n     type_chart = \"sa-trend\" # Pour faire le graphique avec y, sa et tendance\n     )\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nModifier le modèle précédent pour enlever l’effet graduel de Pâques.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nspec_sans_easter <- x13_spec(mysa,\n                 easter.enabled = FALSE)\nmysa2 <- x13(ipi_c_eu[, \"FR\"], spec_sans_easter)\nmysa2$regarima\n\ny = regression model + arima (2, 1, 0, 0, 1, 1)\nLog-transformation: no\nCoefficients:\n          Estimate Std. Error\nPhi(1)      0.5392      0.051\nPhi(2)      0.3055      0.051\nBTheta(1)  -0.6907      0.041\n\n             Estimate Std. Error\nWeek days      0.6949      0.036\nLeap year      2.0370      0.734\nTC (4-2020)  -37.5412      2.286\nAO (3-2020)  -20.6096      2.234\nAO (5-2011)   12.6737      1.898\nLS (11-2008)  -9.8861      1.884\n\n\nResidual standard error: 2.376 on 349 degrees of freedom\nLog likelihood = -824.2, aic =  1668 aicc =  1669, bic(corrected for length) = 1.878\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nCalculer les p-valeurs associées au modèle Reg-ARIMA de la précédente spécification\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nRécupérer le modèle Reg-ARIMA et utiliser la fonction summary().\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsummary(mysa2$regarima)\n\ny = regression model + arima (2, 1, 0, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-1990 to 12-2020\nLog-transformation: no\nRegression model: no mean, trading days effect(2), leap year effect, no Easter effect, outliers(4)\n\nCoefficients:\nARIMA: \n          Estimate Std. Error  T-stat Pr(>|t|)    \nPhi(1)     0.53923    0.05103  10.567  < 2e-16 ***\nPhi(2)     0.30555    0.05096   5.996 4.92e-09 ***\nBTheta(1) -0.69072    0.04077 -16.942  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n              Estimate Std. Error  T-stat Pr(>|t|)    \nWeek days      0.69490    0.03592  19.346  < 2e-16 ***\nLeap year      2.03702    0.73355   2.777  0.00577 ** \nTC (4-2020)  -37.54123    2.28584 -16.423  < 2e-16 ***\nAO (3-2020)  -20.60960    2.23446  -9.224  < 2e-16 ***\nAO (5-2011)   12.67365    1.89818   6.677 9.30e-11 ***\nLS (11-2008)  -9.88611    1.88424  -5.247 2.65e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 2.376 on 349 degrees of freedom\nLog likelihood = -824.2, aic =  1668, aicc =  1669, bic(corrected for length) = 1.878"
  },
  {
    "objectID": "2021/rte/TP/R-1-R_et_JD.html#créer-un-workspace",
    "href": "2021/rte/TP/R-1-R_et_JD.html#créer-un-workspace",
    "title": "1 - R et JDemetra+",
    "section": "Créer un workspace",
    "text": "Créer un workspace\nDans cette partie nous allons créer un workspace depuis R. Pour cela les fonctions qui peuvent être utilisées sont new_workspace(), load_workspace(), new_multiprocessing(), add_sa_item(), save_workspace(), compute(), get_object(), get_name(), get_ts() ou count().\n\n\n\n\n\n\nExercice\n\n\n\nCréer un workspace qui va contenir une série désaisonnalisée selon 3 spécifications différentes.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nwk <- new_workspace()\nnew_multiprocessing(wk, \"MP-1\")\nadd_sa_item(wk, \"MP-1\", mysa, \"X13 avec Pâques\")\nadd_sa_item(wk, \"MP-1\", mysa2, \"X13 sans Pâques\")\nadd_sa_item(wk, \"MP-1\", tramoseats(ipi_c_eu[, \"FR\"]), \"TRAMO-SEATS\")\nsave_workspace(wk, \"mon_premier_workspace.xml\")\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nImporter le workspace précédent et récupérer :\n\nLe nom du premier multi-processing\nLe nombre de modèles dans ce premier multi-processing\nL’ensemble des séries brutes\nLe 2ème modèle\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nwk <- load_workspace(\"mon_premier_workspace.xml\")\ncompute(wk)\ncount(wk) # Nombre de multiprocessing\n\n[1] 1\n\nmp1 <- get_object(wk, 1) # Le premier multiprocessing\nget_name(mp1)\n\n[1] \"MP-1\"\n\ncount(mp1)\n\n[1] 3\n\nall_y <- get_ts(mp1) # toutes les séries brutes\nmodel2 <- get_object(mp1, 2) # On récupère l'objet associé au 2ème modèle\nget_model(model2, wk)\n\n\u001b[4m\u001b[1mRegARIMA\u001b[22m\u001b[24m\ny = regression model + arima (2, 1, 0, 0, 1, 1)\nLog-transformation: no\nCoefficients:\n          Estimate Std. Error\nPhi(1)      0.5392      0.051\nPhi(2)      0.3055      0.051\nBTheta(1)  -0.6907      0.041\n\n             Estimate Std. Error\nWeek days      0.6949      0.036\nLeap year      2.0370      0.734\nTC (4-2020)  -37.5412      2.286\nAO (3-2020)  -20.6096      2.234\nAO (5-2011)   12.6737      1.898\nLS (11-2008)  -9.8861      1.884\n\n\nResidual standard error: 2.376 on 349 degrees of freedom\nLog likelihood = -824.2, aic =  1668 aicc =  1669, bic(corrected for length) = 1.878\n\n\n\n\u001b[4m\u001b[1mDecomposition\u001b[22m\u001b[24m\n\u001b[1m Monitoring and Quality Assessment Statistics: \u001b[22m \n      M stats\nM(1)    0.118\nM(2)    0.070\nM(3)    1.020\nM(4)    0.207\nM(5)    1.020\nM(6)    0.023\nM(7)    0.086\nM(8)    0.252\nM(9)    0.061\nM(10)   0.272\nM(11)   0.253\nQ       0.311\nQ-M2    0.341\n\nFinal filters: \nSeasonal filter:  3x5\nTrend filter:  13 terms Henderson moving average\n\n\n\u001b[4m\u001b[1mFinal\u001b[22m\u001b[24m\nLast observed values\n             y        sa        t          s            i\nJan 2020 101.0 103.05492 103.1535  -2.054924  -0.09860242\nFeb 2020 100.1 103.97044 103.3561  -3.870443   0.61433677\nMar 2020  91.8  83.16842 103.7741   8.631582 -20.60564584\nApr 2020  66.7  65.39235 104.3888   1.307651 -38.99644727\nMay 2020  73.7  79.05610 104.9443  -5.356103 -25.88818063\nJun 2020  98.2  87.34635 105.2787  10.853649 -17.93233952\nJul 2020  97.4  92.32900 105.3035   5.070997 -12.97447645\nAug 2020  71.7  97.65388 104.9547 -25.953878  -7.30080299\nSep 2020 104.7  97.79183 104.3028   6.908172  -6.51098097\nOct 2020 106.7  98.05499 103.5029   8.645008  -5.44786549\nNov 2020 101.6 100.05993 102.7928   1.540069  -2.73284988\nDec 2020  96.6  99.61720 102.3254  -3.017195  -2.70816560\n\nForecasts:\n               y_f     sa_f      t_f        s_f         i_f\nJan 2021  93.67792 100.6889 102.0697  -7.010962 -1.38078701\nFeb 2021  97.04844 101.0898 101.9241  -4.041334 -0.83433350\nMar 2021 111.88132 100.9504 101.7890  10.930954 -0.83859394\nApr 2021 102.97429 101.6532 101.6187   1.321079  0.03446852\nMay 2021  95.75042 100.9289 101.4711  -5.178523 -0.54218868\nJun 2021 111.64361 100.7014 101.3832  10.942225 -0.68178140\nJul 2021 103.72617 100.9095 101.3791   2.816690 -0.46959728\nAug 2021  78.33366 101.7966 101.4826 -23.462988  0.31407100\nSep 2021 108.80554 101.8094 101.6406   6.996129  0.16879596\nOct 2021 107.51641 101.3617 101.8118   6.154729 -0.45007973\nNov 2021 105.56463 101.8129 101.9805   3.751742 -0.16757433\nDec 2021  99.16008 102.4165 102.1319  -3.256419  0.28462277\n\n\n\u001b[4m\u001b[1mDiagnostics\u001b[22m\u001b[24m\n\u001b[1m Relative contribution of the components to the stationary\n portion of the variance in the original series,\n after the removal of the long term trend \u001b[22m\n Trend computed by Hodrick-Prescott filter (cycle length = 8.0 years)\n           Component\n Cycle         2.807\n Seasonal     67.429\n Irregular     1.369\n TD & Hol.     2.572\n Others       26.609\n Total       100.786\n\n\u001b[1m Combined test in the entire series \u001b[22m\n Non parametric tests for stable seasonality\n                                                          P.value\n   Kruskall-Wallis test                                      0.000\n   Test for the presence of seasonality assuming stability   0.000\n   Evolutive seasonality test                                0.035\n \n Identifiable seasonality present\n\n\u001b[1m Residual seasonality tests \u001b[22m\n                                      P.value\n qs test on sa                          1.000\n qs test on i                           0.983\n f-test on sa (seasonal dummies)        0.556\n f-test on i (seasonal dummies)         0.392\n Residual seasonality (entire series)   0.714\n Residual seasonality (last 3 years)    0.997\n f-test on sa (td)                      0.015\n f-test on i (td)                       0.146\n\n\n\u001b[4m\u001b[1mAdditional output variables\u001b[22m\u001b[24m"
  },
  {
    "objectID": "2021/rte/TP/R-1-R_et_JD.html#manipuler-les-objets-java",
    "href": "2021/rte/TP/R-1-R_et_JD.html#manipuler-les-objets-java",
    "title": "1 - R et JDemetra+",
    "section": "Manipuler les objets Java",
    "text": "Manipuler les objets Java\nL’objectif de cette partie est de manipuler la fonction jx13() pour gagner en temps de calcul.\n\n\n\n\n\n\nExercice\n\n\n\nCréer un modèle à partir de la fonction jx13() et la spécification sans effet graduel de pâques calculée dans une des sections précédentes.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmyjsa <- jx13(ipi_c_eu[, \"FR\"], spec_sans_easter)\nget_indicators(myjsa, \"sa\")\n\n$sa\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n1990  93.26192  95.28210  94.72427  93.79807  93.58689  92.90669  94.21534\n1991  93.60604  92.28757  92.61612  92.18918  87.68624  94.66893  92.29891\n1992  91.60322  92.03867  92.44368  92.10173  91.13355  90.57461  89.27557\n1993  87.95635  87.66799  86.42064  86.77045  87.29414  86.83820  86.72890\n1994  89.25920  87.64515  87.99068  89.29768  91.17636  91.48283  90.76570\n1995  95.23894  94.20432  93.92823  93.97688  92.23570  91.96366  93.79453\n1996  93.19519  92.59312  93.85781  93.16482  91.35090  94.69040  94.14381\n1997  93.28048  95.67111  94.47884 101.83691  96.60488  98.43983  98.24606\n1998 102.20545 103.13141 101.62413 102.96106 103.60058 102.33459 103.79731\n1999 103.76472 102.74795 103.70819 104.16562 106.06980 107.71979 105.66106\n2000 110.06944 109.17177 110.14375 109.79371 114.82438 106.83213 110.32456\n2001 112.62576 113.20381 114.26307 110.62964 111.94532 111.54071 112.09929\n2002 110.40192 110.92422 110.77613 111.86170 107.96491 110.99208 111.34867\n2003 108.82396 109.69598 109.30218 110.11139 106.05417 104.24931 108.98362\n2004 108.86061 110.87940 110.17711 110.71582 111.15572 112.82616 111.54792\n2005 113.95584 110.83848 106.38000 114.36016 113.60201 111.15980 109.25001\n2006 112.56654 110.40119 112.72819 111.48283 114.36479 113.05862 111.30270\n2007 112.81233 113.99272 114.79256 113.11564 112.78587 115.81567 116.41861\n2008 114.51052 115.76727 111.07812 119.37532 111.27702 111.22352 111.98724\n2009  94.36527  93.88381  91.33972  93.06359  94.74364  93.50699  94.26196\n2010  96.26416  96.64089  98.58551  99.22953 102.29301 100.37051  99.13683\n2011 104.89593 104.99950 104.38147 102.29292 114.79067  97.53951 101.38411\n2012 102.79898 100.28989 101.70648  99.91410  98.86265 100.22038 101.40031\n2013  97.44981  98.68330  97.59979 100.48643  99.33341  99.94008 100.18739\n2014  98.06608 100.13701  98.50695  99.67278  97.97852  97.02262  98.47425\n2015  98.46074  99.49526  99.43802  99.15803  98.66745 101.76119  96.60888\n2016 101.43823 100.61673  96.76938 102.88879 103.36442 100.25266  96.45526\n2017 102.87251 101.24167 102.96195 100.57813 104.44045 101.24441 100.13568\n2018 103.43616 102.91552 103.90301 103.66953  99.87362 104.85129 104.60709\n2019 105.67633 106.32086 105.23475 105.75330 105.93573 100.22658 105.01869\n2020 103.05492 103.97044  83.16842  65.39235  79.05610  87.34635  92.32900\n           Aug       Sep       Oct       Nov       Dec\n1990  92.40895  93.48122  93.44382  92.20500  90.35429\n1991  92.42568  92.21783  92.03596  91.99483  90.56914\n1992  93.41716  89.52944  89.56159  89.94821  88.20834\n1993  89.35112  86.64602  86.78198  84.01598  87.23752\n1994  91.48403  91.09236  91.80621  92.72059  95.22335\n1995  92.44329  93.93017  92.68054  93.31657  94.36201\n1996  94.60521  93.92616  93.60896  93.74495  93.25051\n1997 101.62786  99.72790 102.47571 100.76052 101.84404\n1998 103.61016 103.82358 103.12835 104.35209 102.99943\n1999 105.48958 107.49426 107.98066 107.34122 110.18481\n2000 109.20510 111.02251 111.62295 113.49313 113.65263\n2001 112.99097 110.90319 111.23285 110.60945 107.42627\n2002 111.58435 109.50461 109.48479 110.07986 105.97585\n2003 108.64535 108.35322 110.34772 109.44870 108.12960\n2004 110.49232 112.28445 111.70451 109.01379 111.81955\n2005 110.18106 113.13185 108.23681 112.06914 113.39639\n2006 112.20573 113.51381 112.45401 112.71426 112.63676\n2007 114.37634 112.41341 116.16812 113.65633 111.15318\n2008 109.84715 109.52683 108.13030  99.75502  99.31542\n2009 100.17498  97.48713  97.00543  96.82694  95.52096\n2010 100.93712 100.28494 100.14540  98.36527 102.46107\n2011 101.46901 101.52124 101.92153 102.44468 103.38051\n2012 101.34382  99.58022  98.33652  98.54055  97.28724\n2013  97.83959  97.75148 100.17718  98.33999  97.88808\n2014  98.04084  99.40280  98.43145  97.16129  99.15030\n2015 102.41622 101.56240 100.63622 100.72218 100.58640\n2016 101.13931 100.63261  98.27976 100.78665 102.95168\n2017 102.75336 103.61452 105.27554 106.80320 105.60590\n2018 103.92286 102.68056 105.22113 105.28450 104.33286\n2019 102.42566 104.61463 105.51990 102.22427 102.74974\n2020  97.65388  97.79183  98.05499 100.05993  99.61720\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nToujours avec la même spécification, extraire les révisions de la séries désaisonnalisée du point de janvier 2005 (i.e. : série désaisonnalisée lorsqu’on a les données jusqu’en janvier 2005, puis jusqu’en février 2005, etc.).\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nRécupérer l’ensemble des dates de fin d’estimation avec la fonction window(time(ipi_c_eu[, \"FR\"]), start = 2005).\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndates <- window(time(ipi_c_eu[, \"FR\"]), start = 2005)\nestimations <- sapply(dates, function(last_date_estimation){\n  myjsa <- jx13(window(ipi_c_eu[, \"FR\"], end = last_date_estimation), spec_sans_easter)\n  sa <- get_indicators(myjsa, \"sa\")$sa\n  window(sa, start = 2005, end = 2005) # Pour ne récupérer que la valeur en 2005\n})\nestimations <- ts(estimations, start = 2005, frequency = 12)\nplot(estimations)\n\n\n\n\n\n\n\n\n# | include: false\nfile.remove(\"mon_premier_workspace.xml\")\n\n[1] TRUE\n\nunlink(\"mon_premier_workspace\", recursive = TRUE)"
  },
  {
    "objectID": "2021/rte/TP/R-2-CJO.html",
    "href": "2021/rte/TP/R-2-CJO.html",
    "title": "2 - Correction des jours ouvrables",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à créer des régresseurs jours ouvrables personnalisés, à les utiliser dans RJDemetra/JDemetra+ et à vérifier la qualité de la correction.\nPour créer des régresseurs jours ouvrables personnalisés, deux solutions :\nDans ce TP, nous nous intéresserons uniquement à la seconde option. En effet, le package R est plus flexible et permet de créer des régresseurs moins classiques que les working days et trading days.\nCet énoncé a été préparé avec la version 0.5.0 des packages rjd3toolkit et rjd3modelling: dans les nouvelles versions, les noms des fonctions peuvent être différents. Pour installer cette version, vous pouvez utiliser le code suivante :\nSi besoin, ci-dessous un exemple de code pour récupérer vos données :"
  },
  {
    "objectID": "2021/rte/TP/R-2-CJO.html#création-dun-calendrier",
    "href": "2021/rte/TP/R-2-CJO.html#création-dun-calendrier",
    "title": "2 - Correction des jours ouvrables",
    "section": "Création d’un calendrier",
    "text": "Création d’un calendrier\nPar défaut, les régresseurs jours ouvrables de JDemetra+ ne prennent pas en compte les spécificité calendaires des pays : on ne prend pas en compte les jours fériés. Pour les prendre en compte, il faut créer son propre calendrier où l’on supposera qu’un jour férié de plus dans le mois a le même effet qu’un dimanche.\nUn nouveau calendrier avec la fonction calendar.new()\n\nlibrary(rjd3modelling)\nfrenchCalendar <- calendar.new()\n\nTrois fonctions peuvent être utilisées pour ajouter des jours fériés :\n\ncalendar.fixedday() pour ajouter un jour férié qui tombe à date fixe. Par exemple, pour ajouter le 8 mai :\n\n\ncalendar.fixedday(frenchCalendar, month =  5,\n                  day = 8)\n\n\ncalendar.easter() pour ajouter un jour férié dont le jour dépend de Pâques : le paramètre offset permet de spécifier le nombre de jours avant (si négatif) ou après Pâques (si positif). Par exemple, pour ajouter la Pentecôte qui a lieu 60 jours après Pâques :\n\n\ncalendar.easter(frenchCalendar,\n                offset = 60)\n\n\ncalendar.holiday() qui permet d’ajouter des jours fériés par rapport à des dates déjà connues dans JDemetra+ (voir tableau ci-dessous). Comme pour la fonction calendar.easter(), le paramètre offset permet de spécifier la position du jour voulu par rapport rapport à la fête pré-spécifié (par défaut offset = 0, le jour férié coïncide avec le jour pré-spécifié). Par exemple, pour ajouter le nouvel an :\n\n\ncalendar.holiday(frenchCalendar, \"NEWYEAR\")\n\n\n\n\n\nJours pré-spécifiés\n \n  \n    Event \n    Définition \n  \n \n\n  \n    NEWYEAR \n    Fête fixe, 1er janvier. \n  \n  \n    SHROVEMONDAY \n    Fête mobile, lundi avant le mecredi des cendres (48 jours avant pâques). \n  \n  \n    SHROVETUESDAY \n    Fête mobile, mardi avant le mecredi des cendres (47 jours avant pâques). \n  \n  \n    ASHWEDNESDAY \n    Fête mobile, 46 jours avant Pâques. \n  \n  \n    EASTER \n    Fête mobile, Pâques, varie entre le 22 mars et le 25 avril. \n  \n  \n    MAUNDYTHURSDAY \n    Fête mobile, le jeudi avant Pâques. \n  \n  \n    GOODFRIDAY \n    Fête mobile, le vendredi avant Pâques. \n  \n  \n    EASTERMONDAY \n    Fête mobile, le lendemain de Pâques. \n  \n  \n    ASCENSION \n    Fête mobile, célébrée un jeudi, 40 jours après Pâques. \n  \n  \n    PENTECOST \n    Fête mobile, 50 jours après Pâques. \n  \n  \n    CORPUSCHRISTI \n    Fête mobile, 60 jours après Pâques. \n  \n  \n    WHITMONDAY \n    Fête mobile, le jour après la Pentecôte. \n  \n  \n    MAYDAY \n    Fête fixe, 1er mai. \n  \n  \n    ASSUMPTION \n    Fête fixe, 15 août. \n  \n  \n    HALLOWEEN \n    Fête fixe, 31 octobre. \n  \n  \n    ALLSAINTSDAY \n    Fête fixe, 1er novembre. \n  \n  \n    ARMISTICE \n    Fête fixe, 11 novembre. \n  \n  \n    CHRISTMAS \n    Fête fixe, 25 décembre. \n  \n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nCréer un calendrier qui contient tous les jours fériés de la France.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nfrenchCalendar <- calendar.new()\ncalendar.holiday(frenchCalendar, \"NEWYEAR\")\ncalendar.holiday(frenchCalendar, \"EASTERMONDAY\") # Lundi de Pâques\ncalendar.holiday(frenchCalendar, \"MAYDAY\") # 1er mai\ncalendar.fixedday(frenchCalendar, 5, 8)\ncalendar.holiday(frenchCalendar, \"WHITMONDAY\") # Lundi de Pentecôte\ncalendar.fixedday(frenchCalendar, 7, 14)\ncalendar.holiday(frenchCalendar, \"ASSUMPTION\") # Assomption\ncalendar.holiday(frenchCalendar, \"ALLSAINTSDAY\") # Toussaint\ncalendar.holiday(frenchCalendar, \"ARMISTICE\")"
  },
  {
    "objectID": "2021/rte/TP/R-2-CJO.html#création-de-régresseurs-jo",
    "href": "2021/rte/TP/R-2-CJO.html#création-de-régresseurs-jo",
    "title": "2 - Correction des jours ouvrables",
    "section": "Création de régresseurs JO",
    "text": "Création de régresseurs JO\nLe modèle général de correction de jours ouvrables peut s’écrire de la façon suivante : \\[\nX_t = \\sum_{i=1}^{7} \\alpha_i N_{it} + \\varepsilon_t\n\\] Avec :\n\n\\(N_{it}\\) le nombre de jours de lundis (\\(i=1\\)), …, dimanches et jours fériés (\\(i=7\\))\n\\(\\alpha_i\\) l’effet d’un jour de type \\(i\\)\n\nPour éviter les problèmes de multi-colinéarité, on réécrit le modèle en utilisant une modalité de référence (ici dimanche). On désaisonnalise également les régresseurs en enlevant la moyenne de long-terme : \\[X_t =  \\sum_{i=1}^{6} \\beta_i (N_{it} - N_{7t}) +\n\\bar{\\alpha} \\underbrace{(N_t - \\bar{N}_t)}_{LY_t} +  \\varepsilon_t\\] Ce modèle peut être simplifié si en faisant des hypothèses sur les effets des jours ouvrés :\n\nL’hypothèse working days correspond au cas où l’on suppose que tous les jours de la semaine (lundi à vendredi) ont le même effet (\\(\\alpha_1=\\dots=\\alpha_5\\)), les samedis et les dimanches (et jours fériés) ont le même effet (\\(\\alpha_6=\\alpha_7\\)) et sont utilisés en tant que variable de contraste.\nL’hypothèse trading days correspond au cas où l’on suppose que tous les jours ont un effet différent et les dimanches (et jours fériés) sont utilisés en tant que variable de constrate.\n\nSous JDemetra+ on ne peut utiliser que ces deux hypothèses mais rjd3modelling permet de construire d’autres types de J0.\nDe manière plus générale, lorsque l’on utilise une variable de contraste, les régresseurs \\(CJO_{t,i}\\) associé au groupe \\(i\\) est calculé de la façon suivante : \\[\nCJO_{t,i} = \\underbrace{\\sum_{j\\in\\text{groupe }i}N_{jt}}_{\n\\text{nb de jours du groupe }i\n} -\n\\frac{\\sum_{j\\in\\text{groupe }i}1}{\\sum_{j\\in\\text{groupe }0}1}\n\\times\n\\underbrace{\\sum_{j\\in\\text{groupe }0}N_{jt}}_{\n\\text{nb de jours du groupe contraste}\n}\n\\] Dans le cas working days, il y a 2 jours dans le groupe contraste (samedi et dimanche, \\(\\sum_{j\\in\\text{groupe }0}1=2\\)) et 5 jours dans le groupe 1 (lundi à vendredi, \\(\\sum_{j\\in\\text{groupe }1}1=5\\)). Au mois \\(t\\), le régresseurs JO type de jours est donc égal au nombre de jours de la semaine dans le mois, mois \\(5/2\\times\\) nombre de jours de week-end.\nLes régresseurs J0 peuvent être créés à partir de 2 fonctions : htd() qui permet de les créer à partir d’un calendrier spécifique et td(). Dans ces fonctions, le paramètre le plus important est groups pour permet de faire des hypothèses sur les jours. C’est un vecteur de longueur 7 (le nombre de jours de la semaine) dont chaque élément indique à quel groupe le jour de la semaine associé correspond. La variable de contraste est associé au groupe 0.\nPar exemple, groups = c(1,2,3,4,5,6,0) correspond au trading days et groups = c(1,1,1,1,1,0,0) correspond au working days.\nPar exemple :\n\ngroups <- c(1, 2, 3, 4, 5, 6, 0)\nfrequency <- 12\nstart <- c(2000,1)\nwkd <- htd(frenchCalendar, frequency = frequency, start = start, length = 12*35,\n         groups = groups)\nwkd <- ts(wkd, start = start, frequency = frequency)\n\n\n\n\n\n\n\nExercice\n\n\n\nComparer le régresseurs JO working days créé avec le calendrier français et celui sans hypothèse sur les jours fériés (fonction td()).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngroups <- c(1, 1, 1, 1, 1, 0, 0)\nfrequency <- 12\nstart <- c(2000,1)\nwkd <- htd(frenchCalendar, frequency = frequency, start = start, length = 12*35,\n         groups = groups)\nwkd <- ts(wkd, start = start, frequency = frequency)\nwkd_def <- td(frequency = frequency, start = start, length = 12*35,\n         groups = groups)\nwkd_def <- ts(wkd_def, start = start, frequency = frequency)\ndata <- ts.union(wkd, wkd_def)\nplot(data, col = c(\"orange\",\"black\"),\n     plot.type = \"single\")"
  },
  {
    "objectID": "2021/rte/TP/R-2-CJO.html#régresseur-leap-year",
    "href": "2021/rte/TP/R-2-CJO.html#régresseur-leap-year",
    "title": "2 - Correction des jours ouvrables",
    "section": "Régresseur leap year",
    "text": "Régresseur leap year\nLe régresseur année bissextile (leap year), \\(LY_t\\) doit être créé à la main. Il est égal à la différence entre le nombre de jours dans le mois \\(t\\) et le nombre de jours moyens dans le mois \\(t\\), \\(\\bar N_t\\). Tous les mois ont le même nombre de jours, sauf le mois de février qui est de 29 jours tous les 4 ans. \\(\\bar N_t\\) est donc égal à 30 ou 31 si le mois considéré n’est pas un mois de février (et donc \\(N_t - \\bar N_t=0\\)) à 28,25 en février1. \\[\nLY_{t} =\n\\begin{cases}\n  0,75 & \\mbox{si } t \\mbox{ est un mois de février bissextil } \\\\\n  -0,25 & \\mbox{si } t \\mbox{ est un mois de février non bissextil } \\\\\n  0 & \\mbox{sinon}\n\\end{cases}\n\\]\n\n\n\n\n\n\nExercice\n\n\n\nCréer une fonction leap_year qui permet de générer le régresseur leap year.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nleap_year <- function(start = 1990, end = 2030, frequency = 12){\n  ly <- ts(0, start = start, end = end, frequency = 12)\n  mois_feb <- cycle(ly) == 2\n  annees <- trunc(round(time(ly), 3)) # arrondi car parfois des pbs avec fonction time\n  # On utilise la définition exacte\n  is_ly <- (annees %% 400 == 0) |\n    ((annees %% 4 == 0) & (annees %% 100 != 0))\n  ly[mois_feb] <- 28 - 28.2425\n  ly[mois_feb & is_ly] <- 29 - 28.2425\n  # on change si besoin la fréquence\n  stats::aggregate(ly, nfrequency = frequency) \n}\nleap_year(frequency = 12)\n\n         Jan     Feb     Mar     Apr     May     Jun     Jul     Aug     Sep\n1990  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n1991  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n1992  0.0000  0.7575  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n1993  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n1994  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n1995  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n1996  0.0000  0.7575  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n1997  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n1998  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n1999  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2000  0.0000  0.7575  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2001  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2002  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2003  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2004  0.0000  0.7575  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2005  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2006  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2007  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2008  0.0000  0.7575  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2009  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2010  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2011  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2012  0.0000  0.7575  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2013  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2014  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2015  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2016  0.0000  0.7575  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2017  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2018  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2019  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2020  0.0000  0.7575  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2021  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2022  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2023  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2024  0.0000  0.7575  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2025  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2026  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2027  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2028  0.0000  0.7575  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2029  0.0000 -0.2425  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n2030  0.0000                                                                \n         Oct     Nov     Dec\n1990  0.0000  0.0000  0.0000\n1991  0.0000  0.0000  0.0000\n1992  0.0000  0.0000  0.0000\n1993  0.0000  0.0000  0.0000\n1994  0.0000  0.0000  0.0000\n1995  0.0000  0.0000  0.0000\n1996  0.0000  0.0000  0.0000\n1997  0.0000  0.0000  0.0000\n1998  0.0000  0.0000  0.0000\n1999  0.0000  0.0000  0.0000\n2000  0.0000  0.0000  0.0000\n2001  0.0000  0.0000  0.0000\n2002  0.0000  0.0000  0.0000\n2003  0.0000  0.0000  0.0000\n2004  0.0000  0.0000  0.0000\n2005  0.0000  0.0000  0.0000\n2006  0.0000  0.0000  0.0000\n2007  0.0000  0.0000  0.0000\n2008  0.0000  0.0000  0.0000\n2009  0.0000  0.0000  0.0000\n2010  0.0000  0.0000  0.0000\n2011  0.0000  0.0000  0.0000\n2012  0.0000  0.0000  0.0000\n2013  0.0000  0.0000  0.0000\n2014  0.0000  0.0000  0.0000\n2015  0.0000  0.0000  0.0000\n2016  0.0000  0.0000  0.0000\n2017  0.0000  0.0000  0.0000\n2018  0.0000  0.0000  0.0000\n2019  0.0000  0.0000  0.0000\n2020  0.0000  0.0000  0.0000\n2021  0.0000  0.0000  0.0000\n2022  0.0000  0.0000  0.0000\n2023  0.0000  0.0000  0.0000\n2024  0.0000  0.0000  0.0000\n2025  0.0000  0.0000  0.0000\n2026  0.0000  0.0000  0.0000\n2027  0.0000  0.0000  0.0000\n2028  0.0000  0.0000  0.0000\n2029  0.0000  0.0000  0.0000\n2030"
  },
  {
    "objectID": "2021/rte/TP/R-2-CJO.html#exercice-bilan",
    "href": "2021/rte/TP/R-2-CJO.html#exercice-bilan",
    "title": "2 - Correction des jours ouvrables",
    "section": "Exercice bilan",
    "text": "Exercice bilan\n\n\n\n\n\n\nExercice\n\n\n\nCréer un objet regresseurs_JO qui contiendra tous les jeux de régresseurs plausibles. Par exemple :\n\nle régresseur leap year\nle jeu de régresseur trading days (REG6, lundi à samedi, dimanche = contraste)\nle jeu de régresseur working days (REG1, lundi =… = vendredi, samedi=dimanche=contraste)\nle jeu REG2 : lundi = … = vendredi, samedi et dimanche = contraste\nle jeu REG3 : lundi, mardi = … = vendredi, samedi = dimanche = contraste\nle jeu REG5 : lundi à vendredi, samedi = dimanche = contraste\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nfrequency <- 12\nstart <- c(1990,1)\nend = c(2030, 1)\nlength = (end[1] - start[1]) * 12 + end[2] - start[2]\n\nly <- leap_year(frequency = frequency, start = start,\n                end = end)\nreg6 <- htd(frenchCalendar, frequency = frequency, start = start, length = length,\n           groups = c(1, 2, 3, 4, 5, 6, 0))\nreg5 <- htd(frenchCalendar, frequency = frequency, start = start, length = length,\n            groups = c(1, 2, 3, 4, 5, 0, 0))\nreg3 <- htd(frenchCalendar, frequency = frequency, start = start, length = length,\n            groups = c(1, 2, 2, 2, 2, 0, 0))\nreg2 <- htd(frenchCalendar, frequency = frequency, start = start, length = length,\n            groups = c(1, 1, 1, 1, 1, 2, 0))\nreg1 <- htd(frenchCalendar, frequency = frequency, start = start, length = length,\n            groups = c(1, 1, 1, 1, 1, 0, 0))\n\n\nregresseurs_JO <- ts(cbind(reg1, reg2, reg3, reg5, reg6),\n                              start = start, frequency = frequency)\nregresseurs_JO <- ts.union(regresseurs_JO,\n                           ly)\ncolnames(regresseurs_JO) <- c(\"REG1_semaine\",\n                              sprintf(\"REG2_%s\", c(\"lundi_a_vendredi\", \"samedi\")),\n                              sprintf(\"REG3_%s\", c(\"lundi\", \"mardi_a_vendredi\")),\n                              sprintf(\"REG5_%s\", c(\"lundi\", \"mardi\", \"mercredi\", \"jeudi\", \"vendredi\")),\n                              sprintf(\"REG6_%s\", c(\"lundi\", \"mardi\", \"mercredi\", \"jeudi\", \"vendredi\", \"samedi\")),\n                              \"leap_year\")"
  },
  {
    "objectID": "2021/rte/TP/R-2-CJO.html#effet-graduel-de-pâques",
    "href": "2021/rte/TP/R-2-CJO.html#effet-graduel-de-pâques",
    "title": "2 - Correction des jours ouvrables",
    "section": "Effet graduel de Pâques",
    "text": "Effet graduel de Pâques\nPrenons l’exemple de la vente de chocolats. Il est assez commun d’offrir des chocolats à Pâques : il y a donc une hausse des ventes autour du lundi de Pâques. Toutefois, ces ventes ne se font pas le jour de Pâques mais plusieurs jours avant, et plus on se rapproche du jour J, plus ces ventes sont importantes. C’est ce que l’on appel l’effet graduel de Pâques. Sous JDemetra+ on peut définir le nombre de jours avant Pâques pour lequel on considère qu’il y a un effet (easter.duration, entre 1 et 20) ou laisser ce choix à JDemetra+.\n\n\n\n\n\n\nExercice\n\n\n\nSerait-il pertinent de considérer un effet graduel de Noël dans le modèle Reg-ARIMA ?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNon car l’effet graduel de Noël est en fait saisonnier car c’est un jour fixe ! Pour Pâques, comme c’est une fête mobile, les jours précédents peuvent être dans des mois différents en fonction de l’année considérée. Je ne suis pas entré dans les détails mais le régresseur utilisé pour la correction de l’effet graduel de Pâques est désaisonnalisé pour ne prendre en compte que les régresseurs."
  },
  {
    "objectID": "2021/rte/TP/R-3-Preadjustment.html",
    "href": "2021/rte/TP/R-3-Preadjustment.html",
    "title": "3 - Qualité du préajustement sous R",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à vérifier la qualité du pré-ajustement dans RJDemetra\n\nSi besoin, ci-dessous un exemple de code pour récupérer vos données :\n\nfichier <- \"../data/data_rte.xlsx\"\n# # Ou en téléchargeant le fichier depuis internet :\n# fichier <- tempfile(fileext = \"xlsx\")\n# url <- \"https://aqlt.github.io/formations/2021/rte/data/data_rte.xlsx\"\n# download.file(url, fichier)\ndata_rte <- readxl::read_excel(fichier)\ndate_deb <- 2006\ndata_rte <- ts(data_rte[,-1], start = date_deb,\n               frequency = 12)\n\nPrenons une spécification par défaut :\n\nlibrary(RJDemetra)\nipi_fr <- ipi_c_eu[, \"FR\"]\nmysa <- x13(ipi_fr)\n\nComme on l’a vu dans le TP2, les tests de Student peuvent être utilisés pour tester la significativité des coefficients, et on peut également faire des tests de Fisher avec le package car pour voir si l’on peut simplifier les régresseurs jours ouvrables. Voir également le TP2 pour les tests sur la présence de jours ouvrables résiduelle.\n\nsummary(mysa$regarima)\n\ny = regression model + arima (2, 1, 1, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-1990 to 12-2020\nLog-transformation: no\nRegression model: no mean, trading days effect(7), leap year effect, Easter effect, outliers(4)\n\nCoefficients:\nARIMA: \n            Estimate Std. Error  T-stat Pr(>|t|)    \nPhi(1)     0.0003269  0.1077296   0.003   0.9976    \nPhi(2)     0.1688192  0.0740996   2.278   0.0233 *  \nTheta(1)  -0.5485606  0.1016550  -5.396 1.24e-07 ***\nBTheta(1) -0.6660849  0.0422242 -15.775  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n              Estimate Std. Error  T-stat Pr(>|t|)    \nMonday         0.55932    0.22801   2.453 0.014638 *  \nTuesday        0.88221    0.22832   3.864 0.000132 ***\nWednesday      1.03996    0.22930   4.535 7.85e-06 ***\nThursday       0.04943    0.22944   0.215 0.829549    \nFriday         0.91132    0.22988   3.964 8.88e-05 ***\nSaturday      -1.57769    0.22775  -6.927 1.99e-11 ***\nLeap year      2.15403    0.70527   3.054 0.002425 ** \nEaster [1]    -2.37950    0.45391  -5.242 2.71e-07 ***\nTC (4-2020)  -35.59245    2.17330 -16.377  < 2e-16 ***\nAO (3-2020)  -20.89026    2.18013  -9.582  < 2e-16 ***\nAO (5-2011)   13.49850    1.85694   7.269 2.28e-12 ***\nLS (11-2008) -12.54901    1.63554  -7.673 1.60e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 2.218 on 342 degrees of freedom\nLog likelihood = -799.1, aic =  1632, aicc =  1634, bic(corrected for length) = 1.855\n\nlibrary(car)\n# On rejette l'hypothèse de nullité globale des coefficients\nlinearHypothesis(mysa,\n                 c(\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"),\n                 c(0, 0, 0, 0, 0, 0), test = \"F\")\n\nLinear hypothesis test\n\nHypothesis:\nMonday = 0\nTuesday = 0\nWednesday = 0\nThursday = 0\nFriday = 0\nSaturday = 0\n\nModel 1: restricted model\nModel 2: mysa\n\n  Res.Df Df      F    Pr(>F)    \n1    348                        \n2    342  6 83.415 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# On pourrait rassembler les jours de la semaine :\nlinearHypothesis(mysa,\n                 c(\"Monday = Tuesday\",\"Tuesday = Wednesday\",\"\n                   Wednesday = Thursday\", \"Thursday = Friday\"), test = \"F\")\n\nLinear hypothesis test\n\nHypothesis:\nMonday - Tuesday = 0\nTuesday - Wednesday = 0\nWednesday - Thursday = 0\nThursday - Friday = 0\n\nModel 1: restricted model\nModel 2: mysa\n\n  Res.Df Df      F  Pr(>F)  \n1    346                    \n2    342  4 2.1504 0.07429 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nConcernant la qualité du modèle RegARIMA, on peut citer trois tests :\n\nLe test d’indépendance des résidus\nLe test d’homoscédasticité des résidus\nLe test de normalité des résidus\n\nCes trois tests, également disponibles par des fonctions spécifiques sous R (la commande residuals(mysa) permet de récupérer les résidus du modèle), sont également disponibles dans le sous objet .$regarima$residuals.stat$tests :\n\nmysa$regarima$residuals.stat$tests\n\n\n\u001b[1mNormality\u001b[22m\n         Statistic P.value    \nmean       0.12648  0.8994 ***\nskewness  -0.01954  0.8799 ***\nkurtosis   3.54844  0.0339    \n\nSignif. codes:  H0 (normality of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mIndependence\u001b[22m\n                                       Statistic P.value    \nljung box                               55.08622  0.0000    \nljung box (residuals at seasonal lags)   3.09960  0.2123 ***\n\nSignif. codes: H0 (independence of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mLinearity\u001b[22m\n                              Statistic P.value  \nljung box (squared residuals)  34.36237  0.0238  \n\nSignif. codes:  H0 (no conditional heteroscedasticity of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\nL’hétéroscédasticité et la non-normalité proviennent souvent de la présence de points atypiques non corrigés (pour jouer sur le seuil de détection, rajouter dans la spécification outlier.usedefcv = FALSE et prendre une valeur de outlier.cv inférieur à 4, qui est la valeur par défaut). Changer le schéma de décomposition peut aussi aider (transform.function = \"None\" pour un modèle additif ou transform.function = \"Log\" pour un modèle multiplicatif) :\n\nmysa2 <- x13(ipi_fr, x13_spec(mysa, outlier.usedefcv = FALSE,\n                              outlier.cv = 3))\n# Bien plus d'outliers sont détectés !\nsummary(mysa2$regarima)\n\ny = regression model + arima (3, 1, 1, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-1990 to 12-2020\nLog-transformation: no\nRegression model: no mean, trading days effect(7), leap year effect, Easter effect, outliers(28)\n\nCoefficients:\nARIMA: \n          Estimate Std. Error T-stat Pr(>|t|)    \nPhi(1)     0.27920    0.09413  2.966  0.00322 ** \nPhi(2)     0.36429    0.07687  4.739 3.10e-06 ***\nPhi(3)     0.11811    0.07680  1.538  0.12496    \nTheta(1)  -0.63217    0.08106 -7.799 6.84e-14 ***\nBTheta(1) -0.34211    0.05369 -6.372 5.72e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n             Estimate Std. Error  T-stat Pr(>|t|)    \nMonday         0.3870     0.1811   2.137 0.033265 *  \nTuesday        0.9721     0.1818   5.348 1.58e-07 ***\nWednesday      0.8970     0.1830   4.903 1.43e-06 ***\nThursday       0.1836     0.1826   1.006 0.315205    \nFriday         0.9678     0.1846   5.244 2.69e-07 ***\nSaturday      -1.6723     0.1829  -9.145  < 2e-16 ***\nLeap year      1.7207     0.5026   3.423 0.000690 ***\nEaster [1]    -2.3262     0.3536  -6.578 1.68e-10 ***\nTC (4-2020)  -34.9803     1.3450 -26.007  < 2e-16 ***\nAO (3-2020)  -20.5598     1.6847 -12.204  < 2e-16 ***\nAO (5-2011)   11.6856     1.3242   8.825  < 2e-16 ***\nLS (11-2008)  -9.4587     1.0474  -9.030  < 2e-16 ***\nLS (1-2009)   -7.8963     1.0256  -7.699 1.34e-13 ***\nAO (6-2019)   -5.7932     1.4256  -4.064 5.94e-05 ***\nLS (8-2009)    5.7013     0.8196   6.957 1.66e-11 ***\nTC (1-2011)    5.6019     1.0501   5.334 1.70e-07 ***\nAO (5-2018)   -4.5600     1.3401  -3.403 0.000743 ***\nLS (5-2008)   -4.7919     0.7824  -6.125 2.38e-09 ***\nAO (5-2000)    5.2033     1.3250   3.927 0.000103 ***\nAO (6-2003)   -5.4817     1.3322  -4.115 4.81e-05 ***\nAO (5-1991)   -4.5123     1.3544  -3.332 0.000953 ***\nLS (5-1994)    3.2027     0.7772   4.121 4.69e-05 ***\nTC (12-2009)  -4.5311     1.0961  -4.134 4.44e-05 ***\nLS (3-1997)    3.5716     0.7567   4.720 3.38e-06 ***\nLS (1-1993)   -3.4933     0.7611  -4.590 6.15e-06 ***\nAO (8-2020)    6.3136     1.6987   3.717 0.000234 ***\nTC (11-2000)   5.8864     1.0215   5.762 1.79e-08 ***\nTC (8-2015)    3.5207     0.9715   3.624 0.000332 ***\nTC (12-1999)   4.4543     1.0307   4.322 2.01e-05 ***\nLS (10-1997)   2.7159     0.7569   3.588 0.000379 ***\nTC (12-1994)   4.2812     0.9973   4.293 2.27e-05 ***\nTC (10-2017)   3.9944     0.9801   4.076 5.65e-05 ***\nLS (11-2019)  -3.0752     0.9235  -3.330 0.000959 ***\nLS (2-2004)    2.1923     0.7651   2.865 0.004409 ** \nAO (6-2011)   -4.8397     1.3372  -3.619 0.000338 ***\nTC (11-2011)   4.0079     1.0178   3.938 9.88e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 1.627 on 317 degrees of freedom\nLog likelihood = -685.6, aic =  1455, aicc =  1467, bic(corrected for length) = 1.646\n\n\nLa qualité des prévisions peut également être vérifiée à travers plusieurs tests :\n\nEst-ce que la moyenne des erreurs prévisions in sample (i.e. : modèle estimé sur toute la période) et la moyenne des prévisions out of sample (i.e. : modèle estimé de manière dynamique en ajoutant une a à une les nouvelles données) sont nulles ? Ces tests sont sensibles à la non-normalité des résidus\nEst-ce que les variances des erreurs de prévision in sample et out of sample sont les mêmes ? Ce test est sensible à la non-normalité des résidus\nEst-ce qu’il y a “trop” d’outliers ? Dans JDemetra+, on considère par défaut qu’il y a trop d’outliers si la proportion d’outliers par rapport aux nombres d’observations est supérieure à 5 %.\n\nLes trois premiers tests ne sont pas par défaut exportés dans RJDemetra : il faut les rajouter à la main avec le paramètre userdefined. Ils seront alors disponibles dans la sous-liste .$user_defined. Concernant la proportion d’outliers, elle peut être calculée à la main à partir du nombre d’outliers (par exemple disponible dans .$regarima$model$spec_rslt) :\n\nmysa <- x13(ipi_fr, x13_spec(mysa),\n            userdefined = c(\"diagnostics.fcast-insample-mean\",\n                            \"diagnostics.fcast-outsample-mean\",\n                            \"diagnostics.fcast-outsample-variance\"))\nmysa$regarima$model$spec_rslt\n\n           Model                 T.span Log transformation  Mean Trading days\n1 RegARIMA - X13 from 1-1990 to 12-2020              FALSE FALSE            7\n  Leap year Easter Outliers\n1      TRUE   TRUE        4\n\n# Pour éviter outputs trop longs, l'affichage est réduit :\nmysa$user_defined\n\nNames of additional variables (3):\ndiagnostics.fcast-insample-mean, diagnostics.fcast-outsample-mean, diagnostics.fcast-outsample-variance\n\n# Pour supprimer cela, vous pouvez par exemple utiliser le code suivant :\nc(mysa$user_defined)\n\n$`diagnostics.fcast-insample-mean`\n[1] 0.3057321 0.7599958\nattr(,\"description\")\n[1] \"T with 340 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-mean`\n[1] -0.7781656  0.4370126\nattr(,\"description\")\n[1] \"T with 340 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-variance`\n[1] 1.1383576 0.3128808\nattr(,\"description\")\n[1] \"F with 18 degrees of freedom in the nominator and 341 degrees of freedom in the denominator\"\n\n\nVous pouvez bien sûr utiliser votre tests préféré à partir de ceux disponibles sous R (autre test de normalité…).\nPour comparer différents modèles, vous pouvez également utiliser les critères d’information (mais il faut que les modèles ARIMA aient les mêmes ordres de différenciation !). Vous pouvez pour cela utiliser les fonctions de bases de R (AIC(), BIC()…) ou prendre ceux de JDemetra+ (affichés lors du summary(), qu’on peut également retrouver par la commande .$regarima$loglik) :\n\nAIC(mysa)\n\n[1] 1632.169\n\nBIC(mysa)\n\n[1] 1698.185\n\n# Il y a un peu plus de critères que dans base R : AICc et BICc\nmysa$regarima$loglik\n\n                         \nlogvalue      -799.084484\nnp              17.000000\nneffectiveobs  359.000000\naic           1632.168967\naicc          1633.963689\nbic           1698.185448\nbicc             1.855018\n\n\n\n\n\n\n\n\nExercice\n\n\n\nPrenez une série et étudier la qualité du modèle RegARIMA. Essayer de changer quelques paramètres : est-ce que le nouveau modèle vous parait meilleur ou moins bien que l’ancien ?"
  },
  {
    "objectID": "2021/rte/TP/R-4-X11.html",
    "href": "2021/rte/TP/R-4-X11.html",
    "title": "4 - Qualité de la décomposition sous R",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à étudier la qualité de la décomposition depuis RJDemetra\n\nSi besoin, ci-dessous un exemple de code pour récupérer vos données :\n\nfichier <- \"../data/data_rte.xlsx\"\n# # Ou en téléchargeant le fichier depuis internet :\n# fichier <- tempfile(fileext = \"xlsx\")\n# url <- \"https://aqlt.github.io/formations/2021/rte/data/data_rte.xlsx\"\n# download.file(url, fichier)\ndata_rte <- readxl::read_excel(fichier)\ndate_deb <- 2006\ndata_rte <- ts(data_rte[,-1], start = date_deb,\n               frequency = 12)\n\nPrenons une spécification par défaut :\nDans ce TP nous allons voir différentes façon de vérifier la qualité de la décomposition. Tout d’abord, on peut commencer par regarder les statistiques m dont les définitions sont rappelées ci-dessous\n\n\n\n\n \n  \n      \n    Poids \n    Description \n    Si problème   \n  \n \n\n  \n    M1 \n    10 \n    Contribution de l'irrégulier à la variance totale (stationnarisation par différence d'ordre 3). Si trop élevé, difficile d'extraire la saisonnalité. \n    Points atypiques ou taille des filtres \n  \n  \n    M2 \n    11 \n    Contribution de l'irrégulier à la variance totale (stationnarisation par une droite). \n    Points atypiques ou taille des filtres \n  \n  \n    M3 \n    10 \n    Mesuré à partir du ratio I/C. Si trop grand on aura du mal à séparer les deux composantes. \n    Points atypiques ou taille des filtres \n  \n  \n    M4 \n    8 \n    Test autocorrélation sur l'irrégulier (réduire le filtre saisonnier). \n    Filtre saisonnier plus court \n  \n  \n    M5 \n    11 \n    Mesuré à partir du MCD (nombre de mois nécessaires pour que les variations absolues de la TC l'emporte sur I). \n    Points atypiques \n  \n  \n    M6 \n    10 \n    Vérifie si la moyenne mobile M3x5 est appropriée ($1.5 < I/S < 6.5$). \n    Prendre filtre plus long \n  \n  \n    M7 \n    18 \n    Permet de voir si la saisonnalité est identifiable (compare part relative de la saisonnalité stable et mobile). \n    Schéma multiplicatif ? \n  \n  \n    M8 \n    7 \n    Mesure l'évolution de la S de court terme. \n    Changer filtre saisonnier \n  \n  \n    M9 \n    7 \n    Mesure l'évolution de la S de long terme. \n    Changer filtre saisonnier \n  \n  \n    M10 \n    4 \n    M8 sur dernières années ($N-2$ à $N-5$). \n    Changer filtre saisonnier \n  \n  \n    M11 \n    4 \n    M9 sur dernières années ($N-2$ à $N-5$). \n    Changer filtre saisonnier \n  \n\n\n\n\n\nÀ partir d’un objet \"X13\", les statistiques m disponibles dans la sous-liste .$decomposition :\n\nmysa$decomposition\n\n Monitoring and Quality Assessment Statistics:  \n      M stats\nM(1)    0.163\nM(2)    0.089\nM(3)    1.181\nM(4)    0.558\nM(5)    1.020\nM(6)    0.090\nM(7)    0.083\nM(8)    0.244\nM(9)    0.062\nM(10)   0.272\nM(11)   0.256\nQ       0.368\nQ-M2    0.402\n\nFinal filters: \nSeasonal filter:  3x5\nTrend filter:  13 terms Henderson moving average\n\n\n\n\n\n\n\n\nExercice\n\n\n\nQue signifie ces valeurs des statistiques m plus grandes que 1 ? Est-ce important ? Si oui comment les corriger ?\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nQue pensez-vous de la tendance (plot(mysa$final, type_chart = \"sa-trend\")) ? Quelle est la contribution du cycle à la variance totale (mysa$diagnostics$variance_decomposition) ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLa tendance est plutôt plate et la contribution du cycle à la variance totale est petite, on peut donc ignorer la statistique m3. La statistique M5 suggère de prendre un filtre saisonnier plus long, par exemple en utilisant le code suivant :\nmysa2 <- x13(get_ts(mysa), x13_spec(mysa, x11.seasonalma = \"S3X9\"))\nMais en faisant cela on crée de la saisonnalité résiduelle ! (mysa2$diagnostics), c’est donc mieux de rester sur les paramètres par défaut.\n\n\n\nAlors que pour changer le filtre saisonnier il suffit d’utiliser le paramètre x11.seasonalma, pour changer la longueur du filtre de Henderson il faut désactiver l’option de recherche automatique de la longueur du filtre (x11.trendAuto = FALSE) et spécifier la longueur dans le paramètre x11.trendma:\n\nnew_spec <- x13_spec(mysa, x11.trendma = 15)\nnew_spec$x11# Colonne trendma inchangée !\n\n            x11.mode x11.seasonalComp x11.lsigma x11.usigma x11.trendAuto\nPredefined Undefined             TRUE        1.5        2.5          TRUE\nUser_modif      <NA>               NA         NA         NA            NA\nFinal      Undefined             TRUE        1.5        2.5          TRUE\n           x11.trendma x11.seasonalma x11.fcasts x11.bcasts x11.calendarSigma\nPredefined          13            Msr         -1          0              None\nUser_modif          15           <NA>         NA         NA              <NA>\nFinal               13            Msr         -1          0              None\n           x11.sigmaVector x11.excludeFcasts\nPredefined              NA             FALSE\nUser_modif              NA                NA\nFinal                   NA             FALSE\n\nnew_spec <- x13_spec(mysa, x11.trendma = 15, x11.trendAuto = FALSE)\nnew_spec$x11\n\n            x11.mode x11.seasonalComp x11.lsigma x11.usigma x11.trendAuto\nPredefined Undefined             TRUE        1.5        2.5          TRUE\nUser_modif      <NA>               NA         NA         NA         FALSE\nFinal      Undefined             TRUE        1.5        2.5         FALSE\n           x11.trendma x11.seasonalma x11.fcasts x11.bcasts x11.calendarSigma\nPredefined          13            Msr         -1          0              None\nUser_modif          15           <NA>         NA         NA              <NA>\nFinal               15            Msr         -1          0              None\n           x11.sigmaVector x11.excludeFcasts\nPredefined              NA             FALSE\nUser_modif              NA                NA\nFinal                   NA             FALSE\n\n\nSur la qualité de la décomposition, la sous liste .$diagnostics contient les contributions des différentes composantes à la variance de la série, le test combiné et les tests sur la saisonnalité et jours ouvrables résiduels :\n\nmysa$diagnostics\n\n Relative contribution of the components to the stationary\n portion of the variance in the original series,\n after the removal of the long term trend \n Trend computed by Hodrick-Prescott filter (cycle length = 8.0 years)\n           Component\n Cycle         2.251\n Seasonal     59.750\n Irregular     1.067\n TD & Hol.     2.610\n Others       33.718\n Total        99.395\n\n Combined test in the entire series \n Non parametric tests for stable seasonality\n                                                          P.value\n   Kruskall-Wallis test                                      0.000\n   Test for the presence of seasonality assuming stability   0.000\n   Evolutive seasonality test                                0.034\n \n Identifiable seasonality present\n\n Residual seasonality tests \n                                      P.value\n qs test on sa                          0.985\n qs test on i                           0.865\n f-test on sa (seasonal dummies)        0.958\n f-test on i (seasonal dummies)         0.893\n Residual seasonality (entire series)   0.876\n Residual seasonality (last 3 years)    0.906\n f-test on sa (td)                      0.987\n f-test on i (td)                       0.993\n\n\nCes tests sont effectués sur l’ensemble de la série, alors que dans le main result le f-test est effectué sur les 8 dernières années. Il n’est pour l’instant pas possible d’exporter les tests de saisonnalité résiduelle sur les 8 ou 10 dernières années. À partir du packages rjd3sa il est en revanche possible de calculer la tous les tests à l’exception du f-test.\nPar rapport aux éléments vus en cours, les msr par mois sont exportables en utilisant le paramètre userdefined de x13. Il y a cependant actuellement un bug qui ne permet pas de l’exporter pour le dernier mois :\n\nmysa <- x13(ipi_fr, \n            userdefined = c(\"diagnostics.msr-global\",\n                            sprintf(\"diagnostics.msr(%i)\", 1:12)))\nc(mysa$user_defined)\n\n$`diagnostics.msr-global`\n[1] 4.224309\n\n$`diagnostics.msr(1)`\n[1] 6.918248\n\n$`diagnostics.msr(2)`\n[1] 4.679206\n\n$`diagnostics.msr(3)`\n[1] 4.351482\n\n$`diagnostics.msr(4)`\n[1] 5.808313\n\n$`diagnostics.msr(5)`\n[1] 4.446801\n\n$`diagnostics.msr(6)`\n[1] 3.175827\n\n$`diagnostics.msr(7)`\n[1] 5.102764\n\n$`diagnostics.msr(8)`\n[1] 2.756466\n\n$`diagnostics.msr(9)`\n[1] 4.216562\n\n$`diagnostics.msr(10)`\n[1] 4.750469\n\n$`diagnostics.msr(11)`\n[1] 5.088831\n\n$`diagnostics.msr(12)`\nNULL\n\n\nPour extraire tous les MSR, préférer la solution suivante :\n\nextract_msr <- function(x, i = 1:12){\n    jmodel <- suppressWarnings(jx13(get_ts(x), x13_spec(x)))\n    jres <- jmodel$result@internal$getResults()\n    jres <- new(Class = \"X13_java\", internal = jres)\n    res <- sapply(i, function(i_){\n        RJDemetra:::result(jres,\n                           sprintf(\"msr(%i)\", i_))\n    })\n    names(res) <- sprintf(\"msr(%i)\", i)\n    res\n}\nextract_msr(mysa)\n\n  msr(1)   msr(2)   msr(3)   msr(4)   msr(5)   msr(6)   msr(7)   msr(8) \n6.918248 4.679206 4.351482 5.808313 4.446801 3.175827 5.102764 2.756466 \n  msr(9)  msr(10)  msr(11)  msr(12) \n4.216562 4.750469 5.088831 2.953120"
  },
  {
    "objectID": "2021/rte/TP/R-5-JD_in_production.html",
    "href": "2021/rte/TP/R-5-JD_in_production.html",
    "title": "5 - JDemetra+ en production",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à manipuler des workspaces pour une mise en production.\nLors de la mise en production, le plus simple est de manipuler des workspaces et de mettre à jour les modèles, lors de l’arrivée de nouvelles données à travers le JWSACruncher. Pour faciliter son utilisation depuis R, le package rjwsacruncher peut être utilisé.\nLorsque les workspaces sont créés depuis R, on perd toutes les métadonnées (lien vers les fichiers, commentaires, etc.), une solution pour cela : utiliser rjdworkspace (package non publié sur le CRAN) pour récupérer ces données depuis un autre workspace.\nDans ce TP on utilisera les données du package RJDemetra mais n’hésitez pas à utiliser vos propres séries, en utilisant par exemple le code ci-dessous :\nSi besoin, ci-dessous un exemple de code pour récupérer vos données :"
  },
  {
    "objectID": "2021/rte/TP/R-5-JD_in_production.html#sec:installation",
    "href": "2021/rte/TP/R-5-JD_in_production.html#sec:installation",
    "title": "5 - JDemetra+ en production",
    "section": "Configuration du JWSACruncher",
    "text": "Configuration du JWSACruncher\nLe JWSACruncher est téléchargeable ici : https://github.com/jdemetra/jwsacruncher/releases.\nPour utiliser les dernières versions il faut avoir une version de Java supérieure à la 8, si ce n’est pas le cas, il faut télécharger une version portable de Java et configurer le JWSACruncher en conséquence (voir manuel d’installation). Ces manipulations peuvent aussi se faire à partir de rjwsacruncher :\n\n# install.packages(\"rjwsacruncher\") # Si pas déjà installé\nlibrary(rjwsacruncher)\n# Télécharge l'archive du JWSACruncher et la met sur le D:/\ndownload_cruncher(\"D:/\") \n# Dézipper l'archive et ensuite pour configurer avec une version portable de Java :\njwsacruncher_path <- \"D:/jwsacruncher-2.2.2-bin/bin/jwsacruncher.bat\" # Lien vers le fichier jwsacruncher.bat\njava_path <- \"D:/Java8/bin/java.exe\" # Lien vers le fichier java.exe de la version portable de Java\nconfigure_jwsacruncher(jwsacruncher_path, java_path)\n\nPour indiquer à rjwsacruncher où se trouve le JWSACruncher, le plus simple est de mettre à jour l’option cruncher_bin_directory :\n\n# Chemin vers le dossier bin du JWSACruncher\noptions(cruncher_bin_directory =\n            \"/Users/alainquartierlatente/Desktop/jwsacruncher-2.2.2-bin/bin\") \ngetOption(\"cruncher_bin_directory\") # Pour afficher la valeur actuelle\n\n[1] \"/Users/alainquartierlatente/Desktop/jwsacruncher-2.2.2-bin/bin\""
  },
  {
    "objectID": "2021/rte/TP/R-5-JD_in_production.html#utilisation-du-jwsacruncher",
    "href": "2021/rte/TP/R-5-JD_in_production.html#utilisation-du-jwsacruncher",
    "title": "5 - JDemetra+ en production",
    "section": "Utilisation du JWSACruncher",
    "text": "Utilisation du JWSACruncher\nPour éviter que le package rjwsacruncher soit trop volumineux, il ne contient pas le JWSAcruncher de JDemetra+. Ce dernier peut être téléchargé à l’adresse suivante : https://github.com/jdemetra/jdemetra-app/releases ou en utilisant la fonction rjwsacruncher::download_cruncher(). Pour sa configuration avec une version portable, voir le manuel d’installation.\nPour lancer le JWSACruncher il faut trois fichiers :\n\nun fichier contenant les paramètres sur la méthode de rafraîchissement à utilisée pour mettre à jour le workspace (créé à partir de la fonction create_param_file()) ;\n\nun workspace valide de JDemetra+ ;\n\nl’adresse vers le JWSACruncher (option cruncher_bin_directory).\n\nDans le package `rjwsacruncher``, il existe trois fonctions associées au lancement du cruncher :\n\ncreate_param_file() qui permet de créer le fichier de paramètres ;\n\ncruncher() qui permet de lancer le cruncher sur un workspace à partir d’un fichier de paramètres ;\n\ncruncher_and_param() qui permet de lancer le cruncher tout en créant le fichier de paramètres et de personnaliser certaines sorties du cruncher.\n\n\nCréation du fichier de paramètres avec create_param_file()\nLes paramètres de la fonction create_param_file() sont les mêmes que ceux décrits dans le wiki du cruncher de JDemetra+ (https://github.com/jdemetra/jwsacruncher/wiki). Les trois paramètres les plus importants de create_param_file() sont :\n\npolicy qui est la méthode de rafraîchissement utilisée (voir tableau ci-dessous).\n\n\n\n\n\nLes différentes politiques de rafraîchissement\n \n  \n    Option sous JDemetra+ \n    Option du cruncher \n    Signification \n  \n \n\n  \n    Partial concurrent adjustment -> Fixed model \n    current \n    Le modèle ARIMA, les outliers et les autres paramètres du modèle de régression ne sont ni ré-identifiés ni ré-estimés. Le schéma de décomposition est inchangé. \n  \n  \n    Partial concurrent adjustment -> Estimate regression coefficients \n    fixedparameters (ou fixed) \n    Le modèle ARIMA, les outliers et les autres paramètres du modèle regARIMA ne sont pas ré-identifiés. Les coefficients du modèle ARIMA sont fixés et les autres paramètres du modèle de régression sont ré-estimés. Le schéma de décomposition est inchangé. \n  \n  \n    Partial concurrent adjustment -> Estimate regression coefficients + Arima parameters \n    parameters (paramètre par défaut) \n    Le modèle ARIMA, les outliers et les autres paramètres du modèle de régression ne sont pas ré-identifiés mais sont tous ré-estimés. Le schéma de décomposition est inchangé. \n  \n  \n    Partial concurrent adjustment -> Estimate regression coefficients + Last outliers \n    lastoutliers \n    Le modèle ARIMA, les outliers (sauf ceux de la dernière année) et les autres paramètres du modèle de régression ne sont pas ré-identifiés mais sont tous ré-estimés. Les outliers de la dernière année sont ré-identifiés. Le schéma de décomposition est inchangé. \n  \n  \n    Partial concurrent adjustment -> Estimate regression coefficients + all outliers \n    outliers \n    Le modèle ARIMA et les paramètres du modèle regARIMA autres que les outliers ne sont pas ré-identifiés mais ré-estimés. Tous les outliers sont ré-identifiés. Le schéma de décomposition est inchangé. \n  \n  \n    Partial concurrent adjustment -> Estimate regression coefficients + Arima model \n    stochastic \n    Ré-identification de tous les paramètres du modèle regARIMA hormis les variables calendaires. Le schéma de décomposition est inchangé. \n  \n  \n    Concurrent \n    complete ou concurrent \n    Ré-identification de tout le modèle regARIMA. \n  \n\n\n\n\n\n\nmatrix_item qui est une chaîne de caractères contenant les noms des paramètres à exporter. Par défaut, ce sont ceux de l’option default_matrix_item. On peut donc au choix modifier l’option default_matrix_item ou le paramètre matrix_item :\n\n\nlibrary(rjwsacruncher)\n # Pour afficher les paramètres par défaut :\ngetOption(\"default_matrix_item\")\n# Pour modifier les paramètres par défaut pour n'exporter par exemple\n# que les critères d'information :\noptions(default_matrix_item = c(\"likelihood.aic\",\n                                \"likelihood.aicc\",\n                                \"likelihood.bic\",\n                                \"likelihood.bicc\"))\n\n\ntsmatrix_series qui est une chaîne de caractères contenant les noms des paramètres à exporter. Par défaut, ce sont ceux de l’option default_tsmatrix_series. On peut donc au choix modifier l’option default_tsmatrix_series ou le paramètre tsmatrix_series :\n\n\n # Pour afficher les paramètres par défaut :\ngetOption(\"default_tsmatrix_series\")\n# Pour modifier les paramètres par défaut pour n'exporter par exemple que\n# la série désaisonnalisée et ses prévisions :\noptions(default_tsmatrix_series = c(\"sa\", \"sa_f\"))\n\nPour voir l’ensemble des paramètres, il suffit d’utiliser sous R la commande ?create_param_file.\nAprès cela, il ne reste plus qu’à créer le fichier de paramètres. Ci-dessous quelques exemples.\n\n# Un fichier parametres.param sera créé sous D:/ avec la politique de rafraîchissement\n# \"lastoutliers\" et les autres paramètres par défaut\ncreate_param_file(dir_file_param = \"D:/\",\n                  policy = \"lastoutliers\")\n# Si l'on a modifié les options \"default_matrix_item\" et \"default_tsmatrix_series\" pour\n# n'exporter que les critères d'information, la série désaisonnalisée et ses\n# prévisions, la commande précédente est équivalent à : \ncreate_param_file(dir_file_param = \"D:/\",\n                  policy = \"lastoutliers\",\n                  matrix_item = c(\"likelihood.aic\", \"likelihood.aicc\",\n                                  \"likelihood.bic\", \"likelihood.bicc\"),\n                  tsmatrix_series = c(\"sa\", \"sa_f\"))\n\n\n\n\n\n\n\nExercice\n\n\n\nUtiliser la fonction create_param_file() pour créé un fichier de paramètres permettant de mettre à jour un workspace :\n\nEn reestimant le modèle ARIMA, les outliers et les autres paramètres du modèle de régression et en re-identifiant les outliers uniquement sur la dernière année.\nEn exportant la statistique M7, la statistique Q-M2 et les tests de jours ouvrables résiduels ;\nEn exportant La série brute, la série désaisonnalisée et la tendance (de manière verticale).\n\n\n\n\ncreate_param_file(dir_file_param = \"/Users/alainquartierlatente/Desktop/\",\n                  policy = \"lastoutliers\",\n                  matrix_item = c(\"m-statistics.m7\",\n                                  \"m-statistics.q-m2\",\n                                  \"diagnostics.residual trading days tests.f-test on sa (td):2\",\n                                  \"diagnostics.residual trading days tests.f-test on i (td):2\"),\n                  tsmatrix_series = c(\"y\", \"sa\", \"t\"),\n                  csv_layout = \"vtable\" \n)\n\n\n\nLancement du cruncher\nPour lancer le cruncher avec cruncher() ou cruncher_and_param(), il faut spécifier le chemin d’accès au dossier contenant le cruncher (paramètre cruncher_bin_directory) ainsi que celui du workspace à traiter (paramètre workspace).\nPar défaut, le chemin d’accès au dossier du cruncher est celui contenu dans le paramètre cruncher_bin_directory : il suffit donc de modifier une seule fois cette option afin qu’elle s’applique à toutes les exécutions du cruncher. Le chemin à indiquer est celui du dossier contenant le fichier jwsacruncher.bat, situé dans le dossier “Bin” du dossier d’installation du cruncher. Ainsi, s’il a été installé sous D:\\jdemetra-cli-2.2.3, le fichier jwsacruncher.bat sera présent sous D:\\jdemetra-cli-2.2.3\\bin. Il faut donc modifier l’option cruncher_bin_directory de la façon suivante :\n\noptions(cruncher_bin_directory = \"D:/jdemetra-cli-2.2.3/bin/\")\n\nSi aucun chemin de workspace n’est renseigné, une fenêtre s’ouvre, invitant à sélectionner le workspace sur lequel on souhaite lancer le cruncher.\n\ncruncher(workspace = \"workspace.xml\",\n         param_file_path = \"/Users/alainquartierlatente/Desktop/parameters.param\"\n)\n\nSi vous n’avez pas de workspace vous pouvez utiliser le code suivant pour en générer un :\n\nlibrary(RJDemetra)\nspec_x13 <- x13_spec(spec = \"RSA5c\")\nwk <- new_workspace()\nnew_multiprocessing(wk, \"sa1\")\n\nfor (nom_series in colnames(data_rte)){\n  model <- jx13(data_rte[,nom_series], spec_x13)\n  add_sa_item(wk, \"sa1\", model, nom_series)\n}\n\nsave_workspace(wk, \"workspace.xml\")\n\nSi non spécifié dans le fichier des paramètres, les résultats sont exportés dans le sous dossier “Output” du workspace (pour le workspace.xml, les résultats seront donc sous workspace/Output/). On peut aussi créer le fichier des paramètres et lancer le JWSAcruncher avec la fonction cruncher_and_param. Cette fonction permet aussi de renommer les dossiers exportées avec les noms des multi-processings utilisés dans JDemetra+ (évite d’avoir des dossiers du type SAProcessing-1).\n\ncruncher_and_param(\n        workspace = \"workspace.xml\",\n        policy = \"lastoutliers\",\n        matrix_item = c(\"m-statistics.m7\",\n                        \"m-statistics.q-m2\",\n                        \"diagnostics.residual trading days tests.f-test on sa (td):2\",\n                        \"diagnostics.residual trading days tests.f-test on i (td):2\"),\n        tsmatrix_series = c(\"y\", \"sa\", \"t\"),\n        csv_layout = \"vtable\"\n)"
  },
  {
    "objectID": "2021/rte/index.html",
    "href": "2021/rte/index.html",
    "title": "Désaisonnalisation avec JDemetra+ et RJDemetra",
    "section": "",
    "text": "Supports de cours et exercices de la formation Désaisonnalisation avec JDemetra+ et RJDemetra réalisée pour RTE par Alain Quartier-la-Tente en les 23, 24, 30 juin et 1er juillet 2021."
  },
  {
    "objectID": "2021/rte/index.html#tp-jdemetra",
    "href": "2021/rte/index.html#tp-jdemetra",
    "title": "Désaisonnalisation avec JDemetra+ et RJDemetra",
    "section": "TP JDemetra+",
    "text": "TP JDemetra+\n\nPremière manipulation de JDemetra+\nAnalyse exploratoire\nDésaisonnalisation sans correction des jours ouvrables\nDésaisonnalisation avec correction des jours ouvrables\nPré-ajustement\nDécomposition (X11)\nÉtude de cas"
  },
  {
    "objectID": "2021/rte/index.html#tp-fa-brands-r-project",
    "href": "2021/rte/index.html#tp-fa-brands-r-project",
    "title": "Désaisonnalisation avec JDemetra+ et RJDemetra",
    "section": "TP  :",
    "text": "TP  :\n\nTraitement des séries temporelles sous R\nR et JDemetra+\nCorrection des jours ouvrables\nPreajustement\nDécomposition (X11)\nJDemetra+ en production"
  },
  {
    "objectID": "2021/rte/manuel_installation.html",
    "href": "2021/rte/manuel_installation.html",
    "title": "Installer JDemetra+ et du cruncher",
    "section": "",
    "text": "Pour utiliser JDemetra+ il faut deux logiciels : JDemetra+ et Java.\n\n\nJDemetra+ est téléchargeable depuis le lien github de l’application : https://github.com/jdemetra/jdemetra-app/releases. Deux solutions pour l’installer : télécharger le fichier .exe qui nécessite des droits d’administrateur ou télécharger le .zip qui permet d’avoir une version portable du logiciel.\nAttention : pour la seconde option ne pas télécharger le fichier Source code (zip) mais le fichier jdemetra+-2.2.2-bin.zip (pour la version 2.2.2) :\n\nUne fois le fichier téléchargé, il suffit de le dézipper : le logiciel se trouve alors dans le dossier \\nbdemetra\\bin\\, ce sont les fichiers nbdemetra.exe (version 32-bit) et nbdemetra64.exe (version 64-bit).\n\n\n\nPour utiliser la version 2.2.2 de JDemetra+ il faut avoir la version 8 de Java (ou une version supérieure). Si l’on a pas cette version d’installée et que l’on n’a pas les droits d’administrateur pour installer Java il faut alors installer une version portable de Java et lancer JDemetra+ avec cette version de java.\nPour installer une version portable de java on peut par exemple télécharger jPortable depuis https://portableapps.com/apps/utilities/java_portable1 ou https://jdk.java.net/java-se-ri/12.\nPour lancer JDemetra+ avec cette nouvelle version de Java il faut :\n\ncréer un raccourci vers l’application\n\nfaire un clique-droit sur le raccourci et ensuite cliquer sur « Propriétés ». Il reste alors à modifier la variable « Cible » en ajoutant le paramètre suivant : --jdkhome \"[chemin du dossier Java64]\".\n\nPar exemple, si JDemetra+ et jPortable sont installés sous D:\\Programmes\\, la variable Cible contiendra l’adresse D:\\Programmes\\nbdemetra\\bin\\nbdemetra64.exe --jdkhome \"D:\\Programmes\\Java64\".\nAttention : le chemin du raccourci est absolu, il doit donc être modifié à chaque fois qu’un des répertoires racines de JDemetra+ ou jPortable est déplacé."
  },
  {
    "objectID": "2022/ast/TP/1_Manipulation_series_temporelles.html",
    "href": "2022/ast/TP/1_Manipulation_series_temporelles.html",
    "title": "1 - Traitement des séries temporelles sous R",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à manipuler les séries temporelles sous R en utilisant les packages de bases.\nDans R il existe de nombreux packages qui permettent de manipuler les séries temporelles. Pour n’en citer que quelques-uns :\n- Les objets ts peuvent être créés à partir du package stats ;\n- Les objets zoo peuvent être créés à partir du package zoo ;\n- Les objets xts peuvent être créés à partir du package xts ;\n- Les objets tis peuvent être créés à partir du package tseries ;\n- Les objets tsibble peuvent être créés à partir du package tsibble.\ntsbox permet quand à lui de facilement passer d’une classe à l’autre.\nIci nous nous concentrerons essentiellement sur les trois premiers : ts stocker les séries temporelles, zoo et xts pour effectuer certaines manipulations supplémentaires.\nLes packages suivants seront utilisés :"
  },
  {
    "objectID": "2022/ast/TP/1_Manipulation_series_temporelles.html#création-dune-série-temporelle",
    "href": "2022/ast/TP/1_Manipulation_series_temporelles.html#création-dune-série-temporelle",
    "title": "1 - Traitement des séries temporelles sous R",
    "section": "Création d’une série temporelle",
    "text": "Création d’une série temporelle\nLa fonction ts() permet de créer des objets séries-temporelles à partir un vecteur (ou une matrice). La syntaxe de base est ts(vector, start=, end=, frequency=) où start et end sont la première et la dernière observation, frequency est le nombre d’observations par unité de temps (1=annuelle, 2=semestrielle, 4=trimestrielle, 6=bi-mestrielle, 12=mensuelle, etc.).\nPar exemple pour créer une série trimestrielle ayant les valeurs de 1 à 10 et commençant en 1959Q2 :\n\nts(1:10, frequency = 4, start = c(1959, 2)) # 2ème trimestre de 1959\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1959         1    2    3\n1960    4    5    6    7\n1961    8    9   10     \n\n# Équivalent à \nts(1:10, frequency = 4, start = 1959 + 1/4)\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1959         1    2    3\n1960    4    5    6    7\n1961    8    9   10     \n\n\nOn peut aussi définir l’objet à partir de sa date de fin :\n\nts(1:10, frequency = 4, end = c(1959, 2))\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1957    1    2    3    4\n1958    5    6    7    8\n1959    9   10          \n\n\nSi l’on directement extraire un sous-ensemble de la série on peut spécifier les paramètres end et start. Par exemple pour ne garder que les valeurs jusqu’en 1960 inclus :\n\nts(1:10, frequency = 4, start = c(1959, 2), end = c(1960, 4))\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1959         1    2    3\n1960    4    5    6    7\n\n\nOu alors utiliser la fonction window une fois l’objet créé :\n\nts_object <- ts(1:10, frequency = 4, start = c(1959, 2))\nwindow(ts_object, end = c(1960, 4))\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1959         1    2    3\n1960    4    5    6    7\n\n\nOn peut récupérer les différents attributs avec les fonctions start(), end() et frequency() :\n\nstart(ts_object)\n\n[1] 1959    2\n\nend(ts_object)\n\n[1] 1961    3\n\nfrequency(ts_object)\n\n[1] 4\n\n\nDeux autres fonctions peuvent aussi être utiles : time() crée un série-temporelle à partir des dates de notre série-temporelle et cycle() donne la position dans le cycle de chaque observation.\n\ntime(ts_object)\n\n        Qtr1    Qtr2    Qtr3    Qtr4\n1959         1959.25 1959.50 1959.75\n1960 1960.00 1960.25 1960.50 1960.75\n1961 1961.00 1961.25 1961.50        \n\ncycle(ts_object)\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1959         2    3    4\n1960    1    2    3    4\n1961    1    2    3     \n\n\n\n\n\n\n\n\nExercice\n\n\n\nExtraire toutes les données du 2ème trimestre de l’objet ts_object\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nts_object[cycle(ts_object) == 2]\n\n[1] 1 5 9\n\n\nAutre option : utiliser la fonction window()\n\nwindow(ts_object, frequency = 1)\n\nTime Series:\nStart = 1959.25 \nEnd = 1961.25 \nFrequency = 1 \n[1] 1 5 9\n\n\nExplication : lorsque l’on spécifie le paramètre frequency dans la fonction window(), on change la fréquence de la série. Dans notre cas, on veut extraire les valeurs du deuxième trimestre : on veut donc une série annuelle qui contient toutes les valeurs des deuxièmes trimestres. La première observation de ts_object étant un deuxième trimestre, cela donne ce que l’on veut. Pour extraire les valeurs des troisièmes trimestres il faut en plus changer la date de début :\n\nwindow(ts_object, start = c(1950, 3), frequency = 1)\n\nTime Series:\nStart = 1959.25 \nEnd = 1961.25 \nFrequency = 1 \n[1] 1 5 9\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nCréer une série temporelle mensuelle qui commence en 2000, qui se termine en janvier 2020, qui vaut 1 en avril 2009 et 0 à toutes les autres dates.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOption 1 : utiliser la fonction window()\n\nindicatrice <- ts(0, start = 2000, end = 2020, frequency = 12)\nwindow(indicatrice, start = c(2009, 4), end = c(2009, 4)) <- 1\nindicatrice\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2000   0   0   0   0   0   0   0   0   0   0   0   0\n2001   0   0   0   0   0   0   0   0   0   0   0   0\n2002   0   0   0   0   0   0   0   0   0   0   0   0\n2003   0   0   0   0   0   0   0   0   0   0   0   0\n2004   0   0   0   0   0   0   0   0   0   0   0   0\n2005   0   0   0   0   0   0   0   0   0   0   0   0\n2006   0   0   0   0   0   0   0   0   0   0   0   0\n2007   0   0   0   0   0   0   0   0   0   0   0   0\n2008   0   0   0   0   0   0   0   0   0   0   0   0\n2009   0   0   0   1   0   0   0   0   0   0   0   0\n2010   0   0   0   0   0   0   0   0   0   0   0   0\n2011   0   0   0   0   0   0   0   0   0   0   0   0\n2012   0   0   0   0   0   0   0   0   0   0   0   0\n2013   0   0   0   0   0   0   0   0   0   0   0   0\n2014   0   0   0   0   0   0   0   0   0   0   0   0\n2015   0   0   0   0   0   0   0   0   0   0   0   0\n2016   0   0   0   0   0   0   0   0   0   0   0   0\n2017   0   0   0   0   0   0   0   0   0   0   0   0\n2018   0   0   0   0   0   0   0   0   0   0   0   0\n2019   0   0   0   0   0   0   0   0   0   0   0   0\n2020   0                                            \n\n\nOption 2 : utiliser time()\n\nindicatrice <- ts(0, start = 2000, end = 2020, frequency = 12)\n# Donne un vecteur de booléens\n(time(indicatrice) == 2009 + 3/12) \n\n       Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec\n2000 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2001 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2002 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2003 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2004 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2005 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2006 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2007 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2008 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2009 FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2010 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2011 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2012 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2013 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2014 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2015 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2016 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2017 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2018 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2019 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n2020 FALSE                                                                  \n\n# on ajoute + 0 pour forcer la convertion en numérique\n(time(indicatrice) == 2009 + 3/12) + 0\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2000   0   0   0   0   0   0   0   0   0   0   0   0\n2001   0   0   0   0   0   0   0   0   0   0   0   0\n2002   0   0   0   0   0   0   0   0   0   0   0   0\n2003   0   0   0   0   0   0   0   0   0   0   0   0\n2004   0   0   0   0   0   0   0   0   0   0   0   0\n2005   0   0   0   0   0   0   0   0   0   0   0   0\n2006   0   0   0   0   0   0   0   0   0   0   0   0\n2007   0   0   0   0   0   0   0   0   0   0   0   0\n2008   0   0   0   0   0   0   0   0   0   0   0   0\n2009   0   0   0   1   0   0   0   0   0   0   0   0\n2010   0   0   0   0   0   0   0   0   0   0   0   0\n2011   0   0   0   0   0   0   0   0   0   0   0   0\n2012   0   0   0   0   0   0   0   0   0   0   0   0\n2013   0   0   0   0   0   0   0   0   0   0   0   0\n2014   0   0   0   0   0   0   0   0   0   0   0   0\n2015   0   0   0   0   0   0   0   0   0   0   0   0\n2016   0   0   0   0   0   0   0   0   0   0   0   0\n2017   0   0   0   0   0   0   0   0   0   0   0   0\n2018   0   0   0   0   0   0   0   0   0   0   0   0\n2019   0   0   0   0   0   0   0   0   0   0   0   0\n2020   0                                            \n\n\n\n\n\nPour tracer un graphique il suffit maintenant d’utiliser les fonctions plot() et lines()\n\nplot(ts_object * 2)\nlines(ts_object, col = \"red\")"
  },
  {
    "objectID": "2022/ast/TP/1_Manipulation_series_temporelles.html#séries-multivariées",
    "href": "2022/ast/TP/1_Manipulation_series_temporelles.html#séries-multivariées",
    "title": "1 - Traitement des séries temporelles sous R",
    "section": "Séries multivariées",
    "text": "Séries multivariées\nDe la même façon que précédemment on peut créer une série temporelle multivariée. Cette fois-ci l’objet créé est à la fois mts, ts et matrix\n\nset.seed(1)\n# On génère 300 observations d'une loi normale (0, 1)\nloi_normale <- rnorm(300)\nmts <- ts(matrix(loi_normale, nrow = 100, ncol = 3),\n          start = c(1961, 1), frequency = 12)\n\nOn peut accéder à la première variable de la même façon que dans une matrice : par son nom ou son numéro de colonne :\n\ncolnames(mts)\n\n[1] \"Series 1\" \"Series 2\" \"Series 3\"\n\n# mts[,1] # ou de façon équivalente :\nmts[, \"Series 1\"]\n\n              Jan          Feb          Mar          Apr          May\n1961 -0.626453811  0.183643324 -0.835628612  1.595280802  0.329507772\n1962 -0.621240581 -2.214699887  1.124930918 -0.044933609 -0.016190263\n1963  0.619825748 -0.056128740 -0.155795507 -1.470752384 -0.478150055\n1964 -0.394289954 -0.059313397  1.100025372  0.763175748 -0.164523596\n1965 -0.112346212  0.881107726  0.398105880 -0.612026393  0.341119691\n1966  2.401617761 -0.039240003  0.689739362  0.028002159 -0.743273209\n1967  0.610726353 -0.934097632 -1.253633400  0.291446236 -0.443291873\n1968  0.593946188  0.332950371  1.063099837 -0.304183924  0.370018810\n1969 -1.276592208 -0.573265414 -1.224612615 -0.473400636             \n              Jun          Jul          Aug          Sep          Oct\n1961 -0.820468384  0.487429052  0.738324705  0.575781352 -0.305388387\n1962  0.943836211  0.821221195  0.593901321  0.918977372  0.782136301\n1963  0.417941560  1.358679552 -0.102787727  0.387671612 -0.053805041\n1964 -0.253361680  0.696963375  0.556663199 -0.688755695 -0.707495157\n1965 -1.129363096  1.433023702  1.980399899 -0.367221476 -1.044134626\n1966  0.188792300 -1.804958629  1.465554862  0.153253338  2.172611670\n1967  0.001105352  0.074341324 -0.589520946 -0.568668733 -0.135178615\n1968  0.267098791 -0.542520031  1.207867806  1.160402616  0.700213650\n1969                                                                 \n              Nov          Dec\n1961  1.511781168  0.389843236\n1962  0.074564983 -1.989351696\n1963 -1.377059557 -0.414994563\n1964  0.364581962  0.768532925\n1965  0.569719627 -0.135054604\n1966  0.475509529 -0.709946431\n1967  1.178086997 -1.523566800\n1968  1.586833455  0.558486426\n1969                          \n\n\nEt avec les même fonctions que pour les matrices on peut récupérer les noms des colonnes (colnames), le nombre de variables (ncol), etc.\n\n\n\n\n\n\nAttention\n\n\n\nUne source classique d’erreur est de manipuler des séries-temporelles uni et multivariées et de vouloir utiliser les fonctions liées aux matrices sur les séries univariées. Par exemple, colnames(ts_object) renverra toujours l’objet NULL. Une solution est de tester si l’objet est multivarié avec la fonction is.mts()."
  },
  {
    "objectID": "2022/ast/TP/1_Manipulation_series_temporelles.html#manipulation-basiques",
    "href": "2022/ast/TP/1_Manipulation_series_temporelles.html#manipulation-basiques",
    "title": "1 - Traitement des séries temporelles sous R",
    "section": "Manipulation basiques",
    "text": "Manipulation basiques\nPour concaténer plusieurs séries temporelles, les fonctions deux fonctions suivantes peuvent ts.union() et ts.intersect().\n\nts_object2 <- ts(1:10, frequency = 4, start = c(1960, 1))\nts.union(ts_object, ts_object2) # on garde toute la couverture temporelle en rajoutant des NA\n\n        ts_object ts_object2\n1959 Q2         1         NA\n1959 Q3         2         NA\n1959 Q4         3         NA\n1960 Q1         4          1\n1960 Q2         5          2\n1960 Q3         6          3\n1960 Q4         7          4\n1961 Q1         8          5\n1961 Q2         9          6\n1961 Q3        10          7\n1961 Q4        NA          8\n1962 Q1        NA          9\n1962 Q2        NA         10\n\nts.intersect(ts_object, ts_object2) # on ne garde que les périodes communes\n\n        ts_object ts_object2\n1960 Q1         4          1\n1960 Q2         5          2\n1960 Q3         6          3\n1960 Q4         7          4\n1961 Q1         8          5\n1961 Q2         9          6\n1961 Q3        10          7\n\n\nOn va maintenant utiliser la série d’indice de production industrielle de la France (CVS-CJO) :\n\nipi_fr_manuf <- ts(c(99, 99.4, 99.7, 99.4, 100.8, 100, 98.7, 100.2, 101.2, \n100.6, 99.9, 100.9, 102.4, 100.8, 99.5, 100.7, 99.8, 99.1, 99.8, \n101.6, 100.4, 99.4, 102.8, 101, 100.2, 101.1, 102.6, 101.8, 103.7, \n103, 103.6, 103.5, 104.4, 105.6, 105.5, 105.9, 103.6, 102.9, \n103.8, 103.8, 102.5, 104.2, 104, 104.6, 103.4, 104.2, 103.4, \n103.7, 104.9, 105.8, 104.4, 104.3, 106, 103.7, 104.1, 103.1, \n103.9, 104.4), start = 2015, frequency = 12)\n\nPour calculer la série retardée/avancée, il suffit d’utiliser la fonction lag() :\n\n# série retardée d'un mois : en février 2010 on a la valeur de janvier 2010\nlag(ipi_fr_manuf, k = -1) \n\nLa fonction diff permet de calculer la différence entre deux périodes\n\ndiff(ipi_fr_manuf, k = 1)\n\n\n\n\n\n\n\nExercice\n\n\n\nÉcrire une fonction ev() qui calcule l’évolution mensuelle si la série en entrée est mensuelle, l’évolution trimestrielle si la série en entrée est trimestrielle, etc.\nLa fonction ev() transformera donc toute série \\(X_t\\) en : \\[\nY_t=\\frac{X_t-X_{t-1}}{\nX_{t-1}\n}=\\frac{X_t}{\nX_{t-1}\n} - 1\n\\]\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nev <- function(x){\n  result <- (x/stats::lag(x, k = -1) - 1) * 100\n  return(result)\n}\n# Ou de manière équivalente :\nev2 <- function(x){\n  # Attention ici c'est bien k = 1 dans la fonction diff\n  # et k = -1 dans la fonction lag\n  result <- (diff(x, k = 1) /lag(x, k = -1)) * 100\n  return(result)\n}\n\nRemarque : pour des raisons informatiques ces deux fonctions ne donnent pas exactement le même résultat. C’est un problème récurrent lorsque l’on souhaite tester l’égalité entre deux séries temporelles :\n\nall(ev(ipi_fr_manuf) == ev2(ipi_fr_manuf))\n\n[1] FALSE\n\n\nUne solution est plutôt d’utiliser la fonction all.equal() :\n\nisTRUE(all.equal(ev(ipi_fr_manuf), ev2(ipi_fr_manuf)))\n\n[1] TRUE"
  },
  {
    "objectID": "2022/ast/TP/1_Manipulation_series_temporelles.html#utilisation-de-xts",
    "href": "2022/ast/TP/1_Manipulation_series_temporelles.html#utilisation-de-xts",
    "title": "1 - Traitement des séries temporelles sous R",
    "section": "Utilisation de xts",
    "text": "Utilisation de xts\nUn des avantages du package xts est qu’il permet d’appliquer une fonction à chaque période d’une série temporelle (par exemple à toutes les données trimestrielles, annuelles, etc.). Il s’agit des fonctions apply.monthly(), apply.quarterly(), apply.yearly(), etc. Pour cela il faut auparavant convertir les données au format xts.\nPar exemple pour calculer la moyenne annuelle :\n\nlibrary(xts)\nmoy_an <- apply.yearly(as.xts(ipi_fr_manuf), mean)\nmoy_an\n\n              [,1]\ndéc 2015  99.98333\ndéc 2016 100.60833\ndéc 2017 103.40833\ndéc 2018 103.67500\noct 2019 104.46000\n\n\n\n\n\n\n\n\nExercice\n\n\n\nCalculer l’évolution trimestrielle de ipi_fr_manuf.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTout d’abord on prolonge l’IPI par des valeurs manquantes jusqu’à la fin de l’année, sinon la dernière somme sur le trimestre est fausse.\n\nipi_fr_manuf_prolonge <- window(ipi_fr_manuf, end = c(2019, 12), extend = TRUE)\nsomme_trim <- apply.quarterly(as.xts(ipi_fr_manuf_prolonge), sum)\n\nAttention la fonction lag n’agit pas pareil pour les objets xts et ts : il faut ici utiliser l’option k = 1. Voir l’aide associée à ?lag.xts. Pour garder la même convention entre lag.ts() et lag.xts() on peut utiliser l’option options(xts.compat.zoo.lag=TRUE).\n\nevol_trim <- (somme_trim/lag(somme_trim, k = 1) - 1) * 100\n\nOn peut utiliser la fonction format() si l’on veut convertir automatiquement en un objet ts :\n\nstart_year <- as.numeric(format(start(evol_trim), \"%Y\"))\nstart_quarter <- as.numeric(substr(quarters(start(evol_trim)), 2, 2))\nts(evol_trim, start = c(start_year, start_quarter), frequency = 4)\n\n            Qtr1        Qtr2        Qtr3        Qtr4\n2015          NA  0.70446159 -0.03331113  0.43318894\n2016  0.43132050 -1.02411629  0.73431242  0.46388337\n2017  0.23087071  1.51365581  0.97244733  1.76565008\n2018 -2.11356467  0.06445375  0.48309179 -0.22435897\n2019  1.22068744 -0.34909553 -0.92356688          NA\n\n\nOn peut aussi directement utiliser le package ts_box et la fonction ts_ts() :\n\ntsbox::ts_ts(evol_trim)\n\n            Qtr1        Qtr2        Qtr3        Qtr4\n2015                      NA  0.70446159 -0.03331113\n2016  0.43318894  0.43132050 -1.02411629  0.73431242\n2017  0.46388337  0.23087071  1.51365581  0.97244733\n2018  1.76565008 -2.11356467  0.06445375  0.48309179\n2019 -0.22435897  1.22068744 -0.34909553 -0.92356688\n2020          NA                                    \n\n\n\n\n\nOn aurait en fait pu le faire directement avec les fonctions de base R ! Par contre la situation aurait été plus compliquée avec des données haute fréquence (du type journalières) non gérées par ts :\n\naggregate(ipi_fr_manuf, nfrequency = 4,\n          FUN = mean)\n\n          Qtr1      Qtr2      Qtr3      Qtr4\n2015  99.36667 100.06667 100.03333 100.46667\n2016 100.90000  99.86667 100.60000 101.06667\n2017 101.30000 102.83333 103.83333 105.66667\n2018 103.43333 103.50000 104.00000 103.76667\n2019 105.03333 104.66667 103.70000"
  },
  {
    "objectID": "2022/ast/TP/1_Manipulation_series_temporelles.html#utilisation-de-zoo",
    "href": "2022/ast/TP/1_Manipulation_series_temporelles.html#utilisation-de-zoo",
    "title": "1 - Traitement des séries temporelles sous R",
    "section": "Utilisation de zoo",
    "text": "Utilisation de zoo\nLe package zoo donne un ensemble d’outils qui permettent de manipuler les séries-temporelles. De nombreux packages (dont xts) sont d’ailleurs basés sur ce format. Il permet notamment de faire des imputations de données manquantes selon différentes fonctions (toutes les fonctions commençant par na.) et de mieux gérer le format des dates associées aux séries temporelles (ce qui permet de faire des manipulations avec la fonction format, ce qui permet par exemple plus facilement exporter des séries temporelles sous Excel). Le calcul de l’évolution trimestrielle aurait par exemple pu être faite avec ce package :\n\nsomme_trim <- aggregate(as.zoo(ipi_fr_manuf_prolonge), yearqtr, sum)\nsomme_trim <- as.ts(somme_trim) #La conversion en ts est plus simple depuis un objet zoo\nevol_trim <- ev(somme_trim)\nevol_trim\n\n            Qtr1        Qtr2        Qtr3        Qtr4\n2015              0.70446159 -0.03331113  0.43318894\n2016  0.43132050 -1.02411629  0.73431242  0.46388337\n2017  0.23087071  1.51365581  0.97244733  1.76565008\n2018 -2.11356467  0.06445375  0.48309179 -0.22435897\n2019  1.22068744 -0.34909553 -0.92356688          NA\n\n\nPour le prochain exercice, utiliser la série suivante :\n\nserie_avec_NA <- ts(c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, 0, 0, 0, \n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, \n  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \n  NA, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, NA, NA, NA, NA, NA, \n  NA, NA, NA, NA, NA, NA), start = 2000, frequency = 12)\n\n\n\n\n\n\n\nExercice\n\n\n\nSur la série serie_avec_NA, utiliser les différentes fonctions du package zoo pour :\n\nEnlever les valeurs manquantes au début de la série ;\n\nRemplacer les valeurs manquantes à la fin de la série par la dernière valeur observée.\n\nInterpoler de manière linéaire les valeurs manquantes entre les 0 et les 1.\n\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nLes trois fonctions à utiliser sont : na.trim(), na.locf et na.approx(). Il faudra peut-être inverser deux étapes pour que cela marche.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nD’abord on enlève les valeurs manquantes au début de la série\n\netape_1 <- na.trim(serie_avec_NA, sides = \"left\")\netape_1\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2001   0   0   0   0   0   0   0   0   0   0   0   0\n2002   0   0   0   0   0   0   0   0   0   0   0   0\n2003  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n2004  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n2005   1   1   1   1   1   1   1   1   1   1   1   1\n2006   1   1   1   1   1   1   1   1   1   1   1   1\n2007  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n\n\nEnsuite on interpole\n\netape_2 <- na.approx(etape_1, na.rm = FALSE)\netape_2\n\n      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n2001 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2002 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2003 0.04 0.08 0.12 0.16 0.20 0.24 0.28 0.32 0.36 0.40 0.44 0.48\n2004 0.52 0.56 0.60 0.64 0.68 0.72 0.76 0.80 0.84 0.88 0.92 0.96\n2005 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n2006 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n2007   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA\n\n\nEnfin on remplace les valeurs à la fin de la série\n\netape_3 <- na.locf(etape_2)\netape_3\n\n      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n2001 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2002 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2003 0.04 0.08 0.12 0.16 0.20 0.24 0.28 0.32 0.36 0.40 0.44 0.48\n2004 0.52 0.56 0.60 0.64 0.68 0.72 0.76 0.80 0.84 0.88 0.92 0.96\n2005 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n2006 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n2007 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nÀ l’aide des fonctions as.yearmon() et format(), créer un data.frame contenant une colonne “date” qui contient les dates au format JJ/MM/YYYY et une deuxième colonnes avec les valeurs de ipi_fr_manuf.\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nLa fonction as.yearmon() doit être appliquée sur time(ipi_fr_manuf). Pour la fonction format regarder l’aide ?format.Date.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndates <- as.yearmon(time(ipi_fr_manuf))\ndates <- format(dates, \"%d/%m/%Y\")\ndonnees_formatees <- data.frame(date = dates, ipi = ipi_fr_manuf)\nhead(donnees_formatees)\n\n        date   ipi\n1 01/01/2015  99.0\n2 01/02/2015  99.4\n3 01/03/2015  99.7\n4 01/04/2015  99.4\n5 01/05/2015 100.8\n6 01/06/2015 100.0\n\n\n\n\n\nIl peut également être utile d’exporter un objet R ts ou mts vers un fichier Excel, tout en rajoutant une colonne “date” qui sera au format date. Ci-dessous un exemple en utilisant le package XLConnect :\n\nlibrary(XLConnect)\nts2xls <- function(x, file, sheet=\"Feuille 1\", format = \"dd/mm/yyyy\"){\n  wb <- loadWorkbook(file, create = TRUE)\n  createSheet(wb, sheet)\n  if(is.mts(x)){\n    col <- c(\"date\", colnames(x))\n  }else{\n    col <- c(\"date\", \"x\")\n  }\n  # Le titre\n  writeWorksheet(wb,matrix(col,nrow = 1),\n                 sheet = sheet,startCol = 1,startRow =1,\n                 header = FALSE)\n\n  # Petit trick pour que la colonne date soit au format date d'Excel\n  csDate <- getOrCreateCellStyle(wb, name = \"date\")\n  setDataFormat(csDate, format = format)\n  date <- as.Date(format(zoo::as.Date((time(x))), \"%d/%m/%Y\"),\n                  \"%d/%m/%Y\")\n  writeWorksheet(wb,date,sheet = sheet,\n                 startCol = 1,startRow = 2,\n                 header = FALSE)\n  setCellStyle(wb, sheet = sheet, row = seq_along(date)+1,\n               col = 1,\n               cellstyle = csDate)\n  # Fin colonne date\n\n  # Autres colonnes\n  writeWorksheet(wb,x,sheet = sheet,startCol = 2,startRow = 2,\n                 header = FALSE)\n  setColumnWidth(wb, sheet, column = seq_along(col), width = -1)\n  saveWorkbook(wb, file)\n}"
  },
  {
    "objectID": "2022/ast/TP/2_Graphiques.html",
    "href": "2022/ast/TP/2_Graphiques.html",
    "title": "2 - Analyse graphique",
    "section": "",
    "text": "L’objectif de ce TP est d’approfondir les analyses graphiques et les transformations pour stabiliser la variance.\nLes packages suivants seront utilisés :"
  },
  {
    "objectID": "2022/ast/TP/2_Graphiques.html#analyse-graphique-temporelle",
    "href": "2022/ast/TP/2_Graphiques.html#analyse-graphique-temporelle",
    "title": "2 - Analyse graphique",
    "section": "Analyse graphique temporelle",
    "text": "Analyse graphique temporelle\nLe but des prochains exercices est de mettre en pratique les différentes fonctions pour tracer les graphiques vues en cours.\n\n\n\n\n\n\nExercice\n\n\n\nEn utilisant la fonction help(), décrire les trois séries temporelles gold, woolyrnq et gas du package forecast. Quelles sont les périodicités des séries ?\nTracer les 3 séries. Repérer le point atypique sur la série gold : à quelle observation apparaît-il ? À quelle date cela correspond ?\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nOn pourra utiliser la fonction which.max() pour repérer le point atypique. La série gold correspond à la série journalière des prix de l’or hors vendredi samedi : pour récupérer les jours correspondants aux numéros des observations, on pourra utiliser la fonction seq.Date() ainsi que la fonction lubridate::wday().\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ngold représente les prix journaliers de l’or en dollar (hors vendredi et samedi) entre le 1er janvier 1985 et le 31 Mars 1989. Il semble y avoir des valeurs manquantes, un point atypique autour de l’observation 750. Une tendance plutôt à la hausse jusqu’à cette observation puis une tendance à la baisse. Pas de saisonnalité visible\n\nautoplot(gold, y = \"Prix en $\",\n         main = \"Prix journaliers de l'or\")\n\n\n\n\nwoolyrnq représente la production trimestrielle de laine en Australie (en tonnes) entre le premier trimestre 1965 et le troisième trimestre 1994.\n\nautoplot(woolyrnq, y = \"tonnes\",\n         main = \"Production trimestrielle de laine en Australie\")\n\n\n\n\ngas représente la production mensuelle de gaz en Australie entre janvier 1956 et août 1995\n\nautoplot(gas, main = \"Production mensuelle de gaz en Australie\")\n\n\n\n\n\n# Point atypique net pour la série gold à l'observation 770\nwhich.max(gold)\n\n[1] 770\n\ngold[which.max(gold)]\n\n[1] 593.7\n\ndates = seq(from = ymd(\"1985-01-01\"), to = ymd(\"1989-03-31\"), by = \"day\")\nhors_wd = dates[lubridate::wday(dates,week_start = 1) %in% c(1:4,7)] # on ne prend pas les jours 6 et 7 (samedi et dimanche)\nlength(hors_wd) - length(gold) # on a bien le même nombre d'observations\n\n[1] 0\n\nhors_wd[which.max(gold)]\n\n[1] \"1987-12-14\"\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nAnalyser les séries de fpp3::aus_arrivals (arrivées internationales trimestrielles en Australie) : évolution, tendance, saisonnalité et points atypiques (autoplot(), gg_season() et gg_subseries()).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\naus_arrivals %>% autoplot(Arrivals)\n\n\n\n\nLe nombre d’arrivées augmentent avec le temps, sauf ceux en provenance du Japon après 1995. Les séries semblent saisonnières avec une saisonnalité qui dépend du niveau (sauf pour US) et on observe un changement de saisonnalité pour les arrivées en provenance du Japon\n\naus_arrivals %>% gg_season(Arrivals)\n\n\n\n\nRemarque : le multivarié ne marche pas avec forecast. forecast::ggseasonplot(arrivals) donne une erreur.\nLa saisonnalité est différente entre chaque pays : arrivées plus élevées aux T1 et T4 pour le Royaume-Uni. elles sont plus faibles au T1 pour la Nouvelle-Zélande et au plus haut au T3. Pour le Japon : plus faibles aux T2 et T4 sur années récentes. Pour les États-Unis le graphique n’est pas facile à lire\n\naus_arrivals %>% gg_subseries(Arrivals)\n\n\n\n\nPour le Royaume-Uni la hausse des entrées est surtout saisonnière (forte hausse aux T1 et T3). Depuis les États-Unis et la Nouvelle-Zélande la hausse semble la même sur tous les trimestres.\nPlusieurs points atypiques s’observent, par exemple :\n\n2000T3 pour les US (JO)\n\n2001T3-T4 pour les US (11 septembre)\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nEn utilisant les différentes fonctions apprises pour tracer les graphiques (autoplot(), ggseasonplot() et ggsubseriesplot(), gglagplot() et ggAcf()) analyser la série fma::hsales (tendance, saisonnalité, cycle, points atypiques).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nautoplot(hsales)\n\n\n\n\nPas de tendance, il semble il y avoir une saisonnalité et un cycle\n\nggseasonplot(hsales)\n\n\n\n\nLes ventes semblent plus faibles en janv-déc et plus élevées en mars\n\nggsubseriesplot(hsales)\n\n\n\n\nOn retrouve en moyenne les résultats précédents mais les variations des coefficients saisonniers laissent penser à un cycle\n\ngglagplot(hsales)\n\n\n\n\nForte corrélation avec les valeurs précédentes et les valeurs saisonnières\n\nggAcf(hsales)\n\n\n\nggAcf(hsales, 12*7)\n\n\n\n\nEn augmentant le nombre de lag on repère plus facilement les cycles longs (environ 8 ans)."
  },
  {
    "objectID": "2022/ast/TP/2_Graphiques.html#densité-spectrale",
    "href": "2022/ast/TP/2_Graphiques.html#densité-spectrale",
    "title": "2 - Analyse graphique",
    "section": "Densité spectrale",
    "text": "Densité spectrale\nLe but de ces exercices est de calculer les densités spectrales des différentes composantes :\n\ntendance\n\ncycle\n\nsaisonnalité\n\nirrégulier\n\nAttention : par défaut la fonction spectrum enlève une tendance linéaire à la série ! Voir l’aide associée à la fonction ?spectrum.\n\n\n\n\n\n\nExercice\n\n\n\nCalculer le périodogramme et le spectre autorégressif d’une tendance.\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nIl faut utiliser les paramètres spectrum(., detrend = FALSE, log = \"no\").\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nt = ts(1:100, frequency = 12, start = 2000)\nspectrum(t, \n         detrend = FALSE,\n         method = \"pgram\", log = \"no\")\n\n\n\nspectrum(t, \n         method = \"ar\", log = \"no\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nCalculer le périodogramme et le spectre autorégressif d’une série mensuelle saisonnière.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ns = ts(0, frequency = 12, start = 2000, end = 2020)\ns[cycle(s) == 2] <- 1\nspectrum(s, \n         detrend = FALSE,\n         method = \"pgram\", log = \"no\")\n\n\n\nspectrum(s, \n         method = \"ar\", log = \"no\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nCalculer le périodogramme et le spectre autorégressif d’une cycle de 36 mois.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nc = ts(cos(2*pi/36*(1:100)) + sin(2*pi/36*(1:100)), frequency = 12, start = 2000)\nspectrum(c, \n         detrend = FALSE,\n         method = \"pgram\", log = \"no\")\n\n\n\nspectrum(c, \n         method = \"ar\", log = \"no\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nPourquoi a-t-on un spectre différent en simulant un cycle de cette façon ?\n\nc = ts(0, frequency = 12, start = 2000, end = 2020)\nc[cycle(c) == 12][c(TRUE, FALSE, FALSE)] <- 1\nc\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2000   0   0   0   0   0   0   0   0   0   0   0   1\n2001   0   0   0   0   0   0   0   0   0   0   0   0\n2002   0   0   0   0   0   0   0   0   0   0   0   0\n2003   0   0   0   0   0   0   0   0   0   0   0   1\n2004   0   0   0   0   0   0   0   0   0   0   0   0\n2005   0   0   0   0   0   0   0   0   0   0   0   0\n2006   0   0   0   0   0   0   0   0   0   0   0   1\n2007   0   0   0   0   0   0   0   0   0   0   0   0\n2008   0   0   0   0   0   0   0   0   0   0   0   0\n2009   0   0   0   0   0   0   0   0   0   0   0   1\n2010   0   0   0   0   0   0   0   0   0   0   0   0\n2011   0   0   0   0   0   0   0   0   0   0   0   0\n2012   0   0   0   0   0   0   0   0   0   0   0   1\n2013   0   0   0   0   0   0   0   0   0   0   0   0\n2014   0   0   0   0   0   0   0   0   0   0   0   0\n2015   0   0   0   0   0   0   0   0   0   0   0   1\n2016   0   0   0   0   0   0   0   0   0   0   0   0\n2017   0   0   0   0   0   0   0   0   0   0   0   0\n2018   0   0   0   0   0   0   0   0   0   0   0   1\n2019   0   0   0   0   0   0   0   0   0   0   0   0\n2020   0                                            \n\nspectrum(c, \n         method = \"pgram\", log = \"no\")\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCar la série construire reste saisonnière (même valeurs dans les mois autres que décembre) !\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nCalculer le périodogramme d’un bruit blanc (utiliser rnorm()).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nset.seed(1)\ni = ts(rnorm(100), frequency = 12, start = 2000)\nspectrum(i, \n         detrend = FALSE,\n         method = \"pgram\", log = \"no\")\n\n\n\nspectrum(i, \n         method = \"ar\", log = \"no\")\n\n\n\n\nQuestion supplémentaire : à quoi correspond la droite du graphique précédent ?\nCela correspond à \\(\\mathbb V[i]/frequence \\simeq\\) 0,067."
  },
  {
    "objectID": "2022/ast/TP/3_Decomposition.html",
    "href": "2022/ast/TP/3_Decomposition.html",
    "title": "3 - Décomposition d’une série temporelle",
    "section": "",
    "text": "L’objectif de ce TP est d’introduire aux méthodes de décomposition.\n\nDans ce TP nous utiliserons notamment les niveaux bruts des indices de production industrielle (IPI) publiés le 04 novembre 2022 par l’Insee, fichier de données téléchargeable ici : https://www.insee.fr/fr/statistiques/6655844.\nLes packages suivants seront utilisés :\n\npackages_to_install <- c(\"ggplot2\", \"forecast\", \"RJDemetra\", \"ggdemetra\", \"dygraphs\")\n\npackages <- installed.packages()[,\"Package\"][! packages_to_install %in% installed.packages()[,\"Package\"]]\nif (length(packages) > 0) {\n    install.packages(packages)\n}\n\n\n\n\n\n\n\nExercice\n\n\n\nTélécharger et importer les données d’IPI et créer un objet mts qui contient les indices bruts.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nif (!file.exists(\"IPI.xls\")) {\n    download.file(\"https://www.insee.fr/fr/statistiques/fichier/6655844/IPI_202209.xls\", \"IPI.xls\")\n}\nipi <- readxl::read_excel(\"IPI.xls\", sheet = \"niveaux bruts-Raw levels\")\nipi[1, 1]\n\n# A tibble: 1 × 1\n  `NAF rev. 2`\n         <dbl>\n1       199001\n\nipi <- ts(ipi[, -1], start = 1990, frequency = 12)\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nÉtudier les séries de l’IPI dans l’industrie manufacturière (\"CZ\"), dans le textile, habillement, cuir (\"[CB]\") : quelle type de décomposition serait adaptée ? Comparer les résultats de la série désaisonnalisée avec stl(s.window = 7), stl(s.window = \"periodic\") et RJDemetra::x13() avec et sans correction de jours ouvrables (on pourra utiliser la fonction forecast::seasadj() pour extraire la série désaisonnalisée issue de STL et ggdemetra::seasonaladj() pour extraire celle de X-13). Comparer également autour d’une année bissextile.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(forecast)\nlibrary(RJDemetra)\nlibrary(ggdemetra)\nlibrary(ggplot2)\nlibrary(patchwork)\nipi_cz <- ipi[, \"CZ\"]\nipi_cb <- ipi[, \"[CB]\"]\nautoplot(ipi_cz) +\n    labs(y = \"Indice\", title = \"IPI dans l'industrie manufacturière\")\n\n\n\n\nOn repère une tendance à la hausse jusqu’en 2009, une rupture lors de la crise financière puis une tendance qui parait relativement stable. La saisonnalité ne semble pas proportionnelle au niveau, le schéma de décomposition est sûrement additif.\n\ncz_stl_mobile <- stl(ipi_cz, s.window = 7)\ncz_stl_fixed <- stl(ipi_cz, s.window = \"periodic\")\ncz_x13_sans_cjo <- x13(ipi_cz, \"RSA3\")\ncz_x13_avec_cjo <- x13(ipi_cz, \"RSA5c\")\n\n(autoplot(seasadj(cz_stl_fixed), ylab = NULL, main = \"STL saisonnalité fixée\")  +\n        autoplot(seasadj(cz_stl_mobile), ylab = NULL, main = \"STL s.window=7\")) /\n    (autoplot(seasonaladj(cz_x13_sans_cjo), ylab = NULL, main = \"X-13 sans CJO\") +\n        autoplot(seasonaladj(cz_x13_avec_cjo), ylab = NULL, main = \"X-13 avec CJO\"))\n\n\n\n\nLa saisonnalité évolue sûrement dans le temps : STL avec une saisonnalité fixe conduit à des estimations erratiques. Une partie de la variabilité restante provient des effets jours ouvrables.\nIl y a un effet jours ouvrables et un effet année bissextile : la production est plus importante lorsque l’on a un jour de plus dans le mois (ce qui parait logique). Avec STL, l’indice désaisonnalisé devrait donc être sur-estimé en février dans les années bissextiles et sous-estimé les autres années.\n\ncz_x13_avec_cjo$regarima\n\ny = regression model + arima (2, 1, 1, 0, 1, 1)\nLog-transformation: no\nCoefficients:\n          Estimate Std. Error\nPhi(1)      0.0461      0.105\nPhi(2)      0.2134      0.070\nTheta(1)   -0.5000      0.101\nBTheta(1)  -0.6856      0.040\n\n             Estimate Std. Error\nMonday         0.5674      0.223\nTuesday        0.9162      0.222\nWednesday      0.9361      0.222\nThursday       0.1098      0.221\nFriday         0.9240      0.222\nSaturday      -1.6803      0.222\nLeap year      2.2923      0.693\nEaster [1]    -2.3645      0.446\nTC (4-2020)  -20.4000      1.992\nTC (3-2020)  -20.8289      2.002\nAO (5-2011)   12.9309      1.841\nLS (11-2008) -12.3788      1.633\n\n\nResidual standard error: 2.202 on 363 degrees of freedom\nLog likelihood = -843.2, aic =  1720 aicc =  1722, bic(corrected for length) = 1.829\n\nsa_data <- ts.union(seasadj(cz_stl_mobile), seasonaladj(cz_x13_avec_cjo))\ncolnames(sa_data) <- c(\"STL\", \"X13\")\nautoplot(window(sa_data, start = 1995, end = c(1997, 12)),\n         ylab = \"\", \n         main = \"Série désaisonnalisée IPI CZ autour de l'année bissextile de 1996\") + \n    geom_vline(xintercept = c(1996) + 1/12,linetype = 2)\n\n\n\n\nLes coefficients saisonniers semblent surtout évolutifs en juin, août et décembre, ce qui explique également que supposer la saisonnalité stable dans le temps conduit à des estimations bruitées.\n\nplot(cz_x13_avec_cjo$decomposition)\n\n\n\n\nPassons maintenant à la série d’IPI-CB.\n\nautoplot(ipi_cb) + \n    labs(y = \"Indice\", title = \"IPI dans le textile, habillement, cuir (CB)\")\n\n\n\n\nOn repère une tendance à la baisse jusqu’en 2010 puis une tendance relativement stable. La saisonnalité semble proportionnelle au niveau, le schéma de décomposition est sûrement multiplicatif. Il faudra passer au log la série pour STL (schéma de décomposition non géré automatiquement).\n\ncb_stl_mobile <- stl(log(ipi_cb), s.window = 7)\ncb_stl_fixed <- stl(log(ipi_cb), s.window = \"periodic\")\ncb_x13_sans_cjo <- x13(ipi_cb, \"RSA3\")\ncb_x13_avec_cjo <- x13(ipi_cb, \"RSA5c\")\n\np <- (autoplot(exp(seasadj(cb_stl_fixed)), ylab = NULL, main = \"STL saisonnalité fixée\")  + \n        autoplot(exp(seasadj(cb_stl_mobile)), ylab = NULL, main = \"STL s.window=7\")) /\n    (autoplot(seasonaladj(cb_x13_sans_cjo), ylab = NULL, main = \"X-13 sans CJO\") + \n        autoplot(seasonaladj(cb_x13_avec_cjo), ylab = NULL, main = \"X-13 avec CJO\"))\np\n\n\n\n\nIl est difficile d’analyser les graphiques mais il semble que l’on a les mêmes constats que précédemment : STL avec une saisonnalité fixe conduit à des estimations erratiques et une partie de la variabilité restante semble provenir des effets jours ouvrables. On peut refaire le graphique après 2010 en utilisant par exemple la fonction & de patchwork qui permet d’appliquer à élément à tous les graphiques (de la même façon on aurait pu utiliser la fonction window sur les données en entrée).\n\np &  coord_cartesian(xlim = c(2010, 2019),\n                     ylim = c(85, 130))\n\n\n\n\nMême constat que précédemment sur l’année bissextile même si sur l’exemple (1996) la différence n’est pas très forte.\n\ncb_x13_avec_cjo$regarima\n\ny = regression model + arima (3, 1, 1, 0, 1, 0)\nLog-transformation: no\nCoefficients:\n         Estimate Std. Error\nPhi(1)    -0.3753      0.063\nPhi(2)    -0.1075      0.060\nPhi(3)    -0.2599      0.057\nTheta(1)  -0.9478      0.033\n\n             Estimate Std. Error\nMonday         0.9095      0.691\nTuesday        1.0802      0.692\nWednesday      2.3714      0.700\nThursday       0.2554      0.692\nFriday         0.7146      0.701\nSaturday      -2.8858      0.689\nLeap year      1.1978      2.213\nEaster [1]    -5.0870      1.424\nTC (3-2020)  -41.5459      6.539\nLS (1-1996)  -33.9004      5.778\nTC (7-1991)   37.1581      6.258\nLS (2-2004)   25.4803      5.846\nLS (7-1993)   32.3702      5.781\nTC (10-1993) -29.3495      6.286\nLS (4-1997)   26.9281      5.889\nTC (5-1991)  -26.1855      6.274\nAO (4-2020)  -28.3794      6.443\n\n\nResidual standard error:  9.46 on 358 degrees of freedom\nLog likelihood = -1393, aic =  2831 aicc =  2834, bic(corrected for length) = 4.822\n\nsa_data <- ts.union(exp(seasadj(cb_stl_mobile)), seasonaladj(cb_x13_avec_cjo))\ncolnames(sa_data) <- c(\"STL\", \"X13\")\nautoplot(window(sa_data, start = 1995, end = c(1997, 12)),\n         ylab = \"\", \n         main = \"Série désaisonnalisée IPI CB autour de l'année bissextile de 1996\") + \n    geom_vline(xintercept = c(1996) + 1/12,linetype = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nMême exercice sur la série co2 : quel schéma de décomposition parait plausible ? Quel spécification parait adaptée ? On pourra utiliser la fonction le package dygraphs pour comparer les séries.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nautoplot(co2, main = \"Concentration atmosphérique de CO2 à Mauna Loa\")\n\n\n\n\nSérie déjà étudiée : une tendance linéaire mais la saisonnalité n’est pas proportionnelle au niveau. Aucune transformation n’est nécessaire. Pas de raison de faire de la cjo. On repère une tendance à la hausse jusqu’en 2009, une rupture lors de la crise financière puis une tendance qui parait relativement stable. La saisonnalité ne semble pas proportionnelle au niveau, le schéma de décomposition est sûrement additif.\n\nco2_stl_mobile <- stl(co2, s.window = 7)\nco2_stl_fixed <- stl(co2, s.window = \"periodic\")\nco2_x13 <- x13(co2, \"RSA3\")\nco2_x13$regarima # Un schéma multiplicatif est retenu mais cela ne devrait pas changer les résultats\n\ny = regression model + arima (0, 1, 1, 0, 1, 1)\nLog-transformation: yes\nCoefficients:\n          Estimate Std. Error\nTheta(1)   -0.3598      0.044\nBTheta(1)  -0.9116      0.022\n\n\nResidual standard error: 0.0008342 on 452 degrees of freedom\nLog likelihood =  2569, aic = 164.9 aicc = 164.9, bic(corrected for length) = -14.15\n\nco2_x13_add <- x13(co2, \"RSA0\")\ndata_cvs <- ts.union(seasadj(co2_stl_fixed),\n                     seasadj(co2_stl_mobile),\n                     seasonaladj(co2_x13),\n                     seasonaladj(co2_x13_add))\ndata_tc <- ts.union(forecast::trendcycle(co2_stl_fixed),\n                    forecast::trendcycle(co2_stl_mobile),\n                    ggdemetra::trendcycle(co2_x13),\n                    ggdemetra::trendcycle(co2_x13_add))\ndata_s <- ts.union(forecast::seasonal(co2_stl_fixed),\n                   forecast::seasonal(co2_stl_mobile),\n                   ggdemetra::seasonal(co2_x13),\n                   ggdemetra::seasonal(co2_x13_add))\ncolnames(data_cvs) <-  colnames(data_tc) <- colnames(data_s) <-\n    c(\"STL sais. fixée\", \"STL\", \"X-13 (Multiplicatif)\", \"X-13 (Additif)\")\nautoplot(data_cvs, main = \"Série désaisonnalisée\")\n\n\n\nautoplot(data_tc, main = \"Tendance-Cycle\")\n\n\n\nautoplot(data_s, main = \"Composante saisonnière\")\n\n\n\n\nGraphique peu visible mais les résultats semblent proches. Le package dygraphs permet de faire un graphique interactif qui pourra permettre.\n\nlibrary(dygraphs)\ndygraph(data_cvs, main = \"Série désaisonnalisée\") %>%\n    dyRangeSelector()\n\n\n\n\ndygraph(data_tc, main = \"Tendance-Cycle\") %>%\n    dyRangeSelector()\n\n\n\n\n\nEn zoomant on note que les résultats sur la tendance-cycle sont très proches entre les différentes méthodes. Les différences sur la série désaisonnalisée provient essentiellement de la composante saisonnière qui évolue légèrement dans le temps :\n\nfeasts::gg_season(tsibble::as_tsibble(data_s))"
  },
  {
    "objectID": "2022/ast/TP/4_Lissage_Exponentiel.html",
    "href": "2022/ast/TP/4_Lissage_Exponentiel.html",
    "title": "4 - Lissage exponentiel",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à appliquer les modèles ETS\n\nLes packages suivants seront utilisés :\n\npackages_to_install <- c(\"ggplot2\", \"forecast\", \"RJDemetra\", \"ggdemetra\")\n\npackages <- installed.packages()[,\"Package\"][! packages_to_install %in% installed.packages()[,\"Package\"]]\nif (length(packages) > 0) {\n    install.packages(packages)\n}\nlibrary(forecast)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n\n\n\n\n\n\nExercice\n\n\n\nEtudier les séries co2 et UKgas : quel modèle parait le plus adapté ? Faut-il transformer la série ? Comparer les prévisions en utilisant des schémas additifs et multiplicatifs et en transformant ou non la série.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nautoplot(co2) + autoplot(UKgas)\n\n\n\n\nLes deux séries ont une tendance et une saisonnalité. La saisonnalité parait additive pour co2 et multiplicative pour UKGas. Pas de raison de transformer les séries.\n\nets_co2_add <- ets(co2, model = \"ZZA\")\nets_co2_mult <- ets(co2, model = \"ZZM\")\nets_co2_add\n\nETS(M,A,A) \n\nCall:\n ets(y = co2, model = \"ZZA\") \n\n  Smoothing parameters:\n    alpha = 0.5995 \n    beta  = 0.0065 \n    gamma = 0.129 \n\n  Initial states:\n    l = 315.2927 \n    b = 0.0772 \n    s = -0.8309 -1.8609 -3.0483 -2.782 -1.2615 0.7793\n           2.1909 2.7066 2.1724 1.2282 0.6624 0.0439\n\n  sigma:  9e-04\n\n     AIC     AICc      BIC \n1748.989 1750.349 1819.513 \n\nets_co2_mult\n\nETS(M,Ad,M) \n\nCall:\n ets(y = co2, model = \"ZZM\") \n\n  Smoothing parameters:\n    alpha = 0.6824 \n    beta  = 0.0415 \n    gamma = 3e-04 \n    phi   = 0.9773 \n\n  Initial states:\n    l = 315.3348 \n    b = 0.1077 \n    s = 0.9972 0.9939 0.9904 0.9909 0.9963 1.0024\n           1.0069 1.0088 1.0074 1.004 1.0018 0.9999\n\n  sigma:  8e-04\n\n     AIC     AICc      BIC \n1721.105 1722.628 1795.777 \n\nautoplot(window(co2, start = 1993), y = \"Millions de thermies\") +\n    autolayer(forecast(ets_co2_add, h = 60, PI = FALSE), \"ETS(M,A,A)\") +\n    autolayer(forecast(ets_co2_mult, h = 60, PI = FALSE), \"ETS(M,Ad,M)\")\n\n\n\n\nLes prévisions très proches sur le court terme mais s’éloignent sur le long terme. Cela vient notamment la tendance est amortie dans le modèle multiplicatif.\n\nets_gas_add <- ets(UKgas, model = \"ZZA\")\nets_gas_mult <- ets(UKgas, model = \"ZZM\")\nets_gas_add_log <- ets(UKgas, model = \"ZZA\", lambda = 0)\nets_gas_add_log_unb <- ets(UKgas, model = \"ZZA\", lambda = 0, biasadj = TRUE)\n\nautoplot(window(UKgas, start = 1970), y = \"co2\") +\n    autolayer(forecast(ets_gas_add, h = 24, PI = FALSE), \"ETS(A,A,A)\") +\n    autolayer(forecast(ets_gas_mult, h = 24, PI = FALSE), \"ETS(M,A,M)\") +\n    autolayer(forecast(ets_gas_add_log, h = 24, PI = FALSE), \"ETS(A,A,A) sur log(UKgas)\") \n\n\n\n\nIci la différence entre multiplicatif et additif est plus nette : Dans les deux modèles on prévoit une hausse de la tendance mais les amplitudes croissent de manière exponentielle dans le modèle multiplicatif alors qu’elles restent constantes dans le cas additif (ce qui est logique). Passer au log ne semble pas avoir beaucoup d’impact.\nSur le plus long terme les résultats sont en revanche différents. Passer au log conduit à des estimations plus importantes (notamment lorsque l’on corrige du bais. Rappels : sans correction du biais cela revient à avoir une estimation de la médiane plutôt que moyen, ce qui n’est pas forcément incohérent). C’est logique car lorsque l’on passe au log cela revient à supposer que la tendance est également multiplicative.\n\nautoplot(window(UKgas, start = 1985), y = \"co2\")  +\n    autolayer(forecast(ets_gas_mult, h = 60, PI = FALSE), \"ETS(M,A,M)\") +\n    autolayer(forecast(ets_gas_add_log, h = 60, PI = FALSE), \"ETS(A,A,A) sur log(UKgas)\") +\n    autolayer(forecast(ets_gas_add_log_unb, h = 60, PI = FALSE), \"ETS(A,A,A) sur log(UKgas) corrigé biais\")\n\n\n\n\nAppliquer le modèle \\(ETS(A,A,A)\\) sur la série en logarithme et utiliser le modèle \\(ETS(M,M,M)\\) donnent des résultats similaires.\n\nautoplot(window(UKgas, start = 1985), y = \"co2\")  +\n    autolayer(forecast(ets_gas_add_log, h = 60, PI = FALSE), \"ETS(A,A,A) sur log(UKgas)\") +\n    autolayer(forecast(ets(UKgas, model = \"MMM\"), h = 60, PI = FALSE), \"ETS(M,M,M)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nL’objectif de cette exercice est d’étudier la série AirPassengers en utilisant plusieurs méthodes :\n\nEnlever les 12 derniers mois de AirPassengers.\nDésaisonnaliser la série en utilisant stl(., s.window = \"periodic\") (après transformation de la série) et RJDemetra::x13(., spec = RJDemetra::x13_spec(easter.enabled = FALSE, transform.function = \"Log\")).\nAppliquer un modèle ETS sur la série désaisonnalisée.\nPrévoir la série désaisonnalisée sur 12 mois puis la série brute réintroduisant :\n\n\nla saisonnalité sur la dernière année pour la méthode STL (peut se faire en une étape avec la fonction forecast::stlf()) ;\nles prévisions de la saisonnalité pour la méthode X-13-ARIMA.\n\n\nComparer les prévisions des précédentes méthodes avec un ETS directement calculé sur la série désaisonnalisée (avec ou sans transformation de Box-Cox).\nQu’en est-il de la prévision en temps-réel (en utilisant la fonction tsCV()) ?\n\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nPour récupérer la composante saisonnière avec X-13 on pourra utiliser le code suivant\n\nlibrary(RJDemetra)\ny <- window(ipi_c_eu[,\"FR\"], start = 2010)\nx13_spec <- x13_spec(easter.enabled = FALSE, transform.function = \"Log\")\nmod_x13 <- x13(y, x13_spec)\nggdemetra::seasonal(mod_x13)\n\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2010 0.9479753 0.9734184 1.1314166 1.0194466 0.9149364 1.1040334 1.0253971\n2011 0.9486036 0.9738929 1.1146702 0.9990949 0.9435734 1.0943653 0.9971672\n2012 0.9744944 0.9952811 1.0894809 0.9994940 0.9609052 1.0773442 1.0308806\n2013 0.9881143 0.9734166 1.0586928 1.0414531 0.9661151 1.0343284 1.0633799\n2014 0.9887445 0.9708317 1.0618924 1.0340629 0.9456969 1.0716857 1.0449424\n2015 0.9611904 0.9664643 1.0947446 1.0268935 0.9248260 1.1112972 1.0452371\n2016 0.9336952 0.9939049 1.1148269 1.0091687 0.9628352 1.0902251 0.9872514\n2017 0.9643035 0.9598990 1.1181909 0.9641950 1.0015167 1.0999538 0.9910340\n2018 0.9940038 0.9589041 1.0890126 0.9941445 0.9936340 1.0782580 1.0244067\n2019 0.9762525 0.9595422 1.0576157 1.0265143 1.0011358 1.0398603 1.0629867\n2020 0.9768492 0.9563783 1.0931460 1.0048644 0.9500369 1.1224476 1.0549500\n           Aug       Sep       Oct       Nov       Dec\n2010 0.7473449 1.0778667 1.0402228 1.0450781 0.9908451\n2011 0.7725295 1.0855555 1.0436457 1.0336021 0.9645023\n2012 0.7668908 1.0190248 1.1114204 1.0328655 0.9392665\n2013 0.7511679 1.0558980 1.0943162 1.0101039 0.9672872\n2014 0.7347217 1.0923548 1.0977123 0.9715733 0.9995163\n2015 0.7410440 1.0774877 1.0685360 1.0097237 0.9855990\n2016 0.7929649 1.0745879 1.0421123 1.0381299 0.9631477\n2017 0.7846862 1.0498446 1.0744776 1.0308174 0.9322877\n2018 0.7891563 1.0084274 1.1117543 1.0382887 0.9294119\n2019 0.7697163 1.0458578 1.0967583 1.0142887 0.9512178\n2020 0.7506828 1.0740572 1.0727587 1.0092022 0.9628865\n\nggdemetra::seasonaladj(mod_x13)\n\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2010  95.25565  95.64233  96.78133  98.48481 104.37885 101.26505  98.30338\n2011 104.36394 104.32359 103.43866 101.69204 116.68408  99.14422 101.28692\n2012 101.89900 100.37365 101.24088  99.85052 100.00987 100.71062 100.69062\n2013  97.45836  98.31350  98.13990  99.28435  99.57405 101.99855  98.92984\n2014  97.90194 100.01734  98.78591  99.51039  97.70572  97.78987  98.85712\n2015  98.41963  99.43461  99.01853  99.71823  98.39689 100.60315  96.72447\n2016 101.85337 100.21080  97.14512 102.36148 102.40590 101.17176  97.03709\n2017 102.56108 101.15647 102.39754 101.63919 102.54447 101.27698 100.40019\n2018 102.41410 102.82571 103.67189 103.60666  99.33235 104.61318 104.06023\n2019 106.32495 106.30070 105.52037 104.43109 105.08065 101.93677 103.29386\n2020 103.39364 104.66569  83.97780  66.37711  77.57594  87.48738  92.32665\n           Aug       Sep       Oct       Nov       Dec\n2010  99.68623 101.12568 100.93991  98.27017 102.84151\n2011 101.35535 101.33060 101.95031 102.84422 103.88777\n2012 102.75257 100.97889  96.81305  98.65757  97.41645\n2013  97.71450  97.83142  99.87972  98.00971  97.79929\n2014  97.31577  98.13661  98.11314  98.29418  98.44762\n2015 102.69296 101.25406 100.79212 100.81966 101.35969\n2016 100.50886 100.41059  99.22155 100.85443 103.51476\n2017 103.73573 103.06287 105.35353 107.68154 106.72671\n2018 104.66875 103.82503 104.33960 105.55831 105.01264\n2019 102.37538 104.22067 106.22213 102.53491 102.81557\n2020  95.51304  97.48084  99.46319 100.67358 100.32336\n\nggdemetra::seasonal(mod_x13, forecast = TRUE)\n\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2021 0.9240691 0.9625840 1.1283879 1.0116767 0.9542506 1.1122949 1.0301236\n           Aug       Sep       Oct       Nov       Dec\n2021 0.7736290 1.0661433 1.0421204 1.0454394 0.9628614\n\n\nSi l’on veut une version plus rapide du code on peut également utiliser cette option :\n\nmod_jx13 <- jx13(y, x13_spec)\nsaisonnalite <- get_indicators(mod_jx13, c(\"s\", \"sa\", \"s_f\", \"y_f\"))\nsaisonnalite[[\"s\"]]\n\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2010 0.9479753 0.9734184 1.1314166 1.0194466 0.9149364 1.1040334 1.0253971\n2011 0.9486036 0.9738929 1.1146702 0.9990949 0.9435734 1.0943653 0.9971672\n2012 0.9744944 0.9952811 1.0894809 0.9994940 0.9609052 1.0773442 1.0308806\n2013 0.9881143 0.9734166 1.0586928 1.0414531 0.9661151 1.0343284 1.0633799\n2014 0.9887445 0.9708317 1.0618924 1.0340629 0.9456969 1.0716857 1.0449424\n2015 0.9611904 0.9664643 1.0947446 1.0268935 0.9248260 1.1112972 1.0452371\n2016 0.9336952 0.9939049 1.1148269 1.0091687 0.9628352 1.0902251 0.9872514\n2017 0.9643035 0.9598990 1.1181909 0.9641950 1.0015167 1.0999538 0.9910340\n2018 0.9940038 0.9589041 1.0890126 0.9941445 0.9936340 1.0782580 1.0244067\n2019 0.9762525 0.9595422 1.0576157 1.0265143 1.0011358 1.0398603 1.0629867\n2020 0.9768492 0.9563783 1.0931460 1.0048644 0.9500369 1.1224476 1.0549500\n           Aug       Sep       Oct       Nov       Dec\n2010 0.7473449 1.0778667 1.0402228 1.0450781 0.9908451\n2011 0.7725295 1.0855555 1.0436457 1.0336021 0.9645023\n2012 0.7668908 1.0190248 1.1114204 1.0328655 0.9392665\n2013 0.7511679 1.0558980 1.0943162 1.0101039 0.9672872\n2014 0.7347217 1.0923548 1.0977123 0.9715733 0.9995163\n2015 0.7410440 1.0774877 1.0685360 1.0097237 0.9855990\n2016 0.7929649 1.0745879 1.0421123 1.0381299 0.9631477\n2017 0.7846862 1.0498446 1.0744776 1.0308174 0.9322877\n2018 0.7891563 1.0084274 1.1117543 1.0382887 0.9294119\n2019 0.7697163 1.0458578 1.0967583 1.0142887 0.9512178\n2020 0.7506828 1.0740572 1.0727587 1.0092022 0.9628865\n\nsaisonnalite[[\"sa\"]]\n\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2010  95.25565  95.64233  96.78133  98.48481 104.37885 101.26505  98.30338\n2011 104.36394 104.32359 103.43866 101.69204 116.68408  99.14422 101.28692\n2012 101.89900 100.37365 101.24088  99.85052 100.00987 100.71062 100.69062\n2013  97.45836  98.31350  98.13990  99.28435  99.57405 101.99855  98.92984\n2014  97.90194 100.01734  98.78591  99.51039  97.70572  97.78987  98.85712\n2015  98.41963  99.43461  99.01853  99.71823  98.39689 100.60315  96.72447\n2016 101.85337 100.21080  97.14512 102.36148 102.40590 101.17176  97.03709\n2017 102.56108 101.15647 102.39754 101.63919 102.54447 101.27698 100.40019\n2018 102.41410 102.82571 103.67189 103.60666  99.33235 104.61318 104.06023\n2019 106.32495 106.30070 105.52037 104.43109 105.08065 101.93677 103.29386\n2020 103.39364 104.66569  83.97780  66.37711  77.57594  87.48738  92.32665\n           Aug       Sep       Oct       Nov       Dec\n2010  99.68623 101.12568 100.93991  98.27017 102.84151\n2011 101.35535 101.33060 101.95031 102.84422 103.88777\n2012 102.75257 100.97889  96.81305  98.65757  97.41645\n2013  97.71450  97.83142  99.87972  98.00971  97.79929\n2014  97.31577  98.13661  98.11314  98.29418  98.44762\n2015 102.69296 101.25406 100.79212 100.81966 101.35969\n2016 100.50886 100.41059  99.22155 100.85443 103.51476\n2017 103.73573 103.06287 105.35353 107.68154 106.72671\n2018 104.66875 103.82503 104.33960 105.55831 105.01264\n2019 102.37538 104.22067 106.22213 102.53491 102.81557\n2020  95.51304  97.48084  99.46319 100.67358 100.32336\n\nsaisonnalite[[\"s_f\"]]\n\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2021 0.9240691 0.9625840 1.1283879 1.0116767 0.9542506 1.1122949 1.0301236\n           Aug       Sep       Oct       Nov       Dec\n2021 0.7736290 1.0661433 1.0421204 1.0454394 0.9628614\n\n# On a d'ailleurs directement une prévision de la série brute qui est faite par modèle ARIMA\nsaisonnalite[[\"y_f\"]]\n\n           Jan       Feb       Mar       Apr       May       Jun       Jul\n2021  93.80530  98.83526 116.70635 105.64151  99.21541 117.25615 107.92506\n           Aug       Sep       Oct       Nov       Dec\n2021  81.39014 112.06948 110.18417 110.21518 101.77148\n\n\nPour la fonction tsCV() on pourra utiliser la fonction suivante pour X-13\n\nfx13_stl <- function(x, h){\n    mod_jx13 <- jx13(x, x13_spec)\n    mod_jx13 <- get_indicators(mod_jx13, c(\"sa\", \"s_f\"))\n    ets_x13 <- ets(mod_jx13$sa, model = \"AAN\") # modèle fixé pour gagner du temps\n    ets_x13_f <- forecast(ets_x13, h = h)\n    ets_x13_f$mean <- ets_x13_f$mean * mod_jx13$s_f[1:h] # on ajoute 1:h pour éviter quelques bugs\n    ets_x13_f$model <- \"X-13 + ETS\"\n    # Pas la peine d'actualiser autres paramètres\n    ets_x13_f\n}\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(RJDemetra)\ny <- window(AirPassengers, end = end(AirPassengers) - c(1, 0))\nautoplot(y)\n\n\n\n# Saisonnalité présente qui dépend de la tendance : passage au log nécessaire pour STL\nmod_stl <- stl(log(y), s.window = \"periodic\")\n\nx13_spec <- x13_spec(easter.enabled = FALSE)\nmod_jx13 <- jx13(y, x13_spec)\nmod_jx13 <- get_indicators(mod_jx13, c(\"s\", \"sa\", \"s_f\", \"y_f\"))\nautoplot(exp(seasadj(mod_stl))) + \n    autolayer(mod_jx13$sa)\n\n\n\nets_x13 <- ets(mod_jx13$sa)\nets_stl <- ets(seasadj(mod_stl))\nets_x13_f <- forecast(ets_x13, h = 12)\nets_stl_f <- forecast(ets_stl, h = 12)\nx13_f <- ets_x13_f$mean * mod_jx13$s_f # Il faut multiplier car schéma multiplicatif\nets_f <- ets_stl_f$mean + lag(seasonal(mod_stl), -12)\nets_f <- exp(ets_f)\n\nOn aurait directement pu obtenir les résultats avec fonction forecast::stlf() :\n\nets_f - stlf(y, lambda = 0, h = 12, s.window = \"periodic\")$mean\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1960   0   0   0   0   0   0   0   0   0   0   0   0\n\nest_direct <- ets(y)\nest_direct_bc <- ets(y, lambda = 0)\nautoplot(window(AirPassengers, start = end(AirPassengers) - c(1, 0)),\n         y = \"AirPassengers\") +\n    autolayer(x13_f, series = \"X-13 + ETS\") +\n    autolayer(mod_jx13$y_f, series = \"X-13\")+ \n    autolayer(ets_f, series = \"STL + ETS\")+ \n    autolayer(forecast(est_direct, PI=FALSE, h =12), series = \"ETS(M,Ad,M)\")+ \n    autolayer(forecast(est_direct_bc, PI=FALSE, h =12), series = \"ETS(A,N,A) sur log(AirPassengers)\")\n\n\n\n\nLes séries qui semblent avoir les meilleurs prévisions sont X-13 (modèle ARIMA, voir TP 5) et X-13 + ETS. Le moins bon semble l’ETS directement calculé.\n\nfx13_stl <- function(x, h){\n    mod_jx13 <- jx13(x, x13_spec)\n    mod_jx13 <- get_indicators(mod_jx13, c(\"sa\", \"s_f\"))\n    ets_x13 <- ets(mod_jx13$sa, model = \"AAN\") # modèle fixé pour gagner du temps\n    ets_x13_f <- forecast(ets_x13, h = h)\n    ets_x13_f$mean <- ets_x13_f$mean * mod_jx13$s_f[1:h] # on ajoute 1:h pour éviter quelques bugs\n    ets_x13_f$model <- \"X-13 + ETS\"\n    # Pas la peine d'actualiser autres paramètres\n    # ets_x13_f$upper = ets_x13_f$upper * mod_jx13$s_f\n    # ets_x13_f$lower = ets_x13_f$lower * mod_jx13$s_f\n    ets_x13_f\n}\nfx13 <- function(x, h){\n    mod_jx13 <- jx13(x, x13_spec)\n    x13_f <- get_indicators(mod_jx13, c(\"y_f\"))$y_f\n    ## Ici il y a des calculs en trop car la prévision est uniquement faite avec le pré-ajustement, on pourrait encore optimiser en ne faisant que le pré-ajustement\n    # mod_jx13 <- jregarima(y, x13_spec$regarima)\n    # x13_f <- get_indicators(mod_jx13, c(\"model.y_f\"))[[1]]\n    x13_f <- window(x13_f, end = time(x13_f)[h])\n    return(structure(list(method = \"X-13ARIMA\", \n                          model = mod_jx13, \n                          mean = x13_f,\n                          level = NULL, \n                          lower = NULL, upper = NULL, x = NULL, series = NULL, \n                          fitted = NULL, residuals =NULL), class = \"forecast\"))\n}\nfstl_ets <- function(x, h){\n    stlf(x, lambda = 0, h = 12, s.window = \"periodic\", etsmodel = \"AAN\")\n}\nfets <- function(x, h){\n    forecast(ets(x, model = \"MAM\", damped = TRUE), h = h)\n}\nfets_bc <- function(x, h){\n    forecast(ets(x, lambda = 0, model = \"AAA\"), h = h)\n}\n# On enlève les 3 premières années pour X-13\ne_x13_ets <- tsCV(AirPassengers, fx13_stl, h = 1, initial = 3*12)\ne_x13 <- tsCV(AirPassengers, fx13, h = 1, initial = 3*12)\ne_stl_est <- tsCV(AirPassengers, fstl_ets, h = 1, initial = 3*12)\ne_ets <- tsCV(AirPassengers, fets, h = 1, initial = 3*12)\ne_ets_bc <- tsCV(AirPassengers, fets_bc, h = 1, initial = 3*12)\n\nerreur <- ts.union(e_x13_ets, e_x13, e_stl_est,\n                  e_ets, e_ets_bc)\ncolnames(erreur) <- c(\"X-13+ETS\", \"X-13\", \"STL+ETS\", \"ETS\", \"log(ETS)\")\n\nLe modèle ARIMA (issu de X-13) semble de meilleure qualité :\n\ncolMeans(erreur^2, na.rm = TRUE)\n\nX-13+ETS     X-13  STL+ETS      ETS log(ETS) \n146.4192 140.2659 202.0902 206.2573 210.5955"
  },
  {
    "objectID": "2022/ast/TP/5_ARIMA.html",
    "href": "2022/ast/TP/5_ARIMA.html",
    "title": "5 - Modèles ARIMA",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à manipuler des modèles (S)ARIMA\n\nLes modèles ARIMA peuvent être estimés grâce à plusieurs fonctions, sans être exhaustif :\n\nstats::arima() dans les fonctions de base de R ;\nforecast::Arima() basée sur stats::arima() mais qui permet d’ajouter un terme de dérive et se manipule plus facilement avec autres fonctions de forecast ;\nfable::ARIMA() comme forecast::Arima() mais pour les objets tsibble.\n\nLes packages suivants seront utilisés :\n\npackages_to_install <- c(\"ggplot2\", \"forecast\", \"RJDemetra\", \"patchwork\", \"lmtest\",\n                         \"tsibble\", \"fable\", \"feasts\", \"dplyr\", \"lubridate\")\n\npackages <- installed.packages()[,\"Package\"][! packages_to_install %in% installed.packages()[,\"Package\"]]\nif (length(packages) > 0) {\n    install.packages(packages)\n}\n\nLe but des prochains exercices est d’étudier les séries classiques\n\nLakeHuron niveau annuel du Lac de Huron ;\nsunspot.year nombre annuel de tâches solaires entre 1770 et 1869 ;\nAirPassengers nombre mensuel de passagers aériens ;\nnottem température mensuelle moyenne au chateau de Nottingham.\n\n\nNiveau du Lac de Huron\n\n\n\n\n\n\nExercice\n\n\n\nÉtudier la série LakeHuron : Faut-il transformer la série ? Quel modèle ARIMA parait adapté ? la série est elle stationnaire ? Comparer avec auto.arima().\n\n\n\n\n\n\n\n\nIndice\n\n\n\n\n\nAnalyser les ACF/PACF : est-ce qu’ils ressemblent à ceux d’une marche aléatoire ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(forecast)\nlibrary(patchwork)\nautoplot(LakeHuron)\n\n\n\n\nIl y a potentiellement une tendance à la baisse donc peut-être une tendance à la baisse. A priori pas de raison de transformer la série.\n\ntseries::kpss.test(LakeHuron, \"Trend\")\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  LakeHuron\nKPSS Trend = 0.20006, Truncation lag parameter = 3, p-value = 0.01598\n\ntseries::adf.test(LakeHuron)\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  LakeHuron\nDickey-Fuller = -2.7796, Lag order = 4, p-value = 0.254\nalternative hypothesis: stationary\n\n# Les tests KPSS et ADF considèrent que la série est non-stationnaire\n# ggAcf(LakeHuron) /\n#   ggPacf(LakeHuron)\nggtsdisplay(LakeHuron)\n\n\n\n\nL’ACF décroit de manière exponentielle et rapidement vers 0, ce n’est pas un signe de marche aléatoire. En revanche le premier coefficient est élevé ce qui peut laisser penser que l’on n’a pas une marche aléatoire mais un coefficient AR(1) élevé. Le PACF est nul à partir de l’ordre 3 : cela peut laisser penser à un processus AR d’ordre au plus 2. On estime un modèle ARIMA(2,0,0) avec une tendance (drift).\n\nmod_trend <- Arima(LakeHuron, order = c(2, 0, 0), include.drift = TRUE)\nmod_trend\n\nSeries: LakeHuron \nARIMA(2,0,0) with drift \n\nCoefficients:\n         ar1      ar2  intercept    drift\n      1.0048  -0.2913   580.0915  -0.0216\ns.e.  0.0976   0.1004     0.4636   0.0081\n\nsigma^2 = 0.476:  log likelihood = -101.2\nAIC=212.4   AICc=213.05   BIC=225.32\n\n# Le coefficient AR(1) est très proche de 1 ce qui explique que les tests précédents concluent à une non-stationnarité\nlmtest::coeftest(mod_trend) # tous les coefficients sont significatifs, pas de raison de simplifier\n\n\nz test of coefficients:\n\n             Estimate  Std. Error   z value  Pr(>|z|)    \nar1         1.0048037   0.0976112   10.2939 < 2.2e-16 ***\nar2        -0.2913198   0.1003652   -2.9026  0.003701 ** \nintercept 580.0915109   0.4635882 1251.3079 < 2.2e-16 ***\ndrift      -0.0215688   0.0080988   -2.6632  0.007740 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# A priori les résidus sont un bruit blanc :\ncheckresiduals(mod_trend) \n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,0,0) with drift\nQ* = 3.9283, df = 8, p-value = 0.8635\n\nModel df: 2.   Total lags used: 10\n\ncpgram(residuals(mod_trend))\n\n\n\n# En considérant un AR(1) on a un modèle avec un AIC plus grand\nmod_trend_ar1 <- Arima(LakeHuron, order = c(1, 0, 0), include.drift = TRUE)\nmod_trend_ar1\n\nSeries: LakeHuron \nARIMA(1,0,0) with drift \n\nCoefficients:\n         ar1  intercept    drift\n      0.7835   580.0936  -0.0204\ns.e.  0.0634     0.6075   0.0105\n\nsigma^2 = 0.5122:  log likelihood = -105.23\nAIC=218.45   AICc=218.88   BIC=228.79\n\n# On aurait aussi pu faire un ARIMA(0,1,0) : c'est ce qui est retenu par auto.arima()\nmod_diff <- auto.arima(LakeHuron)\nmod_diff\n\nSeries: LakeHuron \nARIMA(0,1,0) \n\nsigma^2 = 0.5588:  log likelihood = -109.11\nAIC=220.22   AICc=220.26   BIC=222.79\n\n\nAttention : on ne peut comparer les modèles en utilisant l’AIC ! (ordre de différenciation différent). Pour comparer les modèles on peut étudier les erreurs de prévision.\n\nfar2 <- function(x, h){forecast(Arima(x, order = c(2, 0, 0), include.drift = TRUE), h = h)}\nfdiff <- function(x, h){forecast(Arima(x, order = c(0, 1, 0)), h = h)}\ne1 <- tsCV(LakeHuron, far2, h = 1)\ne2 <- tsCV(LakeHuron, fdiff, h = 1)\ne_oos <- na.omit(ts.union(e1, e2))\n# MSE plus petite avec second modèle\ncolMeans(e_oos^2)\n\n       e1        e2 \n0.6151966 0.5409957 \n\n# Mais cela vient du fait que lorsqu'il y a peu d'observations, le premier modèle est instable\ncolMeans(window(e_oos,start = 1890)^2)\n\n       e1        e2 \n0.5598778 0.5847280 \n\ncolMeans(window(e_oos,start = 1900)^2)\n\n       e1        e2 \n0.5806291 0.6187056 \n\n# Résidus In Sample toujours plus petits avec premier modèle\n# On commence en 1878 car ce n'est qu'après cette date que les résidus sont calculés par MLE\ne_is <- window(ts.union(residuals(mod_trend), residuals(mod_diff)), start = 1878)\ncolMeans(e_is^2)\n\nresiduals(mod_trend)  residuals(mod_diff) \n           0.4404010            0.5356053 \n\ncolMeans(window(e_is,start = 1890)^2)\n\nresiduals(mod_trend)  residuals(mod_diff) \n           0.4671440            0.5778036 \n\ncolMeans(window(e_is,start = 1900)^2)\n\nresiduals(mod_trend)  residuals(mod_diff) \n           0.4956467            0.6140781 \n\n\n\n\n\n\n\nNombre annuel de tâches solaires\n\n\n\n\n\n\nExercice\n\n\n\nÉtudier la série sunspot.year entre 1770 et 1869 : Faut-il transformer la série ? Quel modèle ARIMA parait adapté ? la série est elle stationnaire ? Comparer avec auto.arima().\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(forecast)\nlibrary(patchwork)\ny <- window(sunspot.year, start = 1770, end = 1869)\nggtsdisplay(y)\n\n\n\n\nPas de tendance ni de raison de transformer la série. Il y a des mouvements cycliques. A priori pas de raison de transformer la série. A priori pas une marche aléatoire.\n\ntseries::kpss.test(y)\n\n\n    KPSS Test for Level Stationarity\n\ndata:  y\nKPSS Level = 0.15928, Truncation lag parameter = 4, p-value = 0.1\n\ntseries::adf.test(y)\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  y\nDickey-Fuller = -3.8579, Lag order = 4, p-value = 0.01889\nalternative hypothesis: stationary\n\n\nLes tests KPSS et ADF considèrent que la série est non-stationnaire. On remarque que l’ACF décroit rapidement vers O de manière sinusodiale et que le PACF est nul à partir de l’ordre 3 : on estime un AR2.\n\nmod_ar2 <- Arima(y, order = c(2, 0, 0))\nmod_ar2\n\nSeries: y \nARIMA(2,0,0) with non-zero mean \n\nCoefficients:\n         ar1      ar2     mean\n      1.4059  -0.7111  48.2642\ns.e.  0.0706   0.0702   4.9747\n\nsigma^2 = 236.5:  log likelihood = -414.94\nAIC=837.88   AICc=838.3   BIC=848.3\n\nlmtest::coeftest(mod_ar2) # tous les coefficients sont significatifs, pas de raison de simplifier\n\n\nz test of coefficients:\n\n           Estimate Std. Error  z value  Pr(>|z|)    \nar1        1.405873   0.070572  19.9212 < 2.2e-16 ***\nar2       -0.711095   0.070242 -10.1235 < 2.2e-16 ***\nintercept 48.264166   4.974715   9.7019 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# A priori les résidus sont un bruit blanc :\ncheckresiduals(mod_ar2) \n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,0,0) with non-zero mean\nQ* = 12.793, df = 8, p-value = 0.1192\n\nModel df: 2.   Total lags used: 10\n\ncpgram(residuals(mod_ar2))\n\n\n\n# Auto.arima sélectionne un ARIMA(2,0,1) qui a un AICc plus petit\nmod_auto <- auto.arima(y)\nmod_auto\n\nSeries: y \nARIMA(2,0,1) with non-zero mean \n\nCoefficients:\n         ar1      ar2     ma1     mean\n      1.2273  -0.5620  0.3733  48.5319\ns.e.  0.1134   0.1084  0.1344   6.0130\n\nsigma^2 = 225.1:  log likelihood = -412.05\nAIC=834.09   AICc=834.73   BIC=847.12\n\naccuracy(mod_ar2)\n\n                     ME     RMSE      MAE  MPE MAPE      MASE      ACF1\nTraining set -0.1065321 15.14691 12.03611 -Inf  Inf 0.7027453 0.1297447\n\naccuracy(mod_auto)\n\n                     ME     RMSE      MAE  MPE MAPE      MASE        ACF1\nTraining set -0.1925486 14.70035 11.89705 -Inf  Inf 0.6946261 -0.02480733\n\nfar2 <- function(x, h){forecast(Arima(x, order=c(2, 0, 0)), h = h)}\nfar2ma1 <- function(x, h){forecast(Arima(x, order=c(2, 0, 1)), h = h)}\ne1 <- tsCV(y, far2, h = 1)\ne2 <- tsCV(y, far2ma1, h = 1)\ne_oos <- window(ts.intersect(e1, e2), start = 1780)\n# MSE plus petite avec second modèle\ncolMeans(e_oos^2, na.rm = TRUE)\n\n      e1       e2 \n217.5813 204.6266 \n\n\n\n\n\n\n\nMombre mensuel de passagers aériens ;\n\n\n\n\n\n\nExercice\n\n\n\nÉtudier la série AirPassengers : Faut-il transformer la série ? Quel modèle ARIMA parait adapté ? la série est elle stationnaire ? Comparer avec auto.arima().\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nautoplot(AirPassengers)\n\n\n\n\nTendance claire avec une saisonnalité multiplicative. Il faut passer la série au log.\n\nggtsdisplay(log(AirPassengers))\n\n\n\n\nL’analyse de l’ACF montre une décroissance lente avec des pics saisonniers. L’analyse du PACF montre deux pics : à l’ordre 1 proche de 1 et à l’ordre 13. Le second pic à l’ordre 13 et non 12 peut suggérer une double différenciation \\((1-B)(1-B^{12})\\). La présence d’une saisonnalité a déjà été analysée dans les précédents TP : un test n’est pas nécessaire et on peut différencier à l’ordre 12.\n\nggtsdisplay(diff(log(AirPassengers), 12))\n\n\n\n\nLa série différenciée ne présente pas de tendance mais des périodes de hausse et de baisse. L’ACF décroit vers 0 mais pas de manière exponentielle. Le premier coefficient de l’ACF/PACF est élevé ce qui peut laisser penser que la série est toujours non-stationnaire\n\ntseries::kpss.test(diff(log(AirPassengers), 12))\n\n\n    KPSS Test for Level Stationarity\n\ndata:  diff(log(AirPassengers), 12)\nKPSS Level = 0.36816, Truncation lag parameter = 4, p-value = 0.09088\n\ntseries::adf.test(diff(log(AirPassengers), 12))\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diff(log(AirPassengers), 12)\nDickey-Fuller = -3.1899, Lag order = 5, p-value = 0.09265\nalternative hypothesis: stationary\n\ntseries::pp.test(diff(log(AirPassengers), 12))\n\n\n    Phillips-Perron Unit Root Test\n\ndata:  diff(log(AirPassengers), 12)\nDickey-Fuller Z(alpha) = -37.597, Truncation lag parameter = 4, p-value\n= 0.01\nalternative hypothesis: stationary\n\n# Les tests KPSS, ADF et PP donnent des résultats différents : à 5 % le test KPSS ne rejette l'hypothèse nulle de stationnarité, le test de PP rejette l'hypothèse de non-stationnarité alors qu'ADF ne la rejette pas.\nndiffs(diff(log(AirPassengers), 12))\n\n[1] 1\n\n\nLa fonction ndiffs(), basée par défaut sur KPSS conclue à une non-stationnarité. Cela vient de paramètres différents dans le test KPSS utilisé. L’analyse des ACF semblent plutôt montrer un présence de marche aléatoire : on différencie. Les ACF et PACF semblent montrer une saisonnalité encore présente mais pas de décroissance nette de l’ACF ou PACF.\n\nggAcf(diff(diff(log(AirPassengers), 12), 1)) /\n    ggPacf(diff(diff(log(AirPassengers), 12), 1))\n\n\n\nmod = Arima(AirPassengers, order = c(0,1,0), seasonal = c(1,1,1), lambda = 0)\nBox.test(resid(mod), fitdf = 2,lag = 24,type = \"Ljung\")\n\n\n    Box-Ljung test\n\ndata:  resid(mod)\nX-squared = 48.603, df = 22, p-value = 0.0009028\n\ncpgram(resid(mod))\n\n\n\n# checkresiduals(mod)\n\nLes résidus ne sont pas un bruit blanc\n\nggAcf(residuals(mod)) /\n    ggPacf(residuals(mod))\n\n\n\n\nEncore pas de décroissance claire mais un pic à l’ordre 1. On peut donc penser que \\(p,q, P,q \\leq 1\\)\n\nmod1 <- Arima(AirPassengers, order = c(1,1,1), seasonal = c(1,1,1), lambda = 0)\n# On a bien un bruit blanc cette fois\nBox.test(resid(mod1), fitdf = 4,lag = 24,type = \"Ljung\")\n\n\n    Box-Ljung test\n\ndata:  resid(mod1)\nX-squared = 24.669, df = 20, p-value = 0.2144\n\ncpgram(resid(mod1))\n\n\n\nlmtest::coeftest(mod1)\n\n\nz test of coefficients:\n\n      Estimate Std. Error z value  Pr(>|z|)    \nar1   0.166649   0.245890  0.6777 0.4979380    \nma1  -0.561499   0.211550 -2.6542 0.0079493 ** \nsar1 -0.099007   0.153981 -0.6430 0.5202347    \nsma1 -0.497321   0.135967 -3.6577 0.0002545 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLes ordres AR ne sont pas significatifs significatifs. On va enlever un ordre AR et refaire le test : ne pas enlever toutes les variables en même temps car on teste ici si une variable est nulle et non pas si un ensemble de variables est nul !\n\nmod2 <- Arima(AirPassengers, order = c(0,1,1), seasonal = c(1,1,1), lambda = 0)\n# Toujours un bruit blanc et AR saisonnier non significatif\nBox.test(resid(mod2), fitdf = 3,lag = 24,type = \"Ljung\")\n\n\n    Box-Ljung test\n\ndata:  resid(mod2)\nX-squared = 25.475, df = 21, p-value = 0.2272\n\nlmtest::coeftest(mod2) \n\n\nz test of coefficients:\n\n      Estimate Std. Error z value  Pr(>|z|)    \nma1  -0.414254   0.089933 -4.6063   4.1e-06 ***\nsar1 -0.111647   0.154748 -0.7215 0.4706159    \nsma1 -0.481706   0.136304 -3.5341 0.0004092 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod3 = Arima(AirPassengers, order = c(0,1,1), seasonal = c(0,1,1), lambda = 0)\n# Toujours un bruit blanc et tous les coefs sont signifactifs, on ne peut pas simplifier davantage\nBox.test(resid(mod3), fitdf = 2,lag = 24,type = \"Ljung\")\n\n\n    Box-Ljung test\n\ndata:  resid(mod3)\nX-squared = 26.446, df = 22, p-value = 0.233\n\nlmtest::coeftest(mod3) \n\n\nz test of coefficients:\n\n      Estimate Std. Error z value  Pr(>|z|)    \nma1  -0.401828   0.089644 -4.4825 7.378e-06 ***\nsma1 -0.556945   0.073100 -7.6190 2.557e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# C'est le dernier modèle qui a l'AIC le plus petit : c'est celui que l'on retient\nAIC(mod1, mod2, mod3)\n\n     df       AIC\nmod1  5 -480.3109\nmod2  4 -481.9131\nmod3  3 -483.3991\n\n# C'est aussi le modèle retenu par auto.arima\nauto.arima(AirPassengers, lambda = 0)\n\nSeries: AirPassengers \nARIMA(0,1,1)(0,1,1)[12] \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ma1     sma1\n      -0.4018  -0.5569\ns.e.   0.0896   0.0731\n\nsigma^2 = 0.001371:  log likelihood = 244.7\nAIC=-483.4   AICc=-483.21   BIC=-474.77\n\n# auto.arima(AirPassengers, lambda = 0, stepwise = FALSE) # plus lent\n\nOn retrouve le modèle Airline : \\(ARIMA(0,1,1)(0,1,1)\\) !\n\n\n\n\n\nTempérature mensuelle moyenne au chateau de Nottingham\nPour l’analyse de la série nottem, on utilisera le tidyverts. Ci-dessous un exemple de manipulation avec une autre série :\n\nlibrary(tsibble)\nlibrary(dplyr)\nlibrary(fable)\nlibrary(feasts)\nlibrary(ggplot2)\ny <- as_tsibble(USAccDeaths)\ny\n\n# A tsibble: 72 x 2 [1M]\n      index value\n      <mth> <dbl>\n 1 1973 jan  9007\n 2 1973 fév  8106\n 3 1973 mar  8928\n 4 1973 avr  9137\n 5 1973 mai 10017\n 6 1973 jui 10826\n 7 1973 jul 11317\n 8 1973 aoû 10744\n 9 1973 sep  9713\n10 1973 oct  9938\n# … with 62 more rows\n\n(y %>% ACF(value %>%  difference(12)) %>% autoplot()) /\n    (y %>% PACF(value %>%  difference(12)) %>% autoplot()) & ylim(-1,1)\n\n\n\nmodel <- y %>%\n    model(arima = ARIMA(value ~ 0 + pdq(0, 1, 1) + PDQ(0, 1, 0)),\n          auto_arima = ARIMA(value))\nmodel \n\n# A mable: 1 x 2\n                      arima                auto_arima\n                    <model>                   <model>\n1 <ARIMA(0,1,1)(0,1,0)[12]> <ARIMA(0,1,1)(0,1,1)[12]>\n\nmodel %>% accuracy()\n\n# A tibble: 2 × 10\n  .model     .type       ME  RMSE   MAE   MPE  MAPE  MASE RMSSE     ACF1\n  <chr>      <chr>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>\n1 arima      Training  44.0  321.  230. 0.477  2.70 0.526 0.574  0.00648\n2 auto_arima Training  58.8  285.  201. 0.665  2.35 0.460 0.510 -0.0239 \n\nmodel %>% glance()\n\n# A tibble: 2 × 8\n  .model      sigma2 log_lik   AIC  AICc   BIC ar_roots  ma_roots  \n  <chr>        <dbl>   <dbl> <dbl> <dbl> <dbl> <list>    <list>    \n1 arima      128002.   -430.  865.  865.  869. <cpl [0]> <cpl [1]> \n2 auto_arima 102860.   -425.  857.  857.  863. <cpl [0]> <cpl [13]>\n\nmodel %>% residuals() %>%  ACF() %>%  autoplot()\n\n\n\n# On peut utiliser la fonction report() sur un sous modèle\nmodel %>% select(auto_arima) %>% \n    report()\n\nSeries: value \nModel: ARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.4303  -0.5528\ns.e.   0.1228   0.1784\n\nsigma^2 estimated as 102860:  log likelihood=-425.44\nAIC=856.88   AICc=857.32   BIC=863.11\n\nmodel %>% \n    forecast(h=12) %>%  \n    autoplot(y)\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nÉtudier la série as_tsibble(nottem) :\n\nFaut-il transformer la série ?\n\nFaut-il différencier la série ? (utiliser la fonction difference())\nÉtudier les ACF/PACF : quels sont les ordre plausibles ?\nTester un ensemble de modèles possibles. Les trier par AICc et prendre celui qui le minimise.\nVérifier la qualité des résidus\nComparer les prévisions avec une sélection automatique et avec un modèle ETS.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(lubridate)\ny <- as_tsibble(nottem)\nautoplot(y, value)\n\n\n\ngg_season(y, value)\n\n\n\n\nSérie déjà étudiée : a priori pas de transformation nécessaire, pas de tendance et saisonnalité mensuelle nette.\n\ny %>% gg_tsdisplay(value %>%  difference(12), plot_type = \"partial\")\n\n\n\n\nA priori série différenciée est stationnaire. L’analyse des ACF/PACF suggère \\(P= 1\\) et/ou \\(Q=1\\), \\(P<=1\\) et \\(Q <= 2\\). Pas de constante dans le modèle.\n\n# Si on ne veut pas écrire tous les codes à la main on peut aussi faire un programme\n# d = expand.grid(p=0:1,q=0:2,P=0:1, Q=0:1)\n# cat(sprintf(\"sarima%i0%i_%i1%i = ARIMA(value ~ -1 + pdq(%i, 0, %i) + PDQ(%i, 1, %i))\",\n#       d$p, d$q, d$P, d$Q,\n#       d$p, d$q, d$P, d$Q), sep =\",\\n\")\nall_models <- y %>%\n    model(\n        sarima000_010 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(0, 1, 0)),\n        sarima100_010 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(0, 1, 0)),\n        sarima001_010 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(0, 1, 0)),\n        sarima101_010 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(0, 1, 0)),\n        sarima002_010 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(0, 1, 0)),\n        sarima102_010 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(0, 1, 0)),\n        sarima000_110 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(1, 1, 0)),\n        sarima100_110 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 0)),\n        sarima001_110 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(1, 1, 0)),\n        sarima101_110 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(1, 1, 0)),\n        sarima002_110 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(1, 1, 0)),\n        sarima102_110 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(1, 1, 0)),\n        sarima000_011 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(0, 1, 1)),\n        sarima100_011 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(0, 1, 1)),\n        sarima001_011 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(0, 1, 1)),\n        sarima101_011 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(0, 1, 1)),\n        sarima002_011 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(0, 1, 1)),\n        sarima102_011 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(0, 1, 1)),\n        sarima000_111 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(1, 1, 1)),\n        sarima100_111 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 1)),\n        sarima001_111 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(1, 1, 1)),\n        sarima101_111 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(1, 1, 1)),\n        sarima002_111 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(1, 1, 1)),\n        sarima102_111 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(1, 1, 1))\n    )\nall_models %>% \n    glance() %>% \n    arrange(AICc)\n\n# A tibble: 24 × 8\n   .model        sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots  \n   <chr>          <dbl>   <dbl> <dbl> <dbl> <dbl> <list>     <list>    \n 1 sarima100_111   5.25   -519. 1045. 1045. 1059. <cpl [13]> <cpl [12]>\n 2 sarima002_111   5.23   -518. 1045. 1046. 1063. <cpl [12]> <cpl [14]>\n 3 sarima101_111   5.25   -518. 1046. 1046. 1063. <cpl [13]> <cpl [13]>\n 4 sarima102_111   5.25   -518. 1047. 1048. 1068. <cpl [13]> <cpl [14]>\n 5 sarima001_111   5.33   -520. 1048. 1048. 1062. <cpl [12]> <cpl [13]>\n 6 sarima002_011   5.44   -524. 1055. 1056. 1069. <cpl [0]>  <cpl [14]>\n 7 sarima100_011   5.48   -525. 1056. 1056. 1066. <cpl [1]>  <cpl [12]>\n 8 sarima101_011   5.46   -524. 1056. 1056. 1070. <cpl [1]>  <cpl [13]>\n 9 sarima102_011   5.46   -524. 1057. 1057. 1074. <cpl [1]>  <cpl [14]>\n10 sarima001_011   5.55   -526. 1058. 1058. 1069. <cpl [0]>  <cpl [13]>\n# … with 14 more rows\n\nbest_model <- y %>%\n    model(\n        sarima100_111 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 1))\n    )\n\nA priori bruit blanc :\n\nbest_model %>% gg_tsresiduals()\n\n\n\naugment(best_model) %>% \n    features(.innov, ljung_box, dof = 3, lag = 24)\n\n# A tibble: 1 × 3\n  .model        lb_stat lb_pvalue\n  <chr>           <dbl>     <dbl>\n1 sarima100_111    20.6     0.484\n\ncompar_model <- y %>%\n    model(\n        sarima100_111 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 1)),\n        auto_arima = ARIMA(value ~ -1),\n        ets = ETS(value)\n    )\n\nModèle sélectionné a un AICc plus petit que l’auto-arima mais un RMSE plus élevé.\n\ncompar_model\n\n# A mable: 1 x 3\n              sarima100_111                auto_arima          ets\n                    <model>                   <model>      <model>\n1 <ARIMA(1,0,0)(1,1,1)[12]> <ARIMA(1,0,2)(1,1,2)[12]> <ETS(A,N,A)>\n\ncompar_model %>% glance()\n\n# A tibble: 3 × 11\n  .model      sigma2 log_lik   AIC  AICc   BIC ar_ro…¹ ma_ro…²   MSE  AMSE   MAE\n  <chr>        <dbl>   <dbl> <dbl> <dbl> <dbl> <list>  <list>  <dbl> <dbl> <dbl>\n1 sarima100_…   5.25   -519. 1045. 1045. 1059. <cpl>   <cpl>   NA    NA    NA   \n2 auto_arima    5.23   -517. 1048. 1048. 1072. <cpl>   <cpl>   NA    NA    NA   \n3 ets           5.38   -852. 1735. 1737. 1787. <NULL>  <NULL>   5.07  5.17  1.74\n# … with abbreviated variable names ¹​ar_roots, ²​ma_roots\n\ncompar_model %>% accuracy()\n\n# A tibble: 3 × 10\n  .model        .type         ME  RMSE   MAE    MPE  MAPE  MASE RMSSE     ACF1\n  <chr>         <chr>      <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>\n1 sarima100_111 Training 0.0695   2.22  1.72 -0.127  3.69 0.638 0.647 -0.0197 \n2 auto_arima    Training 0.0711   2.20  1.71 -0.124  3.67 0.635 0.641  0.00160\n3 ets           Training 0.00726  2.25  1.74 -0.223  3.75 0.647 0.656  0.198  \n\n\nLes prévisions des 3 modèles sont très proches\n\nforecast(compar_model, h = \"1 year\") %>% \n    autoplot(y %>% filter(year(index) >= 1938))\n\n\n\n\n\n\n\nL’avantage est tidyverts est que l’on peut appliquer facilement plusieurs fonctions à plusieurs séries et comparer les méthodes entre elles. En reprenant l’exemple disponible ici https://fable.tidyverts.org :\n\nlibrary(fable)\nlibrary(tsibble)\nlibrary(tsibbledata)\nlibrary(lubridate)\nlibrary(dplyr)\naus_retail %>%\n    filter(\n        State %in% c(\"New South Wales\", \"Victoria\"),\n        Industry == \"Department stores\"\n    ) %>% \n    model(\n        ets = ETS(box_cox(Turnover, 0.3)),\n        arima = ARIMA(log(Turnover)),\n        snaive = SNAIVE(Turnover)\n    ) %>%\n    forecast(h = \"2 years\") %>% \n    autoplot(filter(aus_retail, year(Month) > 2010), level = NULL)"
  },
  {
    "objectID": "2022/ast/backcasttransform.html",
    "href": "2022/ast/backcasttransform.html",
    "title": "Backcast transformation",
    "section": "",
    "text": "Voir notamment https://robjhyndman.com/hyndsight/backtransforming/.\nCette page vient en complément du cours 2 - Analyse graphique.\n\n1 Convergence vers la médiane\nSoit \\(f_\\lambda\\) la transformation de Box-Cox \\[\nf_\\lambda(x)=\\begin{cases}\n\\log(x)&\\text{ si }\\lambda=0\\\\\n\\frac{sign(x)|x|^\\lambda -1}{\n\\lambda\n}&\\text{ si }\\lambda\\ne0\n\\end{cases}\n\\] et \\(g_\\lambda\\) la transformation inverse \\[\n\\quad\ng_\\lambda(x)=f^{-1}_\\lambda(x) =\n\\begin{cases}\n\\exp(x) & \\text{ si }\\lambda=0\\\\\n\\text{sign}(\\lambda x + 1)|\\lambda x+1|^{1/\\lambda} & \\text{ si }\\lambda\\ne0\n\\end{cases}.\n\\]\nGénéralement la transformation inverse de la valeur prédite ne pourra pas être considérée comme la valeur moyenne de la distribution des prévisions mais plutôt comme la médiane. Il n’y a en général pas de problème à cela mais dans certains cas (comme les prévisions hiérarchiques où l’on fait des agrégations de prévisions) il est nécessaire de faire une correction puisque l’on s’intéresse à la moyenne de la distribution des prévisions (voir section Section 2).\nCette convergence vers la médiane est vraie lorsque la distribution est symétrique puisque dans ce cas : \\[\nMoyenne[f_\\lambda(X)]=Mediane[f_\\lambda(X)]=f_\\lambda(Mediane[X]).\n\\] Il vient donc \\[\ng_\\lambda\\big(Moyenne[f_\\lambda(X)]\\big) =\nMediane\\big[g_\\lambda(f_\\lambda(X))\\big]=\nMediane[X].\n\\]\n\n\n2 Correction du bais avec la transformation Box-Cox\nSoit \\(\\mu\\) la moyenne de la série transformée et \\(\\sigma^{2}\\) sa variance. Les trois premiers termes du développement de Taylor en série entière s’écrivent : \\[\ng_\\lambda(\\mu+x)\\simeq g_\\lambda(\\mu)+g_\\lambda'(\\mu)x+g_\\lambda''(\\mu)\\frac{{x^{2}}}{2}.\n\\]\nIl vient donc : \\[\\begin{align*}\n\\mathbb{E}\\left[g_\\lambda(X)\\right] & =\\mathbb{E}\\left[g_\\lambda(\\mu+X-\\mu)\\right]\\\\\n& \\simeq\\mathbb{E}\\left[g_\\lambda(\\mu)+g_\\lambda'(\\mu)(X-\\mu)+\\frac{1}{2}g_\\lambda''(\\mu)\\left(X-\\mu\\right)^{2}\\right]\\\\\n& =g_\\lambda(\\mu)+g_\\lambda'(\\mu)\\underbrace{\\mathbb{E}\\left[X-\\mu\\right]}_{=0}+\\frac{1}{2}g_\\lambda''(\\mu)\\underbrace{\\mathbb{E}\\left[\\left(X-\\mu\\right)^{2}\\right]}_{=\\sigma^{2}}\\\\\n& =g_\\lambda(\\mu)+g_\\lambda''(\\mu)\\frac{\\sigma^{2}}{2}.\n\\end{align*}\\]\nDe la même façon on peut montrer que \\[\n\\mathbb{V}\\left[g_\\lambda(X)\\right]\\simeq\\left(g_\\lambda'(\\mathbb{E}\\left[X\\right])\\right)^{2}\\mathbb{V}\\left[X\\right]=\\left(g_\\lambda'(\\mu)\\right)^{2}\\sigma^{2}-\\frac{1}{4}\\left(g_\\lambda''(\\mu)\\right)^{2}\\sigma^{4}.\n\\]\nDans le cas de la transformation de Box-Cox \\[\ng_\\lambda(x)=\\begin{cases}\n\\exp(x) & \\text{ si }\\lambda=0\\\\\n\\text{sign}(\\lambda x+1)|\\lambda x+1|^{1/\\lambda} & \\text{ si }\\lambda\\ne0\n\\end{cases},\n\\] donc \\[\ng_\\lambda'(x)=\\begin{cases}\n\\exp(x) & \\text{ si }\\lambda=0\\\\\n\\text{sign}(\\lambda x+1)|\\lambda x+1|^{1/\\lambda-1} & \\text{ si }\\lambda\\ne0\n\\end{cases}\n\\] et \\[\ng_\\lambda''(x)=\\begin{cases}\n\\exp(x) & \\text{ si }\\lambda=0\\\\\n\\text{sign}(\\lambda x+1)(1-\\lambda)|\\lambda x+1|^{1/\\lambda-2} & \\text{ si }\\lambda\\ne0\n\\end{cases}.\n\\]\nLa moyenne de la transformation inverse de Box-Cox est donc \\[\n\\begin{cases}\n\\exp(\\mu)\\left(1+\\frac{\\sigma^{2}}{2}\\right) & \\text{ si }\\lambda=0\\\\\n\\text{sign}(\\lambda\\mu+1)|\\lambda\\mu+1|^{1/\\lambda}\\left(1+\\frac{\\sigma^{2}(1-\\lambda)}{2|\\lambda\\mu+1|^{2}}\\right) & \\text{ si }\\lambda\\ne0\n\\end{cases}.\n\\]\nC’est-à-dire : \\[\n\\begin{cases}\ng_\\lambda(\\mu)\\left(1+\\frac{\\sigma^{2}}{2}\\right) & \\text{ si }\\lambda=0\\\\\ng_\\lambda(\\mu)\\left(1+\\frac{\\sigma^{2}(1-\\lambda)}{2 g_\\lambda(\\mu)^{2\\lambda}}\\right) & \\text{ si }\\lambda\\ne0\n\\end{cases}.\n\\]"
  },
  {
    "objectID": "2022/ast/index.html",
    "href": "2022/ast/index.html",
    "title": "Analyse des séries temporelles avec ",
    "section": "",
    "text": "Supports de cours et exercices de la formation Analyse des séries temporelles avec R au CEPE les 21 et 22 novembre 2022.\n\nCours\n\nRappels sur l’environnement de travail de R\nAnalyse graphique (voir également compléments sur la transformation inverse de Box-Cox)\nDécomposition d’une série temporelle\nLissage exponentiel\nLa modélisation ARIMA\nCompléments\n\n\n\nTravaux pratiques\n\nTraitement des séries temporelles sous R\nAnalyse graphique\nDécomposition d’une série temporelle\nLissage exponentiel\nLa modélisation ARIMA\n\n\n\nBibliographie\nAragon, Y. (2011), Séries temporelles avec R. Méthodes et cas, Springer.\nBrockwell, P. J. and Davis, R. A. (1991) Time Series: Theory and Methods. Second edition. Springer.\nHyndman, R.J., & Athanasopoulos, G. (2018) Forecasting: principles and practice, 2nd edition, OTexts: Melbourne, Australia. OTexts.com/fpp2. Accessed on nov. 2022.\nHyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on nov. 2022.\n\n\nLicence\nCes supports de cours sont librement réutilisable sous © 2022 Alain Quartier-la-Tente, Insee CC BY-NC-SA 3.0 ."
  },
  {
    "objectID": "2022/index.html",
    "href": "2022/index.html",
    "title": "Formations",
    "section": "",
    "text": "2022\n\nNovembre 2022 : Analyse de séries temporelles avec  (Cepe)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ensemble des formations",
    "section": "",
    "text": "2022\n\nNovembre 2022 : Analyse de séries temporelles avec  (Cepe) \n\n\n\n2021\n\nJuin 2021 : Désaisonnalisation avec JDemetra+ et RJDemetra (RTE)"
  }
]
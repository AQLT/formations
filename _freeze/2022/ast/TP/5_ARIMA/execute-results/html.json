{
  "hash": "58c74a00da955fa61901169d8f6f35d4",
  "result": {
    "markdown": "---\ntitle: \"5 - Modèles ARIMA\"\nsubtitle: |\n  Analyse des séries temporelles avec R\nauthor: \"Alain Quartier-la-Tente\"\nformat: html\nlang: fr\nlanguage: \n title-block-author-single: Auteur\n---\n\n\n\n\n> L'objectif de ce TP est d'apprendre à manipuler des modèles (S)ARIMA\n\nLes modèles ARIMA peuvent être estimés grâce à plusieurs fonctions, sans être exhaustif :\n\n-   `stats::arima()` dans les fonctions de base de R ;\n\n-   `forecast::Arima()` basée sur `stats::arima()` mais qui permet d'ajouter un terme de dérive et se manipule plus facilement avec autres fonctions de `forecast` ;\n\n-   `fable::ARIMA()` comme `forecast::Arima()` mais pour les objets `tsibble`.\n\nLes packages suivants seront utilisés :\n\n\n::: {.cell}\n\n```{.r .cell-code}\npackages_to_install <- c(\"ggplot2\", \"forecast\", \"RJDemetra\", \"patchwork\", \"lmtest\",\n\t\t\t\t\t\t \"tsibble\", \"fable\", \"feasts\", \"dplyr\", \"lubridate\")\n\npackages <- installed.packages()[,\"Package\"][! packages_to_install %in% installed.packages()[,\"Package\"]]\nif (length(packages) > 0) {\n\tinstall.packages(packages)\n}\n```\n:::\n\n\n# Séries classiques\n\nLe but des prochains exercices est d'étudier les séries classiques\n\n-   `LakeHuron` niveau annuel du Lac de Huron ;\n\n-   `sunspot.year` nombre annuel de tâches solaires entre 1770 et 1869 ;\n\n-   `AirPassengers` nombre mensuel de passagers aériens ;\n\n-   `nottem` température mensuelle moyenne au chateau de Nottingham.\n\n::: callout-note\n## Exercice\nÉtudier la série `LakeHuron` :  Faut-il transformer la série ? Quel modèle ARIMA parait adapté ? la série est elle stationnaire ? \nComparer avec `auto.arima()`.\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Indice\nAnalyser les ACF/PACF : est-ce qu'ils ressemblent à ceux d'une marche aléatoire ?\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(forecast)\nlibrary(patchwork)\nautoplot(LakeHuron)\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\nIl y a potentiellement une tendance à la baisse donc peut-être une tendance à la baisse.\nA priori pas de raison de transformer la série.\n\n::: {.cell}\n\n```{.r .cell-code}\ntseries::kpss.test(LakeHuron, \"Trend\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKPSS Test for Trend Stationarity\n\ndata:  LakeHuron\nKPSS Trend = 0.20006, Truncation lag parameter = 3, p-value = 0.01598\n```\n:::\n\n```{.r .cell-code}\ntseries::adf.test(LakeHuron)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAugmented Dickey-Fuller Test\n\ndata:  LakeHuron\nDickey-Fuller = -2.7796, Lag order = 4, p-value = 0.254\nalternative hypothesis: stationary\n```\n:::\n\n```{.r .cell-code}\n# Les tests KPSS et ADF considèrent que la série est non-stationnaire\n# ggAcf(LakeHuron) /\n# \tggPacf(LakeHuron)\nggtsdisplay(LakeHuron)\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\nL'ACF décroit de manière exponentielle et rapidement vers 0, ce n'est pas un signe de marche aléatoire.\nEn revanche le premier coefficient est élevé ce qui peut laisser penser que l'on n'a pas une marche aléatoire mais un coefficient AR(1) élevé.\nLe PACF est nul à partir de l'ordre 3 : cela peut laisser penser à un processus AR d'ordre au plus 2.\nOn estime un modèle ARIMA(2,0,0) avec une tendance (*drift*).\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_trend <- Arima(LakeHuron, order = c(2, 0, 0), include.drift = TRUE)\nmod_trend\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: LakeHuron \nARIMA(2,0,0) with drift \n\nCoefficients:\n         ar1      ar2  intercept    drift\n      1.0048  -0.2913   580.0915  -0.0216\ns.e.  0.0976   0.1004     0.4636   0.0081\n\nsigma^2 = 0.476:  log likelihood = -101.2\nAIC=212.4   AICc=213.05   BIC=225.32\n```\n:::\n\n```{.r .cell-code}\n# Le coefficient AR(1) est très proche de 1 ce qui explique que les tests précédents concluent à une non-stationnarité\nlmtest::coeftest(mod_trend) # tous les coefficients sont significatifs, pas de raison de simplifier\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nz test of coefficients:\n\n             Estimate  Std. Error   z value  Pr(>|z|)    \nar1         1.0048037   0.0976112   10.2939 < 2.2e-16 ***\nar2        -0.2913198   0.1003652   -2.9026  0.003701 ** \nintercept 580.0915109   0.4635882 1251.3079 < 2.2e-16 ***\ndrift      -0.0215688   0.0080988   -2.6632  0.007740 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# A priori les résidus sont un bruit blanc :\ncheckresiduals(mod_trend) \n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tLjung-Box test\n\ndata:  Residuals from ARIMA(2,0,0) with drift\nQ* = 3.9283, df = 8, p-value = 0.8635\n\nModel df: 2.   Total lags used: 10\n```\n:::\n\n```{.r .cell-code}\ncpgram(residuals(mod_trend))\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# En considérant un AR(1) on a un modèle avec un AIC plus grand\nmod_trend_ar1 <- Arima(LakeHuron, order = c(1, 0, 0), include.drift = TRUE)\nmod_trend_ar1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: LakeHuron \nARIMA(1,0,0) with drift \n\nCoefficients:\n         ar1  intercept    drift\n      0.7835   580.0936  -0.0204\ns.e.  0.0634     0.6075   0.0105\n\nsigma^2 = 0.5122:  log likelihood = -105.23\nAIC=218.45   AICc=218.88   BIC=228.79\n```\n:::\n\n```{.r .cell-code}\n# On aurait aussi pu faire un ARIMA(0,1,0) : c'est ce qui est retenu par auto.arima()\nmod_diff <- auto.arima(LakeHuron)\nmod_diff\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: LakeHuron \nARIMA(0,1,0) \n\nsigma^2 = 0.5588:  log likelihood = -109.11\nAIC=220.22   AICc=220.26   BIC=222.79\n```\n:::\n:::\n\nAttention : on ne peut comparer les modèles en utilisant l'AIC ! (ordre de différenciation différent).\nPour comparer les modèles on peut étudier les erreurs de prévision.\n\n::: {.cell}\n\n```{.r .cell-code}\nfar2 <- function(x, h){forecast(Arima(x, order=c(2,0,0), include.drift = TRUE), h=h)}\nfdiff <- function(x, h){forecast(Arima(x, order=c(0,1,0)), h=h)}\ne1 <- tsCV(LakeHuron, far2, h=1)\ne2 <- tsCV(LakeHuron, fdiff, h=1)\ne_oos <- na.omit(ts.union(e1, e2))\n# MSE plus petite avec second modèle\ncolMeans(e_oos^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       e1        e2 \n0.6151966 0.5409957 \n```\n:::\n\n```{.r .cell-code}\n# Mais cela vient du fait que lorsqu'il y a peu d'observations, le premier modèle est instable\ncolMeans(window(e_oos,start = 1890)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       e1        e2 \n0.5598778 0.5847280 \n```\n:::\n\n```{.r .cell-code}\ncolMeans(window(e_oos,start = 1900)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       e1        e2 \n0.5806291 0.6187056 \n```\n:::\n\n```{.r .cell-code}\n# Résidus In Sample toujours plus petits avec premier modèle\n# On commence en 1878 car ce n'est qu'après cette date que les résidus sont calculés par MLE\ne_is <- window(ts.union(residuals(mod_trend), residuals(mod_diff)),start = 1878)\ncolMeans(e_is^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nresiduals(mod_trend)  residuals(mod_diff) \n           0.4404010            0.5356053 \n```\n:::\n\n```{.r .cell-code}\ncolMeans(window(e_is,start = 1890)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nresiduals(mod_trend)  residuals(mod_diff) \n           0.4671440            0.5778036 \n```\n:::\n\n```{.r .cell-code}\ncolMeans(window(e_is,start = 1900)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nresiduals(mod_trend)  residuals(mod_diff) \n           0.4956467            0.6140781 \n```\n:::\n:::\n\n:::\n\n::: callout-note\n## Exercice\nÉtudier la série `sunspot.year` entre 1770 et 1869 :  Faut-il transformer la série ? Quel modèle ARIMA parait adapté ? la série est elle stationnaire ? \nComparer avec `auto.arima()`.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(forecast)\nlibrary(patchwork)\ny <- window(sunspot.year, start = 1770, end = 1869)\nggtsdisplay(y)\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\nPas de tendance ni de raison de transformer la série.\nIl y a des mouvements cycliques.\nA priori pas de raison de transformer la série.\nA priori pas une marche aléatoire.\n\n::: {.cell}\n\n```{.r .cell-code}\ntseries::kpss.test(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKPSS Test for Level Stationarity\n\ndata:  y\nKPSS Level = 0.15928, Truncation lag parameter = 4, p-value = 0.1\n```\n:::\n\n```{.r .cell-code}\ntseries::adf.test(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAugmented Dickey-Fuller Test\n\ndata:  y\nDickey-Fuller = -3.8579, Lag order = 4, p-value = 0.01889\nalternative hypothesis: stationary\n```\n:::\n:::\n\nLes tests KPSS et ADF considèrent que la série est non-stationnaire.\nOn remarque que l'ACF décroit rapidement vers O de manière sinusodiale  et que le PACF est nul à partir de l'ordre 3 : on estime un AR2.\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_ar2 <- Arima(y, order = c(2, 0, 0))\nmod_ar2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: y \nARIMA(2,0,0) with non-zero mean \n\nCoefficients:\n         ar1      ar2     mean\n      1.4059  -0.7111  48.2642\ns.e.  0.0706   0.0702   4.9747\n\nsigma^2 = 236.5:  log likelihood = -414.94\nAIC=837.88   AICc=838.3   BIC=848.3\n```\n:::\n\n```{.r .cell-code}\nlmtest::coeftest(mod_ar2) # tous les coefficients sont significatifs, pas de raison de simplifier\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nz test of coefficients:\n\n           Estimate Std. Error  z value  Pr(>|z|)    \nar1        1.405873   0.070572  19.9212 < 2.2e-16 ***\nar2       -0.711095   0.070242 -10.1235 < 2.2e-16 ***\nintercept 48.264166   4.974715   9.7019 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# A priori les résidus sont un bruit blanc :\ncheckresiduals(mod_ar2) \n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tLjung-Box test\n\ndata:  Residuals from ARIMA(2,0,0) with non-zero mean\nQ* = 12.793, df = 8, p-value = 0.1192\n\nModel df: 2.   Total lags used: 10\n```\n:::\n\n```{.r .cell-code}\ncpgram(residuals(mod_ar2))\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Auto.arima sélectionne un ARIMA(2,0,1) qui a un AICc plus petit\nmod_auto <- auto.arima(y)\nmod_auto\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: y \nARIMA(2,0,1) with non-zero mean \n\nCoefficients:\n         ar1      ar2     ma1     mean\n      1.2273  -0.5620  0.3733  48.5319\ns.e.  0.1134   0.1084  0.1344   6.0130\n\nsigma^2 = 225.1:  log likelihood = -412.05\nAIC=834.09   AICc=834.73   BIC=847.12\n```\n:::\n\n```{.r .cell-code}\naccuracy(mod_ar2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     ME     RMSE      MAE  MPE MAPE      MASE      ACF1\nTraining set -0.1065321 15.14691 12.03611 -Inf  Inf 0.7027453 0.1297447\n```\n:::\n\n```{.r .cell-code}\naccuracy(mod_auto)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     ME     RMSE      MAE  MPE MAPE      MASE        ACF1\nTraining set -0.1925486 14.70035 11.89705 -Inf  Inf 0.6946261 -0.02480733\n```\n:::\n\n```{.r .cell-code}\nfar2 <- function(x, h){forecast(Arima(x, order=c(2,0,0)), h=h)}\nfar2ma1 <- function(x, h){forecast(Arima(x, order=c(2,0,1)), h=h)}\ne1 <- tsCV(y, far2, h=1)\ne2 <- tsCV(y, far2ma1, h=1)\ne_oos <- window(ts.intersect(e1, e2), start = 1780)\n# MSE plus petite avec second modèle\ncolMeans(e_oos^2,na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      e1       e2 \n217.5813 204.6266 \n```\n:::\n:::\n\n:::\n\n::: callout-note\n## Exercice\nÉtudier la série `AirPassengers` :  Faut-il transformer la série ? Quel modèle ARIMA parait adapté ? la série est elle stationnaire ? \nComparer avec `auto.arima()`.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(AirPassengers)\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\nTendance claire avec une saisonnalité multiplicative.\nIl faut passer la série au log.\n\n::: {.cell}\n\n```{.r .cell-code}\nggtsdisplay(log(AirPassengers))\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\nL'analyse de l'ACF montre une décroissance lente avec des pics saisonniers.\nL'analyse du PACF montre deux pics : à l'ordre 1 proche de 1 et à l'ordre 13.\nLe second pic à l'ordre 13 et non 12 peut suggérer une double différenciation $(1-B)(1-B^{12})$.\nLa présence d'une saisonnalité a déjà été analysée dans les précédents TP : un test n'est pas nécessaire et on peut différencier à l'ordre 12.\n\n::: {.cell}\n\n```{.r .cell-code}\nggtsdisplay(diff(log(AirPassengers), 12))\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\nLa série différenciée ne présente pas de tendance mais des périodes de hausse et de baisse. \nL'ACF décroit vers 0 mais pas de manière exponentielle. \nLe premier coefficient de l'ACF/PACF est élevé ce qui peut laisser penser que la série est toujours non-stationnaire\n\n::: {.cell}\n\n```{.r .cell-code}\ntseries::kpss.test(diff(log(AirPassengers), 12))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKPSS Test for Level Stationarity\n\ndata:  diff(log(AirPassengers), 12)\nKPSS Level = 0.36816, Truncation lag parameter = 4, p-value = 0.09088\n```\n:::\n\n```{.r .cell-code}\ntseries::adf.test(diff(log(AirPassengers), 12))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAugmented Dickey-Fuller Test\n\ndata:  diff(log(AirPassengers), 12)\nDickey-Fuller = -3.1899, Lag order = 5, p-value = 0.09265\nalternative hypothesis: stationary\n```\n:::\n\n```{.r .cell-code}\ntseries::pp.test(diff(log(AirPassengers), 12))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPhillips-Perron Unit Root Test\n\ndata:  diff(log(AirPassengers), 12)\nDickey-Fuller Z(alpha) = -37.597, Truncation lag parameter = 4, p-value\n= 0.01\nalternative hypothesis: stationary\n```\n:::\n\n```{.r .cell-code}\n# Les tests KPSS, ADF et PP donnent des résultats différents : à 5 % le test KPSS ne rejette l'hypothèse nulle de stationnarité, le test de PP rejette l'hypothèse de non-stationnarité alors qu'ADF ne la rejette pas.\nndiffs(diff(log(AirPassengers), 12))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n:::\n\nLa fonction `ndiffs()`, basée par défaut sur KPSS conclue à une non-stationnarité. \nCela vient de paramètres différents dans le test KPSS utilisé.\nL'analyse des ACF semblent plutôt montrer un présence de marche aléatoire : on différencie.\nLes ACF et PACF semblent montrer une saisonnalité encore présente mais pas de décroissance nette de l'ACF ou PACF.\n\n::: {.cell}\n\n```{.r .cell-code}\nggAcf(diff(diff(log(AirPassengers), 12), 1)) /\n\tggPacf(diff(diff(log(AirPassengers), 12), 1))\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmod = Arima(AirPassengers, order = c(0,1,0), seasonal = c(1,1,1), lambda = 0)\nBox.test(resid(mod), fitdf = 2,lag = 24,type = \"Ljung\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBox-Ljung test\n\ndata:  resid(mod)\nX-squared = 48.603, df = 22, p-value = 0.0009028\n```\n:::\n\n```{.r .cell-code}\ncpgram(resid(mod))\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# checkresiduals(mod)\n# Les résidus ne sont pas un bruit blanc\nggAcf(residuals(mod)) /\n\tggPacf(residuals(mod))\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-13-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# Encore pas de décroissance claire mais un pic à l'ordre 1\n# on peut donc penser que p,q, P,q <= 1\nmod1 <- Arima(AirPassengers, order = c(1,1,1), seasonal = c(1,1,1), lambda = 0)\n# On a bien un bruit blanc cette fois\nBox.test(resid(mod1), fitdf = 4,lag = 24,type = \"Ljung\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBox-Ljung test\n\ndata:  resid(mod1)\nX-squared = 24.669, df = 20, p-value = 0.2144\n```\n:::\n\n```{.r .cell-code}\ncpgram(resid(mod1))\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-13-4.png){width=672}\n:::\n\n```{.r .cell-code}\nlmtest::coeftest(mod1) # ordres AR non significatifs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nz test of coefficients:\n\n      Estimate Std. Error z value  Pr(>|z|)    \nar1   0.166649   0.245890  0.6777 0.4979380    \nma1  -0.561499   0.211550 -2.6542 0.0079493 ** \nsar1 -0.099007   0.153981 -0.6430 0.5202347    \nsma1 -0.497321   0.135967 -3.6577 0.0002545 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# on va enlève un ordre AR et on refait le test : ne pas enlever toutes les variables car on teste ici si une variable est nulle et non pas si un ensemble de variables est nul\n\nmod2 <- Arima(AirPassengers, order = c(0,1,1), seasonal = c(1,1,1), lambda = 0)\n# Toujours un bruit blanc et AR saisonnier non significatif\nBox.test(resid(mod2), fitdf = 3,lag = 24,type = \"Ljung\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBox-Ljung test\n\ndata:  resid(mod2)\nX-squared = 25.475, df = 21, p-value = 0.2272\n```\n:::\n\n```{.r .cell-code}\nlmtest::coeftest(mod2) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nz test of coefficients:\n\n      Estimate Std. Error z value  Pr(>|z|)    \nma1  -0.414254   0.089933 -4.6063   4.1e-06 ***\nsar1 -0.111647   0.154748 -0.7215 0.4706159    \nsma1 -0.481706   0.136304 -3.5341 0.0004092 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nmod3 = Arima(AirPassengers, order = c(0,1,1), seasonal = c(0,1,1), lambda = 0)\n# Toujours un bruit blanc et tous les coefs sont signifactifs, on ne peut pas simplifier davantage\nBox.test(resid(mod3), fitdf = 2,lag = 24,type = \"Ljung\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBox-Ljung test\n\ndata:  resid(mod3)\nX-squared = 26.446, df = 22, p-value = 0.233\n```\n:::\n\n```{.r .cell-code}\nlmtest::coeftest(mod3) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nz test of coefficients:\n\n      Estimate Std. Error z value  Pr(>|z|)    \nma1  -0.401828   0.089644 -4.4825 7.378e-06 ***\nsma1 -0.556945   0.073100 -7.6190 2.557e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# C'est le dernier modèle qui a l'AIC le plus petit : c'est celui que l'on retient\nAIC(mod1, mod2, mod3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     df       AIC\nmod1  5 -480.3109\nmod2  4 -481.9131\nmod3  3 -483.3991\n```\n:::\n\n```{.r .cell-code}\n# C'est aussi le modèle retenu par auto.arima\nauto.arima(AirPassengers, lambda = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: AirPassengers \nARIMA(0,1,1)(0,1,1)[12] \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ma1     sma1\n      -0.4018  -0.5569\ns.e.   0.0896   0.0731\n\nsigma^2 = 0.001371:  log likelihood = 244.7\nAIC=-483.4   AICc=-483.21   BIC=-474.77\n```\n:::\n\n```{.r .cell-code}\n# auto.arima(AirPassengers, lambda = 0, stepwise = FALSE) # plus lent\n```\n:::\n\nOn retrouve le modèle Airline : ARIMA(0,1,1)(0,1,1) !\n:::\n\nPour l'analyse de la série `nottem`, on utilisera le `tidyverts`.\nCi-dessous un exemple de manipulation avec une autre série :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tsibble)\nlibrary(dplyr)\nlibrary(fable)\nlibrary(feasts)\nlibrary(ggplot2)\ny <- as_tsibble(USAccDeaths)\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tsibble: 72 x 2 [1M]\n      index value\n      <mth> <dbl>\n 1 1973 jan  9007\n 2 1973 fév  8106\n 3 1973 mar  8928\n 4 1973 avr  9137\n 5 1973 mai 10017\n 6 1973 jui 10826\n 7 1973 jul 11317\n 8 1973 aoû 10744\n 9 1973 sep  9713\n10 1973 oct  9938\n# … with 62 more rows\n```\n:::\n\n```{.r .cell-code}\n(y %>% ACF(value %>%  difference(12)) %>% autoplot()) /\n\t(y %>% PACF(value %>%  difference(12)) %>% autoplot()) & ylim(-1,1)\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmodel <- y %>%\n\tmodel(arima = ARIMA(value ~ 0 + pdq(0, 1, 1) + PDQ(0, 1, 0)),\n\t\t  auto_arima = ARIMA(value))\nmodel \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A mable: 1 x 2\n                      arima                auto_arima\n                    <model>                   <model>\n1 <ARIMA(0,1,1)(0,1,0)[12]> <ARIMA(0,1,1)(0,1,1)[12]>\n```\n:::\n\n```{.r .cell-code}\nmodel %>% accuracy()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 10\n  .model     .type       ME  RMSE   MAE   MPE  MAPE  MASE RMSSE     ACF1\n  <chr>      <chr>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>\n1 arima      Training  44.0  321.  230. 0.477  2.70 0.526 0.574  0.00648\n2 auto_arima Training  58.8  285.  201. 0.665  2.35 0.460 0.510 -0.0239 \n```\n:::\n\n```{.r .cell-code}\nmodel %>% glance()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 8\n  .model      sigma2 log_lik   AIC  AICc   BIC ar_roots  ma_roots  \n  <chr>        <dbl>   <dbl> <dbl> <dbl> <dbl> <list>    <list>    \n1 arima      128002.   -430.  865.  865.  869. <cpl [0]> <cpl [1]> \n2 auto_arima 102860.   -425.  857.  857.  863. <cpl [0]> <cpl [13]>\n```\n:::\n\n```{.r .cell-code}\nmodel %>% residuals() %>%  ACF() %>%  autoplot()\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# On peut utiliser la fonction report() sur un sous modèle\nmodel %>% select(auto_arima) %>% \n\treport()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: value \nModel: ARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.4303  -0.5528\ns.e.   0.1228   0.1784\n\nsigma^2 estimated as 102860:  log likelihood=-425.44\nAIC=856.88   AICc=857.32   BIC=863.11\n```\n:::\n\n```{.r .cell-code}\nmodel %>% \n\tforecast(h=12) %>%  \n\tautoplot(y)\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-14-3.png){width=672}\n:::\n:::\n\n\n::: callout-note\n## Exercice\nÉtudier la série `as_tsibble(nottem)` :  \n\n1. Faut-il transformer la série ?  \n2. Faut-il différencier la série ? (utiliser la fonction `difference()`) \n3. Étudier les ACF/PACF : quels sont les ordre plausibles ?\n4. Tester un ensemble de modèles possibles. Les trier par AICc et prendre celui qui le minimise.\n5. Vérifier la qualité des résidus\n6. Comparer les prévisions avec une sélection automatique et avec un modèle ETS.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\ny <- as_tsibble(nottem)\n# Pas de transformation de la série a priori nécessaire\nautoplot(y, value)\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\ngg_season(y, value)\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-15-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Série déjà étudiée : pas de tendance et saisonnalité mensuelle nette\n# pas de raison de transformer la série\ny %>% gg_tsdisplay(value %>%  difference(12), plot_type = \"partial\")\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-15-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# A priori série différenciée est stationnaire\n# L'analyse des ACF/PACF suggère P= 1 et/ou Q=1, P<=1 et Q <= 2\n# Pas de constante dans le modèle\n# Si on ne veut pas écrire tous les codes à la main on peut aussi faire un programme\n# d = expand.grid(p=0:1,q=0:2,P=0:1, Q=0:1)\n# cat(sprintf(\"sarima%i0%i_%i1%i = ARIMA(value ~ -1 + pdq(%i, 0, %i) + PDQ(%i, 1, %i))\",\n# \t\td$p, d$q, d$P, d$Q,\n# \t\td$p, d$q, d$P, d$Q), sep =\",\\n\")\nall_models <- y %>%\n\tmodel(\n\t\tsarima000_010 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(0, 1, 0)),\n\t\tsarima100_010 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(0, 1, 0)),\n\t\tsarima001_010 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(0, 1, 0)),\n\t\tsarima101_010 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(0, 1, 0)),\n\t\tsarima002_010 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(0, 1, 0)),\n\t\tsarima102_010 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(0, 1, 0)),\n\t\tsarima000_110 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(1, 1, 0)),\n\t\tsarima100_110 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 0)),\n\t\tsarima001_110 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(1, 1, 0)),\n\t\tsarima101_110 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(1, 1, 0)),\n\t\tsarima002_110 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(1, 1, 0)),\n\t\tsarima102_110 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(1, 1, 0)),\n\t\tsarima000_011 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(0, 1, 1)),\n\t\tsarima100_011 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(0, 1, 1)),\n\t\tsarima001_011 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(0, 1, 1)),\n\t\tsarima101_011 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(0, 1, 1)),\n\t\tsarima002_011 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(0, 1, 1)),\n\t\tsarima102_011 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(0, 1, 1)),\n\t\tsarima000_111 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(1, 1, 1)),\n\t\tsarima100_111 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 1)),\n\t\tsarima001_111 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(1, 1, 1)),\n\t\tsarima101_111 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(1, 1, 1)),\n\t\tsarima002_111 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(1, 1, 1)),\n\t\tsarima102_111 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(1, 1, 1))\n\t)\nall_models %>% \n\tglance() %>% \n\tarrange(AICc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 24 × 8\n   .model        sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots  \n   <chr>          <dbl>   <dbl> <dbl> <dbl> <dbl> <list>     <list>    \n 1 sarima100_111   5.25   -519. 1045. 1045. 1059. <cpl [13]> <cpl [12]>\n 2 sarima002_111   5.23   -518. 1045. 1046. 1063. <cpl [12]> <cpl [14]>\n 3 sarima101_111   5.25   -518. 1046. 1046. 1063. <cpl [13]> <cpl [13]>\n 4 sarima102_111   5.25   -518. 1047. 1048. 1068. <cpl [13]> <cpl [14]>\n 5 sarima001_111   5.33   -520. 1048. 1048. 1062. <cpl [12]> <cpl [13]>\n 6 sarima002_011   5.44   -524. 1055. 1056. 1069. <cpl [0]>  <cpl [14]>\n 7 sarima100_011   5.48   -525. 1056. 1056. 1066. <cpl [1]>  <cpl [12]>\n 8 sarima101_011   5.46   -524. 1056. 1056. 1070. <cpl [1]>  <cpl [13]>\n 9 sarima102_011   5.46   -524. 1057. 1057. 1074. <cpl [1]>  <cpl [14]>\n10 sarima001_011   5.55   -526. 1058. 1058. 1069. <cpl [0]>  <cpl [13]>\n# … with 14 more rows\n```\n:::\n\n```{.r .cell-code}\nbest_model <- y %>%\n\tmodel(\n\t\tsarima100_111 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 1))\n\t)\n# A priori bruit blanc :\nbest_model %>% gg_tsresiduals()\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-15-4.png){width=672}\n:::\n\n```{.r .cell-code}\naugment(best_model) %>% \n\tfeatures(.innov, ljung_box, dof = 3, lag = 24)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .model        lb_stat lb_pvalue\n  <chr>           <dbl>     <dbl>\n1 sarima100_111    20.6     0.484\n```\n:::\n\n```{.r .cell-code}\ncompar_model <- y %>%\n\tmodel(\n\t\tsarima100_111 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 1)),\n\t\tauto_arima = ARIMA(value ~ -1),\n\t\tets = ETS(value)\n\t)\n# Modèle sélectionné a un AICc plus petit que l'auto-arima  mais un RMSE plus élevé\ncompar_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A mable: 1 x 3\n              sarima100_111                auto_arima          ets\n                    <model>                   <model>      <model>\n1 <ARIMA(1,0,0)(1,1,1)[12]> <ARIMA(1,0,2)(1,1,2)[12]> <ETS(A,N,A)>\n```\n:::\n\n```{.r .cell-code}\ncompar_model %>% glance()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 11\n  .model      sigma2 log_lik   AIC  AICc   BIC ar_ro…¹ ma_ro…²   MSE  AMSE   MAE\n  <chr>        <dbl>   <dbl> <dbl> <dbl> <dbl> <list>  <list>  <dbl> <dbl> <dbl>\n1 sarima100_…   5.25   -519. 1045. 1045. 1059. <cpl>   <cpl>   NA    NA    NA   \n2 auto_arima    5.23   -517. 1048. 1048. 1072. <cpl>   <cpl>   NA    NA    NA   \n3 ets           5.38   -852. 1735. 1737. 1787. <NULL>  <NULL>   5.07  5.17  1.74\n# … with abbreviated variable names ¹​ar_roots, ²​ma_roots\n```\n:::\n\n```{.r .cell-code}\ncompar_model %>% accuracy()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 10\n  .model        .type         ME  RMSE   MAE    MPE  MAPE  MASE RMSSE     ACF1\n  <chr>         <chr>      <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>\n1 sarima100_111 Training 0.0695   2.22  1.72 -0.127  3.69 0.638 0.647 -0.0197 \n2 auto_arima    Training 0.0711   2.20  1.71 -0.124  3.67 0.635 0.641  0.00160\n3 ets           Training 0.00726  2.25  1.74 -0.223  3.75 0.647 0.656  0.198  \n```\n:::\n\n```{.r .cell-code}\n# Prévisions des 3 modèles sont très proches\nforecast(compar_model, h =\"1 year\") %>% \n\tautoplot(y %>% filter(year(index) >= 1938))\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-15-5.png){width=672}\n:::\n:::\n\n::: \n\nL'avantage est `tidyverts` est que l'on peut appliquer facilement plusieurs fonctions à plusieurs séries et comparer les méthodes entre elles.\nEn reprenant l'exemple disponible ici <https://fable.tidyverts.org>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fable)\nlibrary(tsibble)\nlibrary(tsibbledata)\nlibrary(lubridate)\nlibrary(dplyr)\naus_retail %>%\n\tfilter(\n\t\tState %in% c(\"New South Wales\", \"Victoria\"),\n\t\tIndustry == \"Department stores\"\n\t) %>% \n\tmodel(\n\t\tets = ETS(box_cox(Turnover, 0.3)),\n\t\tarima = ARIMA(log(Turnover)),\n\t\tsnaive = SNAIVE(Turnover)\n\t) %>%\n\tforecast(h = \"2 years\") %>% \n\tautoplot(filter(aus_retail, year(Month) > 2010), level = NULL)\n```\n\n::: {.cell-output-display}\n![](5_ARIMA_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
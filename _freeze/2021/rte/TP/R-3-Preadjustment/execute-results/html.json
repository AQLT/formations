{
  "hash": "2a131c4b6348f03b58f7fa8ff05c6614",
  "result": {
    "markdown": "---\ntitle: \"3 - Qualité du préajustement sous R\"\nsubtitle: |\n  Formation - Désaisonnalisation avec JDemetra+ et RJDemetra\n  ![](img/logo.png){width=1in}\nauthor: \"Alain Quartier-la-Tente\"\nformat: html\nlang: fr\nlanguage:\n title-block-author-single: Auteur\n---\n\n\n\n\n\n> L'objectif de ce TP est d'apprendre à vérifier la qualité du pré-ajustement dans RJDemetra\n\nSi besoin, ci-dessous un exemple de code pour récupérer vos données :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfichier <- \"../data/data_rte.xlsx\"\n# # Ou en téléchargeant le fichier depuis internet :\n# fichier <- tempfile(fileext = \"xlsx\")\n# url <- \"https://aqlt.github.io/formations/2021/rte/data/data_rte.xlsx\"\n# download.file(url, fichier)\ndata_rte <- readxl::read_excel(fichier)\ndate_deb <- 2006\ndata_rte <- ts(data_rte[,-1], start = date_deb,\n               frequency = 12)\n```\n:::\n\n\nPrenons une spécification par défaut :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(RJDemetra)\nipi_fr <- ipi_c_eu[, \"FR\"]\nmysa <- x13(ipi_fr)\n```\n:::\n\n\nComme on l'a vu dans le TP2, les tests de Student peuvent être utilisés pour tester la significativité des coefficients, et on peut également faire des tests de Fisher avec le package `car` pour voir si l'on peut simplifier les régresseurs jours ouvrables.\nVoir également le TP2 pour les tests sur la présence de jours ouvrables résiduelle.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mysa$regarima)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ny = regression model + arima (2, 1, 1, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-1990 to 12-2020\nLog-transformation: no\nRegression model: no mean, trading days effect(7), leap year effect, Easter effect, outliers(4)\n\nCoefficients:\nARIMA: \n            Estimate Std. Error  T-stat Pr(>|t|)    \nPhi(1)     0.0003269  0.1077296   0.003   0.9976    \nPhi(2)     0.1688192  0.0740996   2.278   0.0233 *  \nTheta(1)  -0.5485606  0.1016550  -5.396 1.24e-07 ***\nBTheta(1) -0.6660849  0.0422242 -15.775  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n              Estimate Std. Error  T-stat Pr(>|t|)    \nMonday         0.55932    0.22801   2.453 0.014638 *  \nTuesday        0.88221    0.22832   3.864 0.000132 ***\nWednesday      1.03996    0.22930   4.535 7.85e-06 ***\nThursday       0.04943    0.22944   0.215 0.829549    \nFriday         0.91132    0.22988   3.964 8.88e-05 ***\nSaturday      -1.57769    0.22775  -6.927 1.99e-11 ***\nLeap year      2.15403    0.70527   3.054 0.002425 ** \nEaster [1]    -2.37950    0.45391  -5.242 2.71e-07 ***\nTC (4-2020)  -35.59245    2.17330 -16.377  < 2e-16 ***\nAO (3-2020)  -20.89026    2.18013  -9.582  < 2e-16 ***\nAO (5-2011)   13.49850    1.85694   7.269 2.28e-12 ***\nLS (11-2008) -12.54901    1.63554  -7.673 1.60e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 2.218 on 342 degrees of freedom\nLog likelihood = -799.1, aic =  1632, aicc =  1634, bic(corrected for length) = 1.855\n```\n:::\n\n```{.r .cell-code}\nlibrary(car)\n# On rejette l'hypothèse de nullité globale des coefficients\nlinearHypothesis(mysa,\n                 c(\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"),\n                 c(0, 0, 0, 0, 0, 0), test = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear hypothesis test\n\nHypothesis:\nMonday = 0\nTuesday = 0\nWednesday = 0\nThursday = 0\nFriday = 0\nSaturday = 0\n\nModel 1: restricted model\nModel 2: mysa\n\n  Res.Df Df      F    Pr(>F)    \n1    348                        \n2    342  6 83.415 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# On pourrait rassembler les jours de la semaine :\nlinearHypothesis(mysa,\n                 c(\"Monday = Tuesday\",\"Tuesday = Wednesday\",\"\n                   Wednesday = Thursday\", \"Thursday = Friday\"), test = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear hypothesis test\n\nHypothesis:\nMonday - Tuesday = 0\nTuesday - Wednesday = 0\nWednesday - Thursday = 0\nThursday - Friday = 0\n\nModel 1: restricted model\nModel 2: mysa\n\n  Res.Df Df      F  Pr(>F)  \n1    346                    \n2    342  4 2.1504 0.07429 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nConcernant la qualité du modèle RegARIMA, on peut citer trois tests :\n\n-   Le test d'indépendance des résidus\n\n-   Le test d'homoscédasticité des résidus\n\n-   Le test de normalité des résidus\n\nCes trois tests, également disponibles par des fonctions spécifiques sous R (la commande `residuals(mysa)` permet de récupérer les résidus du modèle), sont également disponibles dans le sous objet `.$regarima$residuals.stat$tests` :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmysa$regarima$residuals.stat$tests\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\u001b[1mNormality\u001b[22m\n         Statistic P.value    \nmean       0.12648  0.8994 ***\nskewness  -0.01954  0.8799 ***\nkurtosis   3.54844  0.0339    \n\nSignif. codes:  H0 (normality of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mIndependence\u001b[22m\n                                       Statistic P.value    \nljung box                               55.08622  0.0000    \nljung box (residuals at seasonal lags)   3.09960  0.2123 ***\n\nSignif. codes: H0 (independence of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n\n\u001b[1mLinearity\u001b[22m\n                              Statistic P.value  \nljung box (squared residuals)  34.36237  0.0238  \n\nSignif. codes:  H0 (no conditional heteroscedasticity of residuals) is not rejected at \nsignificance levels: 0.1 ***0.05 **\n```\n:::\n:::\n\n\nL'hétéroscédasticité et la non-normalité proviennent souvent de la présence de points atypiques non corrigés (pour jouer sur le seuil de détection, rajouter dans la spécification `outlier.usedefcv = FALSE` et prendre une valeur de `outlier.cv` inférieur à 4, qui est la valeur par défaut).\nChanger le schéma de décomposition peut aussi aider (`transform.function = \"None\"` pour un modèle additif ou `transform.function = \"Log\"` pour un modèle multiplicatif) :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmysa2 <- x13(ipi_fr, x13_spec(mysa, outlier.usedefcv = FALSE,\n                              outlier.cv = 3))\n# Bien plus d'outliers sont détectés !\nsummary(mysa2$regarima)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ny = regression model + arima (3, 1, 1, 0, 1, 1)\n\nModel: RegARIMA - X13\nEstimation span: from 1-1990 to 12-2020\nLog-transformation: no\nRegression model: no mean, trading days effect(7), leap year effect, Easter effect, outliers(28)\n\nCoefficients:\nARIMA: \n          Estimate Std. Error T-stat Pr(>|t|)    \nPhi(1)     0.27920    0.09413  2.966  0.00322 ** \nPhi(2)     0.36429    0.07687  4.739 3.10e-06 ***\nPhi(3)     0.11811    0.07680  1.538  0.12496    \nTheta(1)  -0.63217    0.08106 -7.799 6.84e-14 ***\nBTheta(1) -0.34211    0.05369 -6.372 5.72e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRegression model: \n             Estimate Std. Error  T-stat Pr(>|t|)    \nMonday         0.3870     0.1811   2.137 0.033265 *  \nTuesday        0.9721     0.1818   5.348 1.58e-07 ***\nWednesday      0.8970     0.1830   4.903 1.43e-06 ***\nThursday       0.1836     0.1826   1.006 0.315205    \nFriday         0.9678     0.1846   5.244 2.69e-07 ***\nSaturday      -1.6723     0.1829  -9.145  < 2e-16 ***\nLeap year      1.7207     0.5026   3.423 0.000690 ***\nEaster [1]    -2.3262     0.3536  -6.578 1.68e-10 ***\nTC (4-2020)  -34.9803     1.3450 -26.007  < 2e-16 ***\nAO (3-2020)  -20.5598     1.6847 -12.204  < 2e-16 ***\nAO (5-2011)   11.6856     1.3242   8.825  < 2e-16 ***\nLS (11-2008)  -9.4587     1.0474  -9.030  < 2e-16 ***\nLS (1-2009)   -7.8963     1.0256  -7.699 1.34e-13 ***\nAO (6-2019)   -5.7932     1.4256  -4.064 5.94e-05 ***\nLS (8-2009)    5.7013     0.8196   6.957 1.66e-11 ***\nTC (1-2011)    5.6019     1.0501   5.334 1.70e-07 ***\nAO (5-2018)   -4.5600     1.3401  -3.403 0.000743 ***\nLS (5-2008)   -4.7919     0.7824  -6.125 2.38e-09 ***\nAO (5-2000)    5.2033     1.3250   3.927 0.000103 ***\nAO (6-2003)   -5.4817     1.3322  -4.115 4.81e-05 ***\nAO (5-1991)   -4.5123     1.3544  -3.332 0.000953 ***\nLS (5-1994)    3.2027     0.7772   4.121 4.69e-05 ***\nTC (12-2009)  -4.5311     1.0961  -4.134 4.44e-05 ***\nLS (3-1997)    3.5716     0.7567   4.720 3.38e-06 ***\nLS (1-1993)   -3.4933     0.7611  -4.590 6.15e-06 ***\nAO (8-2020)    6.3136     1.6987   3.717 0.000234 ***\nTC (11-2000)   5.8864     1.0215   5.762 1.79e-08 ***\nTC (8-2015)    3.5207     0.9715   3.624 0.000332 ***\nTC (12-1999)   4.4543     1.0307   4.322 2.01e-05 ***\nLS (10-1997)   2.7159     0.7569   3.588 0.000379 ***\nTC (12-1994)   4.2812     0.9973   4.293 2.27e-05 ***\nTC (10-2017)   3.9944     0.9801   4.076 5.65e-05 ***\nLS (11-2019)  -3.0752     0.9235  -3.330 0.000959 ***\nLS (2-2004)    2.1923     0.7651   2.865 0.004409 ** \nAO (6-2011)   -4.8397     1.3372  -3.619 0.000338 ***\nTC (11-2011)   4.0079     1.0178   3.938 9.88e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 1.627 on 317 degrees of freedom\nLog likelihood = -685.6, aic =  1455, aicc =  1467, bic(corrected for length) = 1.646\n```\n:::\n:::\n\n\nLa qualité des prévisions peut également être vérifiée à travers plusieurs tests :\n\n-   Est-ce que la moyenne des erreurs prévisions *in sample* (i.e. : modèle estimé sur toute la période) et la moyenne des prévisions *out of sample* (i.e. : modèle estimé de manière dynamique en ajoutant une a à une les nouvelles données) sont nulles ?\n    Ces tests sont sensibles à la non-normalité des résidus\n\n-   Est-ce que les variances des erreurs de prévision *in sample* et *out of sample* sont les mêmes ?\n    Ce test est sensible à la non-normalité des résidus\n\n-   Est-ce qu'il y a \"trop\" d'outliers ?\n    Dans JDemetra+, on considère par défaut qu'il y a trop d'outliers si la proportion d'outliers par rapport aux nombres d'observations est supérieure à 5 %.\n\nLes trois premiers tests ne sont pas par défaut exportés dans RJDemetra : il faut les rajouter à la main avec le paramètre `userdefined`.\nIls seront alors disponibles dans la sous-liste `.$user_defined`.\nConcernant la proportion d'outliers, elle peut être calculée à la main à partir du nombre d'outliers (par exemple disponible dans `.$regarima$model$spec_rslt`) :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmysa <- x13(ipi_fr, x13_spec(mysa),\n            userdefined = c(\"diagnostics.fcast-insample-mean\",\n                            \"diagnostics.fcast-outsample-mean\",\n                            \"diagnostics.fcast-outsample-variance\"))\nmysa$regarima$model$spec_rslt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           Model                 T.span Log transformation  Mean Trading days\n1 RegARIMA - X13 from 1-1990 to 12-2020              FALSE FALSE            7\n  Leap year Easter Outliers\n1      TRUE   TRUE        4\n```\n:::\n\n```{.r .cell-code}\n# Pour éviter outputs trop longs, l'affichage est réduit :\nmysa$user_defined\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNames of additional variables (3):\ndiagnostics.fcast-insample-mean, diagnostics.fcast-outsample-mean, diagnostics.fcast-outsample-variance\n```\n:::\n\n```{.r .cell-code}\n# Pour supprimer cela, vous pouvez par exemple utiliser le code suivant :\nc(mysa$user_defined)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$`diagnostics.fcast-insample-mean`\n[1] 0.3057321 0.7599958\nattr(,\"description\")\n[1] \"T with 340 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-mean`\n[1] -0.7781656  0.4370126\nattr(,\"description\")\n[1] \"T with 340 degrees of freedom\"\n\n$`diagnostics.fcast-outsample-variance`\n[1] 1.1383576 0.3128808\nattr(,\"description\")\n[1] \"F with 18 degrees of freedom in the nominator and 341 degrees of freedom in the denominator\"\n```\n:::\n:::\n\n\nVous pouvez bien sûr utiliser votre tests préféré à partir de ceux disponibles sous R (autre test de normalité...).\n\nPour comparer différents modèles, vous pouvez également utiliser les critères d'information (mais il faut que les modèles ARIMA aient les mêmes ordres de différenciation !).\nVous pouvez pour cela utiliser les fonctions de bases de R (`AIC()`, `BIC()`...) ou prendre ceux de JDemetra+ (affichés lors du `summary()`, qu'on peut également retrouver par la commande `.$regarima$loglik`) :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(mysa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1632.169\n```\n:::\n\n```{.r .cell-code}\nBIC(mysa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1698.185\n```\n:::\n\n```{.r .cell-code}\n# Il y a un peu plus de critères que dans base R : AICc et BICc\nmysa$regarima$loglik\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                         \nlogvalue      -799.084484\nnp              17.000000\nneffectiveobs  359.000000\naic           1632.168967\naicc          1633.963689\nbic           1698.185448\nbicc             1.855018\n```\n:::\n:::\n\n\n::: callout-note\n## Exercice\nPrenez une série et étudier la qualité du modèle RegARIMA. Essayer de changer quelques paramètres : est-ce que le nouveau modèle vous parait meilleur ou moins bien que l'ancien ?\n:::\n",
    "supporting": [
      "R-3-Preadjustment_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
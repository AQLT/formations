---
title: "5 - Modèles ARIMA"
subtitle: |
  Analyse des séries temporelles avec R
author: "Alain Quartier-la-Tente"
format: html
lang: fr
language: 
 title-block-author-single: Auteur
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, collapse = FALSE, warning = FALSE,
					  message = FALSE,cache = FALSE)
```

> L'objectif de ce TP est d'apprendre à manipuler des modèles (S)ARIMA

Les modèles ARIMA peuvent être estimés grâce à plusieurs fonctions, sans être exhaustif :

-   `stats::arima()` dans les fonctions de base de R ;

-   `forecast::Arima()` basée sur `stats::arima()` mais qui permet d'ajouter un terme de dérive et se manipule plus facilement avec autres fonctions de `forecast` ;

-   `fable::ARIMA()` comme `forecast::Arima()` mais pour les objets `tsibble`.

Les packages suivants seront utilisés :

```{r,warning=FALSE, message=FALSE, eval=FALSE}
packages_to_install <- c("ggplot2", "forecast", "RJDemetra", "patchwork", "lmtest",
						 "tsibble", "fable", "feasts", "dplyr", "lubridate")

packages <- installed.packages()[,"Package"][! packages_to_install %in% installed.packages()[,"Package"]]
if (length(packages) > 0) {
	install.packages(packages)
}
```

Le but des prochains exercices est d'étudier les séries classiques

-   `LakeHuron` niveau annuel du Lac de Huron ;

-   `sunspot.year` nombre annuel de tâches solaires entre 1770 et 1869 ;

-   `AirPassengers` nombre mensuel de passagers aériens ;

-   `nottem` température mensuelle moyenne au chateau de Nottingham.

# Niveau du Lac de Huron

::: callout-note
## Exercice
Étudier la série `LakeHuron` :  Faut-il transformer la série ? Quel modèle ARIMA parait adapté ? la série est elle stationnaire ? 
Comparer avec `auto.arima()`.
:::

::: {.callout-caution collapse="true"}
## Indice
Analyser les ACF/PACF : est-ce qu'ils ressemblent à ceux d'une marche aléatoire ?
:::

::: {.callout-tip collapse="true"}
## Solution
```{r LakeHuron}
library(forecast)
library(patchwork)
autoplot(LakeHuron)
```
Il y a potentiellement une tendance à la baisse donc peut-être une tendance à la baisse.
A priori pas de raison de transformer la série.
```{r LakeHuron-display}
tseries::kpss.test(LakeHuron, "Trend")
tseries::adf.test(LakeHuron)
# Les tests KPSS et ADF considèrent que la série est non-stationnaire
# ggAcf(LakeHuron) /
# 	ggPacf(LakeHuron)
ggtsdisplay(LakeHuron)
```
L'ACF décroit de manière exponentielle et rapidement vers 0, ce n'est pas un signe de marche aléatoire.
En revanche le premier coefficient est élevé ce qui peut laisser penser que l'on n'a pas une marche aléatoire mais un coefficient AR(1) élevé.
Le PACF est nul à partir de l'ordre 3 : cela peut laisser penser à un processus AR d'ordre au plus 2.
On estime un modèle ARIMA(2,0,0) avec une tendance (*drift*).
```{r LakeHuron-residuals}
mod_trend <- Arima(LakeHuron, order = c(2, 0, 0), include.drift = TRUE)
mod_trend
# Le coefficient AR(1) est très proche de 1 ce qui explique que les tests précédents concluent à une non-stationnarité
lmtest::coeftest(mod_trend) # tous les coefficients sont significatifs, pas de raison de simplifier
# A priori les résidus sont un bruit blanc :
checkresiduals(mod_trend) 
cpgram(residuals(mod_trend))

# En considérant un AR(1) on a un modèle avec un AIC plus grand
mod_trend_ar1 <- Arima(LakeHuron, order = c(1, 0, 0), include.drift = TRUE)
mod_trend_ar1

# On aurait aussi pu faire un ARIMA(0,1,0) : c'est ce qui est retenu par auto.arima()
mod_diff <- auto.arima(LakeHuron)
mod_diff
```
Attention : on ne peut comparer les modèles en utilisant l'AIC ! (ordre de différenciation différent).
Pour comparer les modèles on peut étudier les erreurs de prévision.
```{r}
far2 <- function(x, h){forecast(Arima(x, order = c(2, 0, 0), include.drift = TRUE), h = h)}
fdiff <- function(x, h){forecast(Arima(x, order = c(0, 1, 0)), h = h)}
e1 <- tsCV(LakeHuron, far2, h = 1)
e2 <- tsCV(LakeHuron, fdiff, h = 1)
e_oos <- na.omit(ts.union(e1, e2))
# MSE plus petite avec second modèle
colMeans(e_oos^2)
# Mais cela vient du fait que lorsqu'il y a peu d'observations, le premier modèle est instable
colMeans(window(e_oos,start = 1890)^2)
colMeans(window(e_oos,start = 1900)^2)

# Résidus In Sample toujours plus petits avec premier modèle
# On commence en 1878 car ce n'est qu'après cette date que les résidus sont calculés par MLE
e_is <- window(ts.union(residuals(mod_trend), residuals(mod_diff)), start = 1878)
colMeans(e_is^2)
colMeans(window(e_is,start = 1890)^2)
colMeans(window(e_is,start = 1900)^2)
```
:::


# Nombre annuel de tâches solaires

::: callout-note
## Exercice
Étudier la série `sunspot.year` entre 1770 et 1869 :  Faut-il transformer la série ? Quel modèle ARIMA parait adapté ? la série est elle stationnaire ? 
Comparer avec `auto.arima()`.
:::

::: {.callout-tip collapse="true"}
## Solution
```{r sunspot.year}
library(forecast)
library(patchwork)
y <- window(sunspot.year, start = 1770, end = 1869)
ggtsdisplay(y)
```
Pas de tendance ni de raison de transformer la série.
Il y a des mouvements cycliques.
A priori pas de raison de transformer la série.
A priori pas une marche aléatoire.
```{r}
tseries::kpss.test(y)
tseries::adf.test(y)
```
Les tests KPSS et ADF considèrent que la série est non-stationnaire.
On remarque que l'ACF décroit rapidement vers O de manière sinusodiale  et que le PACF est nul à partir de l'ordre 3 : on estime un AR2.
```{r sunspot.year-resod}
mod_ar2 <- Arima(y, order = c(2, 0, 0))
mod_ar2
lmtest::coeftest(mod_ar2) # tous les coefficients sont significatifs, pas de raison de simplifier
# A priori les résidus sont un bruit blanc :
checkresiduals(mod_ar2) 
cpgram(residuals(mod_ar2))

# Auto.arima sélectionne un ARIMA(2,0,1) qui a un AICc plus petit
mod_auto <- auto.arima(y)
mod_auto
accuracy(mod_ar2)
accuracy(mod_auto)

far2 <- function(x, h){forecast(Arima(x, order=c(2, 0, 0)), h = h)}
far2ma1 <- function(x, h){forecast(Arima(x, order=c(2, 0, 1)), h = h)}
e1 <- tsCV(y, far2, h = 1)
e2 <- tsCV(y, far2ma1, h = 1)
e_oos <- window(ts.intersect(e1, e2), start = 1780)
# MSE plus petite avec second modèle
colMeans(e_oos^2, na.rm = TRUE)
```
:::

# Mombre mensuel de passagers aériens ;

::: callout-note
## Exercice
Étudier la série `AirPassengers` :  Faut-il transformer la série ? Quel modèle ARIMA parait adapté ? la série est elle stationnaire ? 
Comparer avec `auto.arima()`.
:::

::: {.callout-tip collapse="true"}
## Solution
```{r AirPassengers}
autoplot(AirPassengers)
```
Tendance claire avec une saisonnalité multiplicative.
Il faut passer la série au log.
```{r AirPassengers-log}
ggtsdisplay(log(AirPassengers))
```
L'analyse de l'ACF montre une décroissance lente avec des pics saisonniers.
L'analyse du PACF montre deux pics : à l'ordre 1 proche de 1 et à l'ordre 13.
Le second pic à l'ordre 13 et non 12 peut suggérer une double différenciation $(1-B)(1-B^{12})$.
La présence d'une saisonnalité a déjà été analysée dans les précédents TP : un test n'est pas nécessaire et on peut différencier à l'ordre 12.
```{r AirPassengers-diff}
ggtsdisplay(diff(log(AirPassengers), 12))
```
La série différenciée ne présente pas de tendance mais des périodes de hausse et de baisse. 
L'ACF décroit vers 0 mais pas de manière exponentielle. 
Le premier coefficient de l'ACF/PACF est élevé ce qui peut laisser penser que la série est toujours non-stationnaire
```{r}
tseries::kpss.test(diff(log(AirPassengers), 12))
tseries::adf.test(diff(log(AirPassengers), 12))
tseries::pp.test(diff(log(AirPassengers), 12))
# Les tests KPSS, ADF et PP donnent des résultats différents : à 5 % le test KPSS ne rejette l'hypothèse nulle de stationnarité, le test de PP rejette l'hypothèse de non-stationnarité alors qu'ADF ne la rejette pas.
ndiffs(diff(log(AirPassengers), 12))
```
La fonction `ndiffs()`, basée par défaut sur KPSS conclue à une non-stationnarité. 
Cela vient de paramètres différents dans le test KPSS utilisé.
L'analyse des ACF semblent plutôt montrer un présence de marche aléatoire : on différencie.
Les ACF et PACF semblent montrer une saisonnalité encore présente mais pas de décroissance nette de l'ACF ou PACF.
```{r AirPassengers-diff-double}
ggAcf(diff(diff(log(AirPassengers), 12), 1)) /
	ggPacf(diff(diff(log(AirPassengers), 12), 1))

mod = Arima(AirPassengers, order = c(0,1,0), seasonal = c(1,1,1), lambda = 0)
Box.test(resid(mod), fitdf = 2,lag = 24,type = "Ljung")
cpgram(resid(mod))
# checkresiduals(mod)
```
Les résidus ne sont pas un bruit blanc
```{r AirPassengers-diff-double-acf}
ggAcf(residuals(mod)) /
	ggPacf(residuals(mod))
```
Encore pas de décroissance claire mais un pic à l'ordre 1. 
On peut donc penser que $p,q, P,q \leq 1$
```{r AirPassengers-arma-comp}
mod1 <- Arima(AirPassengers, order = c(1,1,1), seasonal = c(1,1,1), lambda = 0)
# On a bien un bruit blanc cette fois
Box.test(resid(mod1), fitdf = 4,lag = 24,type = "Ljung")
cpgram(resid(mod1))
lmtest::coeftest(mod1)
```
Les ordres AR ne sont pas significatifs significatifs. 
On va enlever un ordre AR et refaire le test : ne pas enlever toutes les variables en même temps car on teste ici si une variable est nulle et non pas si un ensemble de variables est nul !

```{r AirPassengers-arma-fin}
mod2 <- Arima(AirPassengers, order = c(0,1,1), seasonal = c(1,1,1), lambda = 0)
# Toujours un bruit blanc et AR saisonnier non significatif
Box.test(resid(mod2), fitdf = 3,lag = 24,type = "Ljung")
lmtest::coeftest(mod2) 

mod3 = Arima(AirPassengers, order = c(0,1,1), seasonal = c(0,1,1), lambda = 0)
# Toujours un bruit blanc et tous les coefs sont signifactifs, on ne peut pas simplifier davantage
Box.test(resid(mod3), fitdf = 2,lag = 24,type = "Ljung")
lmtest::coeftest(mod3) 
# C'est le dernier modèle qui a l'AIC le plus petit : c'est celui que l'on retient
AIC(mod1, mod2, mod3)

# C'est aussi le modèle retenu par auto.arima
auto.arima(AirPassengers, lambda = 0)
# auto.arima(AirPassengers, lambda = 0, stepwise = FALSE) # plus lent
```
On retrouve le modèle Airline : $ARIMA(0,1,1)(0,1,1)$ !
:::

# Température mensuelle moyenne au chateau de Nottingham

Pour l'analyse de la série `nottem`, on utilisera le `tidyverts`.
Ci-dessous un exemple de manipulation avec une autre série :

```{r tsibble-ex}
library(tsibble)
library(dplyr)
library(fable)
library(feasts)
library(ggplot2)
y <- as_tsibble(USAccDeaths)
y
(y %>% ACF(value %>%  difference(12)) %>% autoplot()) /
	(y %>% PACF(value %>%  difference(12)) %>% autoplot()) & ylim(-1,1)
model <- y %>%
	model(arima = ARIMA(value ~ 0 + pdq(0, 1, 1) + PDQ(0, 1, 0)),
		  auto_arima = ARIMA(value))
model 
model %>% accuracy()
model %>% glance()
model %>% residuals() %>%  ACF() %>%  autoplot()
# On peut utiliser la fonction report() sur un sous modèle
model %>% select(auto_arima) %>% 
	report()
model %>% 
	forecast(h=12) %>%  
	autoplot(y)
```

::: callout-note
## Exercice
Étudier la série `as_tsibble(nottem)` :  

1. Faut-il transformer la série ?  
2. Faut-il différencier la série ? (utiliser la fonction `difference()`) 
3. Étudier les ACF/PACF : quels sont les ordre plausibles ?
4. Tester un ensemble de modèles possibles. Les trier par AICc et prendre celui qui le minimise.
5. Vérifier la qualité des résidus
6. Comparer les prévisions avec une sélection automatique et avec un modèle ETS.
:::

::: {.callout-tip collapse="true"}
## Solution
```{r nottem-plots, message=FALSE}
library(lubridate)
y <- as_tsibble(nottem)
autoplot(y, value)
gg_season(y, value)
```
Série déjà étudiée : a priori pas de transformation nécessaire, pas de tendance et saisonnalité mensuelle nette.
```{r nottem-diff12, message=FALSE}
y %>% gg_tsdisplay(value %>%  difference(12), plot_type = "partial")
```
A priori série différenciée est stationnaire.
L'analyse des ACF/PACF suggère $P= 1$ et/ou $Q=1$, $P<=1$ et $Q <= 2$.
Pas de constante dans le modèle.
```{r, message=FALSE}
# Si on ne veut pas écrire tous les codes à la main on peut aussi faire un programme
# d = expand.grid(p=0:1,q=0:2,P=0:1, Q=0:1)
# cat(sprintf("sarima%i0%i_%i1%i = ARIMA(value ~ -1 + pdq(%i, 0, %i) + PDQ(%i, 1, %i))",
# 		d$p, d$q, d$P, d$Q,
# 		d$p, d$q, d$P, d$Q), sep =",\n")
all_models <- y %>%
	model(
		sarima000_010 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(0, 1, 0)),
		sarima100_010 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(0, 1, 0)),
		sarima001_010 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(0, 1, 0)),
		sarima101_010 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(0, 1, 0)),
		sarima002_010 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(0, 1, 0)),
		sarima102_010 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(0, 1, 0)),
		sarima000_110 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(1, 1, 0)),
		sarima100_110 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 0)),
		sarima001_110 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(1, 1, 0)),
		sarima101_110 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(1, 1, 0)),
		sarima002_110 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(1, 1, 0)),
		sarima102_110 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(1, 1, 0)),
		sarima000_011 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(0, 1, 1)),
		sarima100_011 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(0, 1, 1)),
		sarima001_011 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(0, 1, 1)),
		sarima101_011 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(0, 1, 1)),
		sarima002_011 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(0, 1, 1)),
		sarima102_011 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(0, 1, 1)),
		sarima000_111 = ARIMA(value ~ -1 + pdq(0, 0, 0) + PDQ(1, 1, 1)),
		sarima100_111 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 1)),
		sarima001_111 = ARIMA(value ~ -1 + pdq(0, 0, 1) + PDQ(1, 1, 1)),
		sarima101_111 = ARIMA(value ~ -1 + pdq(1, 0, 1) + PDQ(1, 1, 1)),
		sarima002_111 = ARIMA(value ~ -1 + pdq(0, 0, 2) + PDQ(1, 1, 1)),
		sarima102_111 = ARIMA(value ~ -1 + pdq(1, 0, 2) + PDQ(1, 1, 1))
	)
all_models %>% 
	glance() %>% 
	arrange(AICc)
best_model <- y %>%
	model(
		sarima100_111 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 1))
	)
```
A priori bruit blanc :
```{r nottem-best-mod, message=FALSE}
best_model %>% gg_tsresiduals()
augment(best_model) %>% 
	features(.innov, ljung_box, dof = 3, lag = 24)
compar_model <- y %>%
	model(
		sarima100_111 = ARIMA(value ~ -1 + pdq(1, 0, 0) + PDQ(1, 1, 1)),
		auto_arima = ARIMA(value ~ -1),
		ets = ETS(value)
	)
```
Modèle sélectionné a un AICc plus petit que l'auto-arima  mais un RMSE plus élevé.
```{r, message=FALSE}
compar_model
compar_model %>% glance()
compar_model %>% accuracy()
```
Les prévisions des 3 modèles sont très proches
```{r nottem-prem, message=FALSE}
forecast(compar_model, h = "1 year") %>% 
	autoplot(y %>% filter(year(index) >= 1938))
```
::: 

L'avantage est `tidyverts` est que l'on peut appliquer facilement plusieurs fonctions à plusieurs séries et comparer les méthodes entre elles.
En reprenant l'exemple disponible ici <https://fable.tidyverts.org> :

```{r aus-retail-ex}
library(fable)
library(tsibble)
library(tsibbledata)
library(lubridate)
library(dplyr)
aus_retail %>%
	filter(
		State %in% c("New South Wales", "Victoria"),
		Industry == "Department stores"
	) %>% 
	model(
		ets = ETS(box_cox(Turnover, 0.3)),
		arima = ARIMA(log(Turnover)),
		snaive = SNAIVE(Turnover)
	) %>%
	forecast(h = "2 years") %>% 
	autoplot(filter(aus_retail, year(Month) > 2010), level = NULL)
```
